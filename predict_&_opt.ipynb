{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import typing\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import cvxpy as cp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "import sys\n",
    "import io\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "from torch.utils import data as torch_data\n",
    "import pickle\n",
    "import itertools\n",
    "import warnings\n",
    "from numpy import linalg as LA\n",
    "from sklearn import preprocessing\n",
    "from cvxpylayers.torch.cvxpylayer import CvxpyLayer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"training_data = []\n",
    "inci_matrix = torch.tensor([ [-1,-1,-1,0,0,0,0,0],\n",
    "    [1,0,0,-1,0,-1,0,0],\n",
    "               [0,1,0,1,1,0,-1,0],\n",
    "               \n",
    "               [0,0,1,0,-1,0,0,-1],\n",
    "               [0,0,0,0,0,1,1,1] \n",
    "               ],dtype=torch.float32)\n",
    "\n",
    "print(inci_matrix)  \n",
    "while len(training_data) != 1000:\n",
    "    \n",
    "    e1 = float(random.randrange(1, 10, 1)) #random.randrange(1, 10, 1)#1.0#np.random.normal(0.0, 1.0, 1)[0]#random.randrange(1, 10, 1)\n",
    "    e2 = float(random.randrange(1, 10, 1))   #random.randrange(1, 10, 1)#5.0#np.random.normal(0.0, 1.0, 1)[0]#random.randrange(1, 10, 1)\n",
    "    e3 = float(random.randrange(1, 10, 1))  #random.randrange(1, 10, 1)#6.0#np.random.normal(0.0, 1.0, 1)[0]#random.randrange(1, 5, 1)\n",
    "    e4 =float(random.randrange(1, 10, 1))#random.randrange(1, 10, 1)#2.0\n",
    "    e5 = float(random.randrange(1, 10, 1))#random.randrange(1, 10, 1)#2.0\n",
    "    e6 = float(random.randrange(1, 10, 1))  #random.randrange(1, 10, 1)#1.0\n",
    "    e7  = float(random.randrange(1, 10, 1))  #random.randrange(1, 10, 1)#2.0\n",
    "    e8  = float(random.randrange(1, 10, 1))\n",
    "    #if e1 <= 0 or e2 <= 0 or e3 <= 0:\n",
    "        #   continue \n",
    "\n",
    "    #m = np.array([[0,e1,e2],\n",
    "        #           [e1,0,e3],\n",
    "        #          [e2,e3,0]])\n",
    "\n",
    "    z = torch.tensor([e1,e2,e3, e4, e5, e6, e7, e8])\n",
    "    training_data.append(z)\n",
    "training_data = torch.stack(training_data)\"\"\"\n",
    "\n",
    "\n",
    "training_data = []\n",
    "#inci_matrix = torch.tensor([ [-1,-1,-1,0,0,0,0,0],\n",
    "#    [1,0,0,-1,0,-1,0,0],\n",
    " #              [0,1,0,1,1,0,-1,0],\n",
    "               \n",
    "  #             [0,0,1,0,-1,0,0,-1],\n",
    "   #            [0,0,0,0,0,1,1,1] \n",
    "    #           ],dtype=torch.float32)\n",
    "\n",
    "#inci_matrix = torch.tensor([ [-1,-1,-1,0,0,0,0,0],\n",
    "   # [1,0,0,-1,0,-1,0,0],\n",
    "    #           [0,1,0,1,1,0,-1,0],\n",
    "               \n",
    "   #            [0,0,1,0,-1,0,0,-1],\n",
    "  #             [0,0,0,0,0,1,1,1] \n",
    " #              ],dtype=torch.float32)\n",
    "\n",
    "\n",
    "inci_matrix = pickle.load( open( \"matrix_{}b{}.p\".format(20,30), \"rb\" ) )\n",
    "\n",
    "\n",
    "\n",
    "#print(inci_matrix)  \n",
    "while len(training_data) != 2000:\n",
    "    \n",
    "    z = torch.tensor([float(random.uniform(0.001, 1)) for i in range(30)])\n",
    "    #z = torch.tensor([e1,e2,e3, e4, e5, e6, e7, e8])\n",
    "    training_data.append(z)\n",
    "training_data = torch.stack(training_data)\n",
    "#model_load = torch.load('shortest_path_proxy_{}.model'.format('Dag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_net_data_generation(inputs):\n",
    "    \n",
    "    data = []\n",
    "    target = []\n",
    "\n",
    "    N,M  = inputs.shape\n",
    "    \n",
    "    A = torch.rand((M, M))\n",
    "   \n",
    "    print(\"Condition number: \",LA.cond(A))\n",
    "\n",
    "    A_Inv = torch.linalg.inv(A)\n",
    "    alpha = 0.05 # perturbation amplitude\n",
    "\n",
    "    \n",
    "    for i in inputs:\n",
    "        target.append(i)\n",
    "        x = torch.nn.functional.normalize(torch.matmul(A_Inv,i), dim=0, p=2)\n",
    "        data.append(x)\n",
    "        \n",
    "    \n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number:  628.64886\n",
      "(2000, 30)\n"
     ]
    }
   ],
   "source": [
    "#print(training_data)\n",
    "x_nn, y_nn = pred_net_data_generation(training_data)\n",
    "\n",
    "x_nn = torch.stack(x_nn)\n",
    "y_nn = torch.stack(y_nn)\n",
    "\n",
    "x_nn = preprocessing.normalize(x_nn)\n",
    "y_nn = preprocessing.normalize(y_nn)\n",
    "#print(x_nn[0])\n",
    "print(x_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of train, validation, test data (1200, 30) (1200, 30) (300, 30) (300, 30) (500, 30) (500, 30)\n"
     ]
    }
   ],
   "source": [
    "seed_random = 9999\n",
    "np.random.seed(seed_random)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_nn, y_nn, test_size=0.25, train_size=0.75, random_state=seed_random, shuffle=True)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, test_size=0.2, train_size=0.8, random_state=seed_random, shuffle=True)\n",
    "\n",
    "print('shapes of train, validation, test data', x_train.shape, y_train.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "\n",
    "# JK\n",
    "def init_weights(net, init_type='normal', init_gain=0.02):\n",
    "    \"\"\"Initialize network weights.\n",
    "\n",
    "    Parameters:\n",
    "        net (network)   -- network to be initialized\n",
    "        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
    "        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
    "\n",
    "    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
    "    work better for some applications. Feel free to try yourself.\n",
    "    \"\"\"\n",
    "\n",
    "    def init_func(m):  # define the initialization function\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, init_gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
    "            elif init_type == 'kaiming_uniform':\n",
    "                #init.kaiming_uniform(m.weight.data, a=0, mode='fan_in')\n",
    "                #init.kaiming_uniform(m.bias.data, a=0, mode='fan_in')\n",
    "                nn.init.kaiming_uniform_(m.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
    "                init.orthogonal_(m.bias.data, gain=init_gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find(\n",
    "                'BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "            init.normal_(m.weight.data, 1.0, init_gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'iterations':2000,'batch_size': 100, 'input_size':30, 'hidden_units_1': 100, 'hidden_units_2':150, 'hidden_units_3': 200, 'hidden_units_4': 300, 'hidden_units_5': 200, 'hidden_units_6': 150, 'hidden_units_7': 100, 'hidden_units_8': 300,'hidden_units_9': 300,'do_1': 0.2, 'do_2': 0.1, 'do_3': 0.05, 'output_size': 30, 'lr': 0.001, 'min_lr': 1e-05, 'max_lr': 0.001, 'epochs': 20, 'lr_sched': 'clr', 'lr_sched_mode': 'triangular', 'gamma': 0.95}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "trainset = torch_data.TensorDataset(torch.as_tensor(x_train, dtype=torch.float, device=device), \n",
    "torch.as_tensor(y_train, dtype=torch.float, device=device))\n",
    "train_dl = torch_data.DataLoader(trainset, batch_size=params['batch_size'], drop_last=True)\n",
    "\n",
    "val_dl = torch_data.DataLoader(torch_data.TensorDataset(torch.as_tensor(x_cv, dtype=torch.float, device=device), \n",
    "torch.as_tensor(y_cv, dtype=torch.float, device=device)), batch_size=params['batch_size'], drop_last=True)\n",
    "\n",
    "test_dl = torch_data.DataLoader(torch_data.TensorDataset(torch.as_tensor(x_test, dtype=torch.float, device=device), \n",
    "torch.as_tensor(y_test, dtype=torch.float, device=device)), batch_size=params['batch_size'], drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with xavier\n",
      "model loaded into device= cpu\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(9999)\n",
    "def get_model():\n",
    "    \"\"\"\n",
    "    creates a PyTorch model. Change the 'params' dict above to \n",
    "    modify the neural net configuration.\n",
    "    \"\"\"\n",
    "    model = torch.nn.Sequential(\n",
    "     torch.nn.Linear(params['input_size'], params['hidden_units_1']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_1']),\n",
    "        torch.nn.Dropout(p=params['do_1']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_1'], params['hidden_units_2']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_2']),\n",
    "         torch.nn.Dropout(p=params['do_2']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_2'], params['hidden_units_3']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_3']),\n",
    "         torch.nn.Dropout(p=params['do_3']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_3'], params['hidden_units_4']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_4']),\n",
    "        torch.nn.Dropout(p=params['do_3']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_4'], params['hidden_units_5']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_5']),\n",
    "        torch.nn.Dropout(p=params['do_3']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_5'], params['hidden_units_6']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_6']),\n",
    "        torch.nn.Dropout(p=params['do_3']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_6'], params['hidden_units_7']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_7']),\n",
    "        torch.nn.Dropout(p=params['do_3']),\n",
    "        torch.nn.ReLU(),\n",
    "           #torch.nn.ReLU(),\n",
    "       # torch.nn.Linear(params['hidden_units_7'], params['hidden_units_8']),\n",
    "       # torch.nn.BatchNorm1d(params['hidden_units_8']),\n",
    "       # torch.nn.Dropout(p=params['do_3']),\n",
    "       # torch.nn.ReLU(),\n",
    "       # torch.nn.Linear(params['hidden_units_8'], params['hidden_units_9']),\n",
    "       # torch.nn.BatchNorm1d(params['hidden_units_9']),\n",
    "      #  torch.nn.Dropout(p=params['do_3']),\n",
    "     #  torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_7'], params['output_size']),\n",
    "       # torch.nn.ReLU(),\n",
    "       # torch.nn.Sigmoid(),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def regret(y_true, y_hat,proxy):\n",
    "    \n",
    "    A = inci_matrix\n",
    "    n,m = A.shape\n",
    "    eps_ = 0.1\n",
    "    \n",
    "    #print( \"weight_target {} , predicted weight {}\".format(y_true[0], y_hat[0]))\n",
    "    \n",
    "    y_true_decision = proxy(y_true)\n",
    "    \n",
    "    y_hat_decision = proxy(y_hat)\n",
    "    \n",
    "   # b = np.zeros(n)\n",
    "   # b[0] = -1\n",
    "   # b[n-1] = 1\n",
    "   # b = torch.tensor(b)\n",
    "    \n",
    "    #print( \"weight_target decision {} , predicted weight decision {}\".format(y_true_decision[0], y_hat_decision[0]))\n",
    "    \n",
    "    \n",
    "    objective_true =( (y_true * y_true_decision).sum(1)   \n",
    "                     + torch.tensor([eps_*torch.norm(y_true_decision[i], p=2) for i in range((y_true_decision.shape)[0])])\n",
    "                    # +torch.tensor([eps_*torch.sum(y_true_decision[i]*torch.log(y_true_decision[i])) for i in range((y_true_decision.shape)[0])])\n",
    "                     \n",
    "                     )\n",
    "    \n",
    "    objective_hat =  ( (y_true * y_hat_decision).sum(1) \n",
    "                    + torch.tensor([eps_*torch.norm(y_hat_decision[i], p=2) for i in range((y_hat_decision.shape)[0])])\n",
    "                   # +torch.tensor([eps_*torch.sum(y_hat_decision[i]*torch.log(y_hat_decision[i])) for i in range((y_hat_decision.shape)[0])])\n",
    "                      )\n",
    "    \n",
    "   \n",
    "    regret = torch.mean(objective_hat - objective_true)\n",
    "    #print(regret)\n",
    "   \n",
    "    loss_vec = (y_true * proxy(y_hat)).sum(1)\n",
    "    \n",
    "  \n",
    "    loss = torch.mean(loss_vec)\n",
    "   \n",
    "    return loss, regret\n",
    "\n",
    "def regret_cvxpy(y_true, y_hat,cvx):\n",
    "    A = inci_matrix\n",
    "    \n",
    "    \n",
    "    \n",
    "    eps_ = 0.1\n",
    "    \n",
    "    \n",
    "    y_true_decision = cvx(A,y_true)\n",
    "    y_hat_decision = cvx(A,y_hat)\n",
    "    \n",
    "    #eps_*torch.sum(y_true_decision[i]*torch.log(y_true_decision[i]))\n",
    "    #eps_*torch.norm(y_true_decision[i], p=2) \n",
    "    \n",
    "    objective_true =( (y_true * y_true_decision).sum(1) \n",
    "                     + torch.tensor([eps_*torch.norm(y_true_decision[i], p=2) for i in range((y_true_decision.shape)[0])])\n",
    "                     #+torch.tensor([eps_*torch.sum(y_true_decision[i]*torch.log(y_true_decision[i])) for i in range((y_true_decision.shape)[0])]) \n",
    "                     \n",
    "                     )\n",
    "    objective_hat =  ( (y_true * y_hat_decision).sum(1) \n",
    "                      + torch.tensor([eps_*torch.norm(y_hat_decision[i], p=2) for i in range((y_hat_decision.shape)[0])])\n",
    "                     # +torch.tensor([eps_*torch.sum(y_hat_decision[i]*torch.log(y_hat_decision[i])) for i in range((y_hat_decision.shape)[0])])\n",
    "                      \n",
    "                      )\n",
    "    \n",
    "    regret = torch.mean(objective_hat - objective_true)\n",
    "    return regret\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "initialize_model = True\n",
    "if initialize_model:\n",
    "    init_weights(model, 'xavier')\n",
    "\n",
    "print('model loaded into device=', next(model.parameters()).device)\n",
    "\n",
    "# this is just to capture model summary as string\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = buffer = io.StringIO()\n",
    "\n",
    "summary(model, input_size=(params['input_size'], ))\n",
    "\n",
    "sys.stdout = old_stdout\n",
    "model_summary = buffer.getvalue()\n",
    "#print('model-summary\\n', model_summary)\n",
    "# later this 'model-summary' string can be written to tensorboard\n",
    "\n",
    "#lr_reduce_patience = 20\n",
    "#lr_reduce_factor = 0.1\n",
    "\n",
    "loss_fn = regret#nn.MSELoss()  \n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=params['lr'])#, momentum=0.9, dampening=0, weight_decay=0, nesterov=True)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_violations(inc_matrix, selected_edges):\n",
    "    #viol = 0\n",
    "    viol_lst = []\n",
    "    n,m = inc_matrix.shape\n",
    "    b = np.zeros(n)\n",
    "    # these are flipped to get 0 for violations, original are the opposite \n",
    "    b[0] = -1\n",
    "    b[n-1] = 1\n",
    "    \n",
    "    batch_size, null = selected_edges.shape\n",
    "    \n",
    "    for i in selected_edges:\n",
    "      #torch.unsqueeze(i,1)\n",
    "      #print(i.shape)\n",
    "      viol = 0\n",
    "      \n",
    "      a = torch.matmul(inci_matrix,i)\n",
    "      #print(a.shape)\n",
    "     # print(a.shape)\n",
    "      #print(b.shape)\n",
    "      c = a - b \n",
    "      for values in c:\n",
    "        viol += torch.abs(values) \n",
    "      \n",
    "      \n",
    "      \n",
    "      for j in i:\n",
    "        if j < 0:\n",
    "          viol += torch.abs(j)\n",
    "        elif j > 1:\n",
    "          viol += torch.abs(j-1)\n",
    "      viol_lst.append(viol)\n",
    "      \n",
    "    #print(viol_lst)\n",
    "      \n",
    "    return  max(viol_lst), sum(viol_lst)/len(viol_lst)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cvxpy for proxy measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvx_py(A, pred):\n",
    "   \n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    \n",
    "    eps = 0.1\n",
    "    \n",
    "    batch_s, edges  = pred.shape\n",
    "   \n",
    "    \n",
    "    n,m = A.shape\n",
    "    target = torch.zeros((batch_s, edges))\n",
    "    \n",
    "    #print(target.shape)\n",
    "    c = cp.Parameter(m)\n",
    "    #c = c.detach().numpy()\n",
    "    b = np.zeros(n)\n",
    "    b[0] = -1\n",
    "    b[n-1] = 1\n",
    "    x = cp.Variable(shape=m)\n",
    "    constr = [x>=0, x <= 1,\n",
    "             A@x == b]\n",
    "    \n",
    "    #0.5*cp.maximum(0,cp.sum(A@x - b))\n",
    "    #- eps*cp.sum(cp.entr(x))\n",
    "    #+ eps*cp.norm(x,p=2)\n",
    "    problem  = cp.Problem(cp.Minimize(c @ x + eps*cp.norm(x,p=2) )\n",
    "                          ,constr)\n",
    "    cvxlayer = CvxpyLayer(problem, parameters=[c], variables=[x])\n",
    "  \n",
    "   \n",
    "    solutions = lambda z: cvxlayer(z)[0] #, args = {'tol':1e-10})[0]\n",
    "    index = 0\n",
    "    for x in pred:\n",
    "        \n",
    "         \n",
    "        #print(x)\n",
    "       # print(x)\n",
    "        \n",
    "            #sol = solutions(x)\n",
    "        target[index] = solutions(x)\n",
    "        \n",
    "        #print(problem.value)\n",
    "        index += 1\n",
    "    \n",
    "    return torch.Tensor(target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------iteration: 0\n",
      "l1 decision: 0.2495909035205841\n",
      "l1 weight: 0.2122010439634323\n",
      "avg viol: 0.4733633075410035, max viol: 1.2219667583703995 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : 0.3671990931034088, valid regret : 0.2502618730068207 \n",
      "\n",
      " UPDATE \n",
      "\n",
      "---------------------------------------iteration: 1\n",
      "l1 decision: 0.05656363070011139\n",
      "l1 weight: 0.18710312247276306\n",
      "avg viol: 0.5746616196981631, max viol: 1.1456763185560703 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : 0.1458059847354889, valid regret : 0.043407317250967026 \n",
      "\n",
      " UPDATE \n",
      "\n",
      "---------------------------------------iteration: 2\n",
      "l1 decision: 0.05562819913029671\n",
      "l1 weight: 0.17950023710727692\n",
      "avg viol: 0.9283753798215184, max viol: 1.2494680602103472 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : 0.01572435349225998, valid regret : 0.01972162164747715 \n",
      "\n",
      " UPDATE \n",
      "\n",
      "---------------------------------------iteration: 3\n",
      "l1 decision: 0.05625821277499199\n",
      "l1 weight: 0.17594479024410248\n",
      "avg viol: 1.0117937839013758, max viol: 1.2944221643265337 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.012286847457289696, valid regret : -0.014857133850455284 \n",
      "---------------------------------------iteration: 4\n",
      "l1 decision: 0.06050736829638481\n",
      "l1 weight: 0.17753911018371582\n",
      "avg viol: 1.0786842345213516, max viol: 1.4059715259354562 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.04024398699402809, valid regret : -0.032853174954652786 \n",
      "---------------------------------------iteration: 5\n",
      "l1 decision: 0.06265884637832642\n",
      "l1 weight: 0.17317602038383484\n",
      "avg viol: 1.0966979486629134, max viol: 1.3633400481194258 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.04336490482091904, valid regret : -0.08449674397706985 \n",
      "---------------------------------------iteration: 6\n",
      "l1 decision: 0.06994567811489105\n",
      "l1 weight: 0.17400631308555603\n",
      "avg viol: 1.1367966107127723, max viol: 1.5286587034352124 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.05523163825273514, valid regret : -0.05867473781108856 \n",
      "---------------------------------------iteration: 7\n",
      "l1 decision: 0.061091501265764236\n",
      "l1 weight: 0.17043963074684143\n",
      "avg viol: 1.0860100764705567, max viol: 1.3175802875775844 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.048004377633333206, valid regret : -0.15129390358924866 \n",
      "---------------------------------------iteration: 8\n",
      "l1 decision: 0.07111891359090805\n",
      "l1 weight: 0.1693492829799652\n",
      "avg viol: 1.2358587590465322, max viol: 1.501847849227488 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.08764393627643585, valid regret : -0.12465155869722366 \n",
      "---------------------------------------iteration: 9\n",
      "l1 decision: 0.06769609451293945\n",
      "l1 weight: 0.1682303100824356\n",
      "avg viol: 1.2373534978907264, max viol: 1.4712593858130276 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.08520296216011047, valid regret : -0.15587835013866425 \n",
      "---------------------------------------iteration: 10\n",
      "l1 decision: 0.07369430363178253\n",
      "l1 weight: 0.16877707839012146\n",
      "avg viol: 1.288571528948378, max viol: 1.582289727171883 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.10910765826702118, valid regret : -0.15312321484088898 \n",
      "---------------------------------------iteration: 11\n",
      "l1 decision: 0.06967257708311081\n",
      "l1 weight: 0.16501273214817047\n",
      "avg viol: 1.3105785277026007, max viol: 1.5338777073193341 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.11824270337820053, valid regret : -0.16351936757564545 \n",
      "---------------------------------------iteration: 12\n",
      "l1 decision: 0.07422775030136108\n",
      "l1 weight: 0.16357281804084778\n",
      "avg viol: 1.3574011548835552, max viol: 1.5773867331445217 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.13317832350730896, valid regret : -0.16305555403232574 \n",
      "---------------------------------------iteration: 13\n",
      "l1 decision: 0.0743965357542038\n",
      "l1 weight: 0.16196627914905548\n",
      "avg viol: 1.3820999110204866, max viol: 1.6062918389216065 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.14323841035366058, valid regret : -0.14374908804893494 \n",
      "---------------------------------------iteration: 14\n",
      "l1 decision: 0.07249331474304199\n",
      "l1 weight: 0.16368114948272705\n",
      "avg viol: 1.3669182687799912, max viol: 1.5492347134277225 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.13461366295814514, valid regret : -0.14393672347068787 \n",
      "---------------------------------------iteration: 15\n",
      "l1 decision: 0.07220033556222916\n",
      "l1 weight: 0.16102677583694458\n",
      "avg viol: 1.3686129134584917, max viol: 1.5647180979140103 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.126719668507576, valid regret : -0.11063200235366821 \n",
      "---------------------------------------iteration: 16\n",
      "l1 decision: 0.08324740827083588\n",
      "l1 weight: 0.1630220115184784\n",
      "avg viol: 1.2752653667377307, max viol: 1.4544020928442478 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.09496580809354782, valid regret : -0.04697521775960922 \n",
      "---------------------------------------iteration: 17\n",
      "l1 decision: 0.0619816780090332\n",
      "l1 weight: 0.16287727653980255\n",
      "avg viol: 1.1493366891570622, max viol: 1.3528262916952372 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.061784930527210236, valid regret : -0.1272684931755066 \n",
      "---------------------------------------iteration: 18\n",
      "l1 decision: 0.07069090753793716\n",
      "l1 weight: 0.16595500707626343\n",
      "avg viol: 1.3010303691349692, max viol: 1.4545852052979171 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.11579196155071259, valid regret : -0.15162746608257294 \n",
      "---------------------------------------iteration: 19\n",
      "l1 decision: 0.07072655111551285\n",
      "l1 weight: 0.16484424471855164\n",
      "avg viol: 1.3539247540466022, max viol: 1.4707506373524666 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.13933596014976501, valid regret : -0.1304263472557068 \n",
      "---------------------------------------iteration: 20\n",
      "l1 decision: 0.07699581980705261\n",
      "l1 weight: 0.16243578493595123\n",
      "avg viol: 1.3719569509488065, max viol: 1.5115989311598241 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.13546021282672882, valid regret : -0.1318548619747162 \n",
      "---------------------------------------iteration: 21\n",
      "l1 decision: 0.0657811090350151\n",
      "l1 weight: 0.16218838095664978\n",
      "avg viol: 1.2784434240683913, max viol: 1.440157942008227 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1073957085609436, valid regret : -0.13447487354278564 \n",
      "---------------------------------------iteration: 22\n",
      "l1 decision: 0.07374030351638794\n",
      "l1 weight: 0.16225673258304596\n",
      "avg viol: 1.3869087844964816, max viol: 1.5473343222402036 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.14463335275650024, valid regret : -0.14616526663303375 \n",
      "---------------------------------------iteration: 23\n",
      "l1 decision: 0.06727767735719681\n",
      "l1 weight: 0.16217438876628876\n",
      "avg viol: 1.331944108493626, max viol: 1.4559393944218755 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.13004569709300995, valid regret : -0.14579220116138458 \n",
      "---------------------------------------iteration: 24\n",
      "l1 decision: 0.07435819506645203\n",
      "l1 weight: 0.16103024780750275\n",
      "avg viol: 1.43585384701204, max viol: 1.5799190760590136 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.16282688081264496, valid regret : -0.15626056492328644 \n",
      "---------------------------------------iteration: 25\n",
      "l1 decision: 0.07100405544042587\n",
      "l1 weight: 0.16322065889835358\n",
      "avg viol: 1.403751956971828, max viol: 1.5262042540125549 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.15524671971797943, valid regret : -0.1168055534362793 \n",
      "---------------------------------------iteration: 26\n",
      "l1 decision: 0.07246170192956924\n",
      "l1 weight: 0.16245831549167633\n",
      "avg viol: 1.3660419970337534, max viol: 1.4899803921580315 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.13387946784496307, valid regret : -0.13824597001075745 \n",
      "---------------------------------------iteration: 27\n",
      "l1 decision: 0.06778936833143234\n",
      "l1 weight: 0.1636100858449936\n",
      "avg viol: 1.3356667556910542, max viol: 1.4680218040011823 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.12359912693500519, valid regret : -0.15574316680431366 \n",
      "---------------------------------------iteration: 28\n",
      "l1 decision: 0.07642959803342819\n",
      "l1 weight: 0.16429582238197327\n",
      "avg viol: 1.463677290873602, max viol: 1.5797435794956982 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1738131195306778, valid regret : -0.17518222332000732 \n",
      "---------------------------------------iteration: 29\n",
      "l1 decision: 0.0725383460521698\n",
      "l1 weight: 0.16168086230754852\n",
      "avg viol: 1.4335724159004166, max viol: 1.5420928109670058 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.16415393352508545, valid regret : -0.1237134262919426 \n",
      "---------------------------------------iteration: 30\n",
      "l1 decision: 0.07656873017549515\n",
      "l1 weight: 0.16460038721561432\n",
      "avg viol: 1.4191852098569506, max viol: 1.543282577302307 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1566420942544937, valid regret : -0.1644444465637207 \n",
      "---------------------------------------iteration: 31\n",
      "l1 decision: 0.06958460807800293\n",
      "l1 weight: 0.1649649739265442\n",
      "avg viol: 1.3835891654447188, max viol: 1.5179957607761025 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1545500010251999, valid regret : -0.1507122963666916 \n",
      "---------------------------------------iteration: 32\n",
      "l1 decision: 0.07712669670581818\n",
      "l1 weight: 0.16365081071853638\n",
      "avg viol: 1.4424307175155264, max viol: 1.5652303877286613 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1609625667333603, valid regret : -0.16837726533412933 \n",
      "---------------------------------------iteration: 33\n",
      "l1 decision: 0.07189568877220154\n",
      "l1 weight: 0.16408014297485352\n",
      "avg viol: 1.413647593242931, max viol: 1.5413914788514376 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.15151387453079224, valid regret : -0.14436234533786774 \n",
      "---------------------------------------iteration: 34\n",
      "l1 decision: 0.07840242236852646\n",
      "l1 weight: 0.16441330313682556\n",
      "avg viol: 1.4673692237527576, max viol: 1.5601119943894446 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.17193371057510376, valid regret : -0.17625898122787476 \n",
      "---------------------------------------iteration: 35\n",
      "l1 decision: 0.07128742337226868\n",
      "l1 weight: 0.16622762382030487\n",
      "avg viol: 1.4146637328041833, max viol: 1.5156316423090175 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.16073589026927948, valid regret : -0.1390124261379242 \n",
      "---------------------------------------iteration: 36\n",
      "l1 decision: 0.07880546152591705\n",
      "l1 weight: 0.16509020328521729\n",
      "avg viol: 1.4621888044592923, max viol: 1.5715347505174577 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1672225147485733, valid regret : -0.16569416224956512 \n",
      "---------------------------------------iteration: 37\n",
      "l1 decision: 0.07123541831970215\n",
      "l1 weight: 0.16623620688915253\n",
      "avg viol: 1.4216057535370055, max viol: 1.536433134227991 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.16834713518619537, valid regret : -0.15658354759216309 \n",
      "---------------------------------------iteration: 38\n",
      "l1 decision: 0.07804595679044724\n",
      "l1 weight: 0.16586680710315704\n",
      "avg viol: 1.487769390863832, max viol: 1.5655002067796886 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.17779377102851868, valid regret : -0.1822286993265152 \n",
      "---------------------------------------iteration: 39\n",
      "l1 decision: 0.0745626911520958\n",
      "l1 weight: 0.16686077415943146\n",
      "avg viol: 1.4700886699574767, max viol: 1.5422310335561633 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.16715340316295624, valid regret : -0.16792044043540955 \n",
      "---------------------------------------iteration: 40\n",
      "l1 decision: 0.07722354680299759\n",
      "l1 weight: 0.16721905767917633\n",
      "avg viol: 1.5111068491911284, max viol: 1.6126383021473885 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1929475963115692, valid regret : -0.19581249356269836 \n",
      "---------------------------------------iteration: 41\n",
      "l1 decision: 0.07442723214626312\n",
      "l1 weight: 0.16507837176322937\n",
      "avg viol: 1.4757607019506396, max viol: 1.566564217908308 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1787356585264206, valid regret : -0.1442614495754242 \n",
      "---------------------------------------iteration: 42\n",
      "l1 decision: 0.07904345542192459\n",
      "l1 weight: 0.1669362187385559\n",
      "avg viol: 1.4841791128373005, max viol: 1.5717194080352783 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.18131832778453827, valid regret : -0.19205065071582794 \n",
      "---------------------------------------iteration: 43\n",
      "l1 decision: 0.07279811054468155\n",
      "l1 weight: 0.16584400832653046\n",
      "avg viol: 1.4489438415200493, max viol: 1.5418688794597983 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.17884936928749084, valid regret : -0.17202819883823395 \n",
      "---------------------------------------iteration: 44\n",
      "l1 decision: 0.07941818982362747\n",
      "l1 weight: 0.16461415588855743\n",
      "avg viol: 1.4996428898285377, max viol: 1.5994277792051435 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.18418094515800476, valid regret : -0.18705056607723236 \n",
      "---------------------------------------iteration: 45\n",
      "l1 decision: 0.07462462782859802\n",
      "l1 weight: 0.16489039361476898\n",
      "avg viol: 1.4872083215758902, max viol: 1.5627463951823302 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1794784665107727, valid regret : -0.16937527060508728 \n",
      "---------------------------------------iteration: 46\n",
      "l1 decision: 0.0812651589512825\n",
      "l1 weight: 0.16554002463817596\n",
      "avg viol: 1.5381060680391965, max viol: 1.636290648020804 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19829875230789185, valid regret : -0.20343130826950073 \n",
      "---------------------------------------iteration: 47\n",
      "l1 decision: 0.07265125960111618\n",
      "l1 weight: 0.16605760157108307\n",
      "avg viol: 1.452906920235837, max viol: 1.5507658866699785 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1769961416721344, valid regret : -0.17017972469329834 \n",
      "---------------------------------------iteration: 48\n",
      "l1 decision: 0.08311229944229126\n",
      "l1 weight: 0.1659545749425888\n",
      "avg viol: 1.5272088688216172, max viol: 1.6020209048874676 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1886601597070694, valid regret : -0.19990286231040955 \n",
      "---------------------------------------iteration: 49\n",
      "l1 decision: 0.07453092932701111\n",
      "l1 weight: 0.16561265289783478\n",
      "avg viol: 1.4886570726099309, max viol: 1.567982638720423 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1928720474243164, valid regret : -0.17343586683273315 \n",
      "---------------------------------------iteration: 50\n",
      "l1 decision: 0.08378411084413528\n",
      "l1 weight: 0.16631922125816345\n",
      "avg viol: 1.532910583295743, max viol: 1.5826058275997639 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19041654467582703, valid regret : -0.20075833797454834 \n",
      "---------------------------------------iteration: 51\n",
      "l1 decision: 0.07692001760005951\n",
      "l1 weight: 0.1661367267370224\n",
      "avg viol: 1.5264895149889344, max viol: 1.6052163266576827 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.18787075579166412, valid regret : -0.1932237297296524 \n",
      "---------------------------------------iteration: 52\n",
      "l1 decision: 0.08188710361719131\n",
      "l1 weight: 0.1662786602973938\n",
      "avg viol: 1.5433311341219815, max viol: 1.62051841057837 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.20325998961925507, valid regret : -0.21266943216323853 \n",
      "---------------------------------------iteration: 53\n",
      "l1 decision: 0.07571946084499359\n",
      "l1 weight: 0.16387172043323517\n",
      "avg viol: 1.5098710503231267, max viol: 1.6131987660191953 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19273601472377777, valid regret : -0.1733318567276001 \n",
      "---------------------------------------iteration: 54\n",
      "l1 decision: 0.08247827738523483\n",
      "l1 weight: 0.16686347126960754\n",
      "avg viol: 1.5277204128511948, max viol: 1.5818741655675694 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19408899545669556, valid regret : -0.21716251969337463 \n",
      "---------------------------------------iteration: 55\n",
      "l1 decision: 0.07774689048528671\n",
      "l1 weight: 0.16492152214050293\n",
      "avg viol: 1.5248763404949568, max viol: 1.6261994554661214 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.20579805970191956, valid regret : -0.21725048124790192 \n",
      "---------------------------------------iteration: 56\n",
      "l1 decision: 0.08091162145137787\n",
      "l1 weight: 0.16218040883541107\n",
      "avg viol: 1.5566000115318457, max viol: 1.6420723753981292 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.20266258716583252, valid regret : -0.21489328145980835 \n",
      "---------------------------------------iteration: 57\n",
      "l1 decision: 0.07625213265419006\n",
      "l1 weight: 0.16183575987815857\n",
      "avg viol: 1.521854623015388, max viol: 1.6165496367029846 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19195793569087982, valid regret : -0.18664667010307312 \n",
      "---------------------------------------iteration: 58\n",
      "l1 decision: 0.0825013816356659\n",
      "l1 weight: 0.16348738968372345\n",
      "avg viol: 1.5463244883960579, max viol: 1.603519773692824 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2018888145685196, valid regret : -0.21849481761455536 \n",
      "---------------------------------------iteration: 59\n",
      "l1 decision: 0.07605502009391785\n",
      "l1 weight: 0.16366082429885864\n",
      "avg viol: 1.5222090853253758, max viol: 1.6098130973987281 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1990719735622406, valid regret : -0.18374095857143402 \n",
      "---------------------------------------iteration: 60\n",
      "l1 decision: 0.08328500390052795\n",
      "l1 weight: 0.16383452713489532\n",
      "avg viol: 1.5479618256987306, max viol: 1.610027264105156 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1949925273656845, valid regret : -0.21759317815303802 \n",
      "---------------------------------------iteration: 61\n",
      "l1 decision: 0.07927980273962021\n",
      "l1 weight: 0.16438746452331543\n",
      "avg viol: 1.5703509825243964, max viol: 1.630252017173916 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21597124636173248, valid regret : -0.22420020401477814 \n",
      "---------------------------------------iteration: 62\n",
      "l1 decision: 0.08082424104213715\n",
      "l1 weight: 0.16261333227157593\n",
      "avg viol: 1.5791286420240067, max viol: 1.633903022389859 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2113523632287979, valid regret : -0.21367992460727692 \n",
      "---------------------------------------iteration: 63\n",
      "l1 decision: 0.07757846266031265\n",
      "l1 weight: 0.16391606628894806\n",
      "avg viol: 1.5474996946874306, max viol: 1.6244971688720398 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19725379347801208, valid regret : -0.20519030094146729 \n",
      "---------------------------------------iteration: 64\n",
      "l1 decision: 0.08333402872085571\n",
      "l1 weight: 0.16444404423236847\n",
      "avg viol: 1.572288071741932, max viol: 1.6325579462572932 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2118220329284668, valid regret : -0.21147824823856354 \n",
      "---------------------------------------iteration: 65\n",
      "l1 decision: 0.07556553184986115\n",
      "l1 weight: 0.16147570312023163\n",
      "avg viol: 1.5171065457636723, max viol: 1.6086038765497506 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19591444730758667, valid regret : -0.19393569231033325 \n",
      "---------------------------------------iteration: 66\n",
      "l1 decision: 0.08399561047554016\n",
      "l1 weight: 0.16530247032642365\n",
      "avg viol: 1.5539805875171442, max viol: 1.600052250083536 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2030310183763504, valid regret : -0.22085972130298615 \n",
      "---------------------------------------iteration: 67\n",
      "l1 decision: 0.07869825512170792\n",
      "l1 weight: 0.16209037601947784\n",
      "avg viol: 1.5574089257429296, max viol: 1.6268938858993351 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21536783874034882, valid regret : -0.21983039379119873 \n",
      "---------------------------------------iteration: 68\n",
      "l1 decision: 0.0807713195681572\n",
      "l1 weight: 0.1609622836112976\n",
      "avg viol: 1.5561955414881232, max viol: 1.6123677005525678 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.20492149889469147, valid regret : -0.21483078598976135 \n",
      "---------------------------------------iteration: 69\n",
      "l1 decision: 0.07801219820976257\n",
      "l1 weight: 0.1614384800195694\n",
      "avg viol: 1.5485921156144469, max viol: 1.6257888064719737 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19722691178321838, valid regret : -0.21494321525096893 \n",
      "---------------------------------------iteration: 70\n",
      "l1 decision: 0.08007879555225372\n",
      "l1 weight: 0.16079062223434448\n",
      "avg viol: 1.5647841092082673, max viol: 1.6174312350340188 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2096068412065506, valid regret : -0.22837668657302856 \n",
      "---------------------------------------iteration: 71\n",
      "l1 decision: 0.07865146547555923\n",
      "l1 weight: 0.16149625182151794\n",
      "avg viol: 1.555167334850994, max viol: 1.6282222403679043 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.20806559920310974, valid regret : -0.2152869552373886 \n",
      "---------------------------------------iteration: 72\n",
      "l1 decision: 0.07955972105264664\n",
      "l1 weight: 0.16069245338439941\n",
      "avg viol: 1.5651231057976838, max viol: 1.614610896911472 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.20609717071056366, valid regret : -0.22111797332763672 \n",
      "---------------------------------------iteration: 73\n",
      "l1 decision: 0.08069301396608353\n",
      "l1 weight: 0.1620454490184784\n",
      "avg viol: 1.5775028472585837, max viol: 1.633245391305536 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21649135649204254, valid regret : -0.21379375457763672 \n",
      "---------------------------------------iteration: 74\n",
      "l1 decision: 0.07655082643032074\n",
      "l1 weight: 0.16008475422859192\n",
      "avg viol: 1.531341987180058, max viol: 1.6073797915596515 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19825153052806854, valid regret : -0.2071991115808487 \n",
      "---------------------------------------iteration: 75\n",
      "l1 decision: 0.08285904675722122\n",
      "l1 weight: 0.16304710507392883\n",
      "avg viol: 1.5795870024315082, max viol: 1.6318460260517895 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19456098973751068, valid regret : -0.21210163831710815 \n",
      "---------------------------------------iteration: 76\n",
      "l1 decision: 0.07700890302658081\n",
      "l1 weight: 0.16089479625225067\n",
      "avg viol: 1.5375246403401253, max viol: 1.61073940503411 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.20865240693092346, valid regret : -0.20945897698402405 \n",
      "---------------------------------------iteration: 77\n",
      "l1 decision: 0.08272655308246613\n",
      "l1 weight: 0.16061356663703918\n",
      "avg viol: 1.5709967305796453, max viol: 1.6178752211853862 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.20277473330497742, valid regret : -0.21230943500995636 \n",
      "---------------------------------------iteration: 78\n",
      "l1 decision: 0.07775764167308807\n",
      "l1 weight: 0.16064557433128357\n",
      "avg viol: 1.553816884290427, max viol: 1.6257722228765488 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2131526917219162, valid regret : -0.22023281455039978 \n",
      "---------------------------------------iteration: 79\n",
      "l1 decision: 0.08301641047000885\n",
      "l1 weight: 0.16126881539821625\n",
      "avg viol: 1.5863528918713563, max viol: 1.6690152902156115 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21947170794010162, valid regret : -0.23496130108833313 \n",
      "---------------------------------------iteration: 80\n",
      "l1 decision: 0.07874739170074463\n",
      "l1 weight: 0.15790492296218872\n",
      "avg viol: 1.5747821701376232, max viol: 1.648763366509229 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21426498889923096, valid regret : -0.22418245673179626 \n",
      "---------------------------------------iteration: 81\n",
      "l1 decision: 0.08236562460660934\n",
      "l1 weight: 0.16003738343715668\n",
      "avg viol: 1.5966087289928692, max viol: 1.6613092964980751 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2084234207868576, valid regret : -0.21934781968593597 \n",
      "---------------------------------------iteration: 82\n",
      "l1 decision: 0.07781920582056046\n",
      "l1 weight: 0.15909653902053833\n",
      "avg viol: 1.5547107818976291, max viol: 1.6196895707398653 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21156826615333557, valid regret : -0.21026581525802612 \n",
      "---------------------------------------iteration: 83\n",
      "l1 decision: 0.08169247210025787\n",
      "l1 weight: 0.1608305126428604\n",
      "avg viol: 1.5702773953060387, max viol: 1.621100328862667 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2051347941160202, valid regret : -0.2186649888753891 \n",
      "---------------------------------------iteration: 84\n",
      "l1 decision: 0.0781104788184166\n",
      "l1 weight: 0.15892085433006287\n",
      "avg viol: 1.5611402946087765, max viol: 1.6239797580055892 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.20929968357086182, valid regret : -0.2045259326696396 \n",
      "---------------------------------------iteration: 85\n",
      "l1 decision: 0.07875631749629974\n",
      "l1 weight: 0.16005906462669373\n",
      "avg viol: 1.569865730603924, max viol: 1.623174480162561 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.20973211526870728, valid regret : -0.245272696018219 \n",
      "---------------------------------------iteration: 86\n",
      "l1 decision: 0.08085479587316513\n",
      "l1 weight: 0.15913833677768707\n",
      "avg viol: 1.6171356269947137, max viol: 1.6915911550167948 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.22527651488780975, valid regret : -0.2362062782049179 \n",
      "---------------------------------------iteration: 87\n",
      "l1 decision: 0.08363256603479385\n",
      "l1 weight: 0.16130639612674713\n",
      "avg viol: 1.62883872521983, max viol: 1.702768737100996 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2167765498161316, valid regret : -0.1881340593099594 \n",
      "---------------------------------------iteration: 88\n",
      "l1 decision: 0.07516811788082123\n",
      "l1 weight: 0.15887470543384552\n",
      "avg viol: 1.5026926803682, max viol: 1.6311949422815815 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19537048041820526, valid regret : -0.2313540279865265 \n",
      "---------------------------------------iteration: 89\n",
      "l1 decision: 0.08512819558382034\n",
      "l1 weight: 0.1589849442243576\n",
      "avg viol: 1.6130628894624532, max viol: 1.6818529263837263 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21642561256885529, valid regret : -0.17236533761024475 \n",
      "---------------------------------------iteration: 90\n",
      "l1 decision: 0.07538370043039322\n",
      "l1 weight: 0.15957553684711456\n",
      "avg viol: 1.4931901167542674, max viol: 1.6173265655525029 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.18987010419368744, valid regret : -0.21882730722427368 \n",
      "---------------------------------------iteration: 91\n",
      "l1 decision: 0.08446633070707321\n",
      "l1 weight: 0.15962113440036774\n",
      "avg viol: 1.5908690223714803, max viol: 1.695019397418946 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21446289122104645, valid regret : -0.18901322782039642 \n",
      "---------------------------------------iteration: 92\n",
      "l1 decision: 0.07572886347770691\n",
      "l1 weight: 0.15665355324745178\n",
      "avg viol: 1.5103981818631291, max viol: 1.6552178964484483 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.18829868733882904, valid regret : -0.24067100882530212 \n",
      "---------------------------------------iteration: 93\n",
      "l1 decision: 0.0845632553100586\n",
      "l1 weight: 0.15871815383434296\n",
      "avg viol: 1.6330649441466085, max viol: 1.7223814305616543 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21702373027801514, valid regret : -0.233083114027977 \n",
      "---------------------------------------iteration: 94\n",
      "l1 decision: 0.08017846941947937\n",
      "l1 weight: 0.15704196691513062\n",
      "avg viol: 1.5986292080965359, max viol: 1.6675792392343283 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.22533853352069855, valid regret : -0.2189970761537552 \n",
      "---------------------------------------iteration: 95\n",
      "l1 decision: 0.08570144325494766\n",
      "l1 weight: 0.15915203094482422\n",
      "avg viol: 1.5985888178378809, max viol: 1.6750808339565992 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21361297369003296, valid regret : -0.14612077176570892 \n",
      "---------------------------------------iteration: 96\n",
      "l1 decision: 0.07234328985214233\n",
      "l1 weight: 0.15793444216251373\n",
      "avg viol: 1.4480579960293836, max viol: 1.6287156818434596 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.1657433658838272, valid regret : -0.2454000860452652 \n",
      "---------------------------------------iteration: 97\n",
      "l1 decision: 0.08508647978305817\n",
      "l1 weight: 0.15965616703033447\n",
      "avg viol: 1.6478937827644404, max viol: 1.7275393507443368 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23790258169174194, valid regret : -0.22134031355381012 \n",
      "---------------------------------------iteration: 98\n",
      "l1 decision: 0.08021032810211182\n",
      "l1 weight: 0.15855373442173004\n",
      "avg viol: 1.5965139508078574, max viol: 1.6560866949148476 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.215793177485466, valid regret : -0.19968311488628387 \n",
      "---------------------------------------iteration: 99\n",
      "l1 decision: 0.0785549059510231\n",
      "l1 weight: 0.16082395613193512\n",
      "avg viol: 1.5692746840906329, max viol: 1.6417402040679008 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19729246199131012, valid regret : -0.23977214097976685 \n",
      "---------------------------------------iteration: 100\n",
      "l1 decision: 0.08548719435930252\n",
      "l1 weight: 0.15929152071475983\n",
      "avg viol: 1.6624826428855886, max viol: 1.7381925503723323 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24511998891830444, valid regret : -0.21771912276744843 \n",
      "---------------------------------------iteration: 101\n",
      "l1 decision: 0.08024899661540985\n",
      "l1 weight: 0.15727092325687408\n",
      "avg viol: 1.587815903738374, max viol: 1.6658330019563437 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21231691539287567, valid regret : -0.2213762402534485 \n",
      "---------------------------------------iteration: 102\n",
      "l1 decision: 0.08364406228065491\n",
      "l1 weight: 0.15845732390880585\n",
      "avg viol: 1.622575590077031, max viol: 1.7196780287194997 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.22928538918495178, valid regret : -0.18416377902030945 \n",
      "---------------------------------------iteration: 103\n",
      "l1 decision: 0.07667495310306549\n",
      "l1 weight: 0.1600126475095749\n",
      "avg viol: 1.5152201192628127, max viol: 1.6504170959815383 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19684818387031555, valid regret : -0.23514454066753387 \n",
      "---------------------------------------iteration: 104\n",
      "l1 decision: 0.08169199526309967\n",
      "l1 weight: 0.15761734545230865\n",
      "avg viol: 1.6109278581477702, max viol: 1.7069137542275712 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.22242936491966248, valid regret : -0.230012908577919 \n",
      "---------------------------------------iteration: 105\n",
      "l1 decision: 0.08157048374414444\n",
      "l1 weight: 0.15871259570121765\n",
      "avg viol: 1.6278006403124892, max viol: 1.7051377967000008 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.22148774564266205, valid regret : -0.23939822614192963 \n",
      "---------------------------------------iteration: 106\n",
      "l1 decision: 0.085551917552948\n",
      "l1 weight: 0.15804080665111542\n",
      "avg viol: 1.6439125270262593, max viol: 1.7466239528730512 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23557667434215546, valid regret : -0.22149555385112762 \n",
      "---------------------------------------iteration: 107\n",
      "l1 decision: 0.07945207506418228\n",
      "l1 weight: 0.15795345604419708\n",
      "avg viol: 1.582647711795289, max viol: 1.660676270723343 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21850311756134033, valid regret : -0.21916437149047852 \n",
      "---------------------------------------iteration: 108\n",
      "l1 decision: 0.08667154610157013\n",
      "l1 weight: 0.15782982110977173\n",
      "avg viol: 1.6118746489234035, max viol: 1.7014573141932487 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21663692593574524, valid regret : -0.19782041013240814 \n",
      "---------------------------------------iteration: 109\n",
      "l1 decision: 0.07701215893030167\n",
      "l1 weight: 0.158805251121521\n",
      "avg viol: 1.5354893680050736, max viol: 1.634220163221471 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2051813006401062, valid regret : -0.25175827741622925 \n",
      "---------------------------------------iteration: 110\n",
      "l1 decision: 0.08669645339250565\n",
      "l1 weight: 0.15919342637062073\n",
      "avg viol: 1.6744035940838513, max viol: 1.748664850834757 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23927940428256989, valid regret : -0.23077444732189178 \n",
      "---------------------------------------iteration: 111\n",
      "l1 decision: 0.08262963593006134\n",
      "l1 weight: 0.16067205369472504\n",
      "avg viol: 1.6401967056305147, max viol: 1.6991646499373019 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21929217875003815, valid regret : -0.24313025176525116 \n",
      "---------------------------------------iteration: 112\n",
      "l1 decision: 0.08477701991796494\n",
      "l1 weight: 0.1587916761636734\n",
      "avg viol: 1.657926482844632, max viol: 1.7402541770134121 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24517016112804413, valid regret : -0.22149740159511566 \n",
      "---------------------------------------iteration: 113\n",
      "l1 decision: 0.08010736107826233\n",
      "l1 weight: 0.1583152711391449\n",
      "avg viol: 1.588629070147872, max viol: 1.646564794704318 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.214625284075737, valid regret : -0.22070829570293427 \n",
      "---------------------------------------iteration: 114\n",
      "l1 decision: 0.08576962351799011\n",
      "l1 weight: 0.15954099595546722\n",
      "avg viol: 1.6145456488511991, max viol: 1.7056898190639913 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2281816303730011, valid regret : -0.20004382729530334 \n",
      "---------------------------------------iteration: 115\n",
      "l1 decision: 0.07900218665599823\n",
      "l1 weight: 0.1592879742383957\n",
      "avg viol: 1.5619204575172625, max viol: 1.6396401328966022 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.20874637365341187, valid regret : -0.2445252388715744 \n",
      "---------------------------------------iteration: 116\n",
      "l1 decision: 0.08383771032094955\n",
      "l1 weight: 0.1573157161474228\n",
      "avg viol: 1.6440770534687907, max viol: 1.7328031985089183 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23459626734256744, valid regret : -0.2167356312274933 \n",
      "---------------------------------------iteration: 117\n",
      "l1 decision: 0.08008114993572235\n",
      "l1 weight: 0.15917028486728668\n",
      "avg viol: 1.5931649816897697, max viol: 1.6567495120689273 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.20984424650669098, valid regret : -0.2457091361284256 \n",
      "---------------------------------------iteration: 118\n",
      "l1 decision: 0.08563520014286041\n",
      "l1 weight: 0.15832622349262238\n",
      "avg viol: 1.6592560814047466, max viol: 1.7518741637468338 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24347251653671265, valid regret : -0.22645120322704315 \n",
      "---------------------------------------iteration: 119\n",
      "l1 decision: 0.0802145004272461\n",
      "l1 weight: 0.16064585745334625\n",
      "avg viol: 1.6052364177443088, max viol: 1.6679259019438177 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2236384004354477, valid regret : -0.23758211731910706 \n",
      "---------------------------------------iteration: 120\n",
      "l1 decision: 0.08668022602796555\n",
      "l1 weight: 0.1588992476463318\n",
      "avg viol: 1.6558004338562022, max viol: 1.74397146794945 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23320095241069794, valid regret : -0.22371035814285278 \n",
      "---------------------------------------iteration: 121\n",
      "l1 decision: 0.0809163749217987\n",
      "l1 weight: 0.15970705449581146\n",
      "avg viol: 1.6159324890107383, max viol: 1.6895825755782425 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2295588105916977, valid regret : -0.23173680901527405 \n",
      "---------------------------------------iteration: 122\n",
      "l1 decision: 0.084614597260952\n",
      "l1 weight: 0.15981978178024292\n",
      "avg viol: 1.6177827145167976, max viol: 1.706267302040942 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21978580951690674, valid regret : -0.21419234573841095 \n",
      "---------------------------------------iteration: 123\n",
      "l1 decision: 0.08259899914264679\n",
      "l1 weight: 0.16171154379844666\n",
      "avg viol: 1.6095593539078255, max viol: 1.6679751183837652 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2053046077489853, valid regret : -0.23542027175426483 \n",
      "---------------------------------------iteration: 124\n",
      "l1 decision: 0.08404285460710526\n",
      "l1 weight: 0.16064244508743286\n",
      "avg viol: 1.6291856732440646, max viol: 1.6898283548653126 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2375757247209549, valid regret : -0.23666061460971832 \n",
      "---------------------------------------iteration: 125\n",
      "l1 decision: 0.08337143808603287\n",
      "l1 weight: 0.15924115478992462\n",
      "avg viol: 1.6404687098122668, max viol: 1.6901403721421957 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.22792203724384308, valid regret : -0.2483913004398346 \n",
      "---------------------------------------iteration: 126\n",
      "l1 decision: 0.08351238816976547\n",
      "l1 weight: 0.15973633527755737\n",
      "avg viol: 1.66777623699978, max viol: 1.7460363819263875 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25104695558547974, valid regret : -0.25124722719192505 \n",
      "---------------------------------------iteration: 127\n",
      "l1 decision: 0.08530301600694656\n",
      "l1 weight: 0.16032972931861877\n",
      "avg viol: 1.6814039749733638, max viol: 1.7505649933591485 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2560133934020996, valid regret : -0.2494928389787674 \n",
      "---------------------------------------iteration: 128\n",
      "l1 decision: 0.08547864854335785\n",
      "l1 weight: 0.15831764042377472\n",
      "avg viol: 1.6691030341136501, max viol: 1.7433850353118032 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24048687517642975, valid regret : -0.20313414931297302 \n",
      "---------------------------------------iteration: 129\n",
      "l1 decision: 0.07893744111061096\n",
      "l1 weight: 0.158457949757576\n",
      "avg viol: 1.5645828062358487, max viol: 1.636406602570787 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.19817087054252625, valid regret : -0.2395310252904892 \n",
      "---------------------------------------iteration: 130\n",
      "l1 decision: 0.08379204571247101\n",
      "l1 weight: 0.1587466299533844\n",
      "avg viol: 1.6611126999231056, max viol: 1.7393400212749839 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24103330075740814, valid regret : -0.25167620182037354 \n",
      "---------------------------------------iteration: 131\n",
      "l1 decision: 0.0830974206328392\n",
      "l1 weight: 0.16046996414661407\n",
      "avg viol: 1.6529976969395648, max viol: 1.75397501536645 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24393229186534882, valid regret : -0.24703727662563324 \n",
      "---------------------------------------iteration: 132\n",
      "l1 decision: 0.08557772636413574\n",
      "l1 weight: 0.1582196205854416\n",
      "avg viol: 1.6965325016500719, max viol: 1.7659164885990322 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2457849085330963, valid regret : -0.2466869354248047 \n",
      "---------------------------------------iteration: 133\n",
      "l1 decision: 0.08606157451868057\n",
      "l1 weight: 0.1597682535648346\n",
      "avg viol: 1.6815693182992981, max viol: 1.7461439329199493 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25269046425819397, valid regret : -0.21997958421707153 \n",
      "---------------------------------------iteration: 134\n",
      "l1 decision: 0.07993433624505997\n",
      "l1 weight: 0.15834781527519226\n",
      "avg viol: 1.5884262205596316, max viol: 1.6404412067495286 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21164017915725708, valid regret : -0.24197795987129211 \n",
      "---------------------------------------iteration: 135\n",
      "l1 decision: 0.08394772559404373\n",
      "l1 weight: 0.16136294603347778\n",
      "avg viol: 1.6716789611044804, max viol: 1.7211689734831452 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23172485828399658, valid regret : -0.2505446672439575 \n",
      "---------------------------------------iteration: 136\n",
      "l1 decision: 0.08403420448303223\n",
      "l1 weight: 0.15974770486354828\n",
      "avg viol: 1.678918421958806, max viol: 1.7431688161450438 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2556876838207245, valid regret : -0.2594122886657715 \n",
      "---------------------------------------iteration: 137\n",
      "l1 decision: 0.08562371879816055\n",
      "l1 weight: 0.15962858498096466\n",
      "avg viol: 1.6912615253805416, max viol: 1.7612553462386131 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24938639998435974, valid regret : -0.24353626370429993 \n",
      "---------------------------------------iteration: 138\n",
      "l1 decision: 0.08387357741594315\n",
      "l1 weight: 0.15912453830242157\n",
      "avg viol: 1.6704617004917237, max viol: 1.7376184577587992 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2496853619813919, valid regret : -0.23590782284736633 \n",
      "---------------------------------------iteration: 139\n",
      "l1 decision: 0.08370158076286316\n",
      "l1 weight: 0.16051603853702545\n",
      "avg viol: 1.646085883609485, max viol: 1.7050132172880694 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24026037752628326, valid regret : -0.23003150522708893 \n",
      "---------------------------------------iteration: 140\n",
      "l1 decision: 0.0817197859287262\n",
      "l1 weight: 0.15770959854125977\n",
      "avg viol: 1.6207822974183363, max viol: 1.677121479762718 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.22211533784866333, valid regret : -0.247141033411026 \n",
      "---------------------------------------iteration: 141\n",
      "l1 decision: 0.08406704664230347\n",
      "l1 weight: 0.15977999567985535\n",
      "avg viol: 1.6744286034099058, max viol: 1.7387872489634901 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23782579600811005, valid regret : -0.25023478269577026 \n",
      "---------------------------------------iteration: 142\n",
      "l1 decision: 0.0847906842827797\n",
      "l1 weight: 0.15850411355495453\n",
      "avg viol: 1.6761481561220717, max viol: 1.7552779850084335 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2512238025665283, valid regret : -0.24674519896507263 \n",
      "---------------------------------------iteration: 143\n",
      "l1 decision: 0.08358007669448853\n",
      "l1 weight: 0.16054755449295044\n",
      "avg viol: 1.6512003826757427, max viol: 1.7323041501222178 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2368931919336319, valid regret : -0.21323612332344055 \n",
      "---------------------------------------iteration: 144\n",
      "l1 decision: 0.08107223361730576\n",
      "l1 weight: 0.1574927121400833\n",
      "avg viol: 1.6009316105750622, max viol: 1.668371660867706 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21481338143348694, valid regret : -0.24693803489208221 \n",
      "---------------------------------------iteration: 145\n",
      "l1 decision: 0.08409826457500458\n",
      "l1 weight: 0.15995754301548004\n",
      "avg viol: 1.6828395690047182, max viol: 1.743711125513073 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25198301672935486, valid regret : -0.2550886869430542 \n",
      "---------------------------------------iteration: 146\n",
      "l1 decision: 0.08593438565731049\n",
      "l1 weight: 0.15941782295703888\n",
      "avg viol: 1.6851966361122321, max viol: 1.7542262078495696 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24616184830665588, valid regret : -0.24035687744617462 \n",
      "---------------------------------------iteration: 147\n",
      "l1 decision: 0.0835682600736618\n",
      "l1 weight: 0.1619427353143692\n",
      "avg viol: 1.6688068530084275, max viol: 1.7279069032520056 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23126505315303802, valid regret : -0.24413633346557617 \n",
      "---------------------------------------iteration: 148\n",
      "l1 decision: 0.08631861209869385\n",
      "l1 weight: 0.1597568392753601\n",
      "avg viol: 1.6681818168266909, max viol: 1.7509217886254191 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24740687012672424, valid regret : -0.249873086810112 \n",
      "---------------------------------------iteration: 149\n",
      "l1 decision: 0.0833851769566536\n",
      "l1 weight: 0.159158393740654\n",
      "avg viol: 1.6661604423442622, max viol: 1.7381520722992718 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24204418063163757, valid regret : -0.2360115796327591 \n",
      "---------------------------------------iteration: 150\n",
      "l1 decision: 0.08799158781766891\n",
      "l1 weight: 0.15887238085269928\n",
      "avg viol: 1.6647256489665596, max viol: 1.7493165009655058 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2435399889945984, valid regret : -0.21124336123466492 \n",
      "---------------------------------------iteration: 151\n",
      "l1 decision: 0.07865871489048004\n",
      "l1 weight: 0.15929575264453888\n",
      "avg viol: 1.576805738225812, max viol: 1.6499914980959147 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2174527496099472, valid regret : -0.24974089860916138 \n",
      "---------------------------------------iteration: 152\n",
      "l1 decision: 0.08626185357570648\n",
      "l1 weight: 0.15862752497196198\n",
      "avg viol: 1.6775319960699198, max viol: 1.7371281913947314 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2430054247379303, valid regret : -0.24684077501296997 \n",
      "---------------------------------------iteration: 153\n",
      "l1 decision: 0.0841636136174202\n",
      "l1 weight: 0.1599626988172531\n",
      "avg viol: 1.6790636742475908, max viol: 1.746247859671712 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2389434278011322, valid regret : -0.25976675748825073 \n",
      "---------------------------------------iteration: 154\n",
      "l1 decision: 0.08518967777490616\n",
      "l1 weight: 0.15871202945709229\n",
      "avg viol: 1.69959115715581, max viol: 1.7702828429173678 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2586909532546997, valid regret : -0.26299822330474854 \n",
      "---------------------------------------iteration: 155\n",
      "l1 decision: 0.0860714539885521\n",
      "l1 weight: 0.15997594594955444\n",
      "avg viol: 1.698523153431015, max viol: 1.7699653013260104 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25596097111701965, valid regret : -0.24064624309539795 \n",
      "---------------------------------------iteration: 156\n",
      "l1 decision: 0.08445222675800323\n",
      "l1 weight: 0.15803740918636322\n",
      "avg viol: 1.6723308362448006, max viol: 1.7462262699846178 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2410455346107483, valid regret : -0.21282429993152618 \n",
      "---------------------------------------iteration: 157\n",
      "l1 decision: 0.08257491886615753\n",
      "l1 weight: 0.15918587148189545\n",
      "avg viol: 1.6005705692869379, max viol: 1.6402933490462601 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21629028022289276, valid regret : -0.2525487542152405 \n",
      "---------------------------------------iteration: 158\n",
      "l1 decision: 0.08321783691644669\n",
      "l1 weight: 0.1592528373003006\n",
      "avg viol: 1.669540781371761, max viol: 1.74827636545524 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24482683837413788, valid regret : -0.25162190198898315 \n",
      "---------------------------------------iteration: 159\n",
      "l1 decision: 0.08771322667598724\n",
      "l1 weight: 0.16194631159305573\n",
      "avg viol: 1.7114292210014537, max viol: 1.7629060947801918 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24127116799354553, valid regret : -0.23993749916553497 \n",
      "---------------------------------------iteration: 160\n",
      "l1 decision: 0.08131326735019684\n",
      "l1 weight: 0.15945063531398773\n",
      "avg viol: 1.6336422622879037, max viol: 1.7341670887544751 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24373668432235718, valid regret : -0.23079492151737213 \n",
      "---------------------------------------iteration: 161\n",
      "l1 decision: 0.09022319316864014\n",
      "l1 weight: 0.1598014086484909\n",
      "avg viol: 1.6407715412281687, max viol: 1.686434583272785 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.21910716593265533, valid regret : -0.21510867774486542 \n",
      "---------------------------------------iteration: 162\n",
      "l1 decision: 0.07874682545661926\n",
      "l1 weight: 0.15931741893291473\n",
      "avg viol: 1.5796709499915595, max viol: 1.626839643344283 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2247423678636551, valid regret : -0.24259334802627563 \n",
      "---------------------------------------iteration: 163\n",
      "l1 decision: 0.08803079277276993\n",
      "l1 weight: 0.16093361377716064\n",
      "avg viol: 1.6806701669539326, max viol: 1.7419897634536028 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24788574874401093, valid regret : -0.24001078307628632 \n",
      "---------------------------------------iteration: 164\n",
      "l1 decision: 0.08152324706315994\n",
      "l1 weight: 0.15833456814289093\n",
      "avg viol: 1.636139835601207, max viol: 1.702034328598529 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2325834035873413, valid regret : -0.2464715838432312 \n",
      "---------------------------------------iteration: 165\n",
      "l1 decision: 0.08548004925251007\n",
      "l1 weight: 0.16057053208351135\n",
      "avg viol: 1.6890532104624436, max viol: 1.748664224287495 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23801960051059723, valid regret : -0.24285757541656494 \n",
      "---------------------------------------iteration: 166\n",
      "l1 decision: 0.08311628550291061\n",
      "l1 weight: 0.15821224451065063\n",
      "avg viol: 1.6584964386356114, max viol: 1.7351375333964825 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24280527234077454, valid regret : -0.24750621616840363 \n",
      "---------------------------------------iteration: 167\n",
      "l1 decision: 0.08452856540679932\n",
      "l1 weight: 0.1608544886112213\n",
      "avg viol: 1.6735887002639356, max viol: 1.7382597643882036 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24435974657535553, valid regret : -0.22912991046905518 \n",
      "---------------------------------------iteration: 168\n",
      "l1 decision: 0.08208416402339935\n",
      "l1 weight: 0.1575300097465515\n",
      "avg viol: 1.6376362354739102, max viol: 1.7101474655792117 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.22801148891448975, valid regret : -0.2502446472644806 \n",
      "---------------------------------------iteration: 169\n",
      "l1 decision: 0.08466886729001999\n",
      "l1 weight: 0.1610746830701828\n",
      "avg viol: 1.6929997550560802, max viol: 1.7378948940895498 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2552429437637329, valid regret : -0.24908065795898438 \n",
      "---------------------------------------iteration: 170\n",
      "l1 decision: 0.08402562141418457\n",
      "l1 weight: 0.1589915156364441\n",
      "avg viol: 1.6770757748116738, max viol: 1.736404283437878 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2421896904706955, valid regret : -0.24145935475826263 \n",
      "---------------------------------------iteration: 171\n",
      "l1 decision: 0.08489435911178589\n",
      "l1 weight: 0.16236217319965363\n",
      "avg viol: 1.6811778866651002, max viol: 1.7366513693705201 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23220404982566833, valid regret : -0.23708324134349823 \n",
      "---------------------------------------iteration: 172\n",
      "l1 decision: 0.0823495015501976\n",
      "l1 weight: 0.15911966562271118\n",
      "avg viol: 1.6442515385209118, max viol: 1.715510631678626 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23729680478572845, valid regret : -0.2529435157775879 \n",
      "---------------------------------------iteration: 173\n",
      "l1 decision: 0.08496472984552383\n",
      "l1 weight: 0.15962176024913788\n",
      "avg viol: 1.6870105442396015, max viol: 1.7383718034252524 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24561099708080292, valid regret : -0.23834510147571564 \n",
      "---------------------------------------iteration: 174\n",
      "l1 decision: 0.08287501335144043\n",
      "l1 weight: 0.15848328173160553\n",
      "avg viol: 1.6616648635274032, max viol: 1.737998491153121 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24588119983673096, valid regret : -0.2534485161304474 \n",
      "---------------------------------------iteration: 175\n",
      "l1 decision: 0.08576591312885284\n",
      "l1 weight: 0.16056211292743683\n",
      "avg viol: 1.6870341453776927, max viol: 1.752853391924873 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2561214864253998, valid regret : -0.24155816435813904 \n",
      "---------------------------------------iteration: 176\n",
      "l1 decision: 0.08255930244922638\n",
      "l1 weight: 0.15809312462806702\n",
      "avg viol: 1.6467316619586199, max viol: 1.730137252714485 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23367181420326233, valid regret : -0.2504265308380127 \n",
      "---------------------------------------iteration: 177\n",
      "l1 decision: 0.08472222089767456\n",
      "l1 weight: 0.15899239480495453\n",
      "avg viol: 1.684178706589737, max viol: 1.7570959203876555 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23941919207572937, valid regret : -0.24898985028266907 \n",
      "---------------------------------------iteration: 178\n",
      "l1 decision: 0.08318358659744263\n",
      "l1 weight: 0.15796460211277008\n",
      "avg viol: 1.668466929263086, max viol: 1.7449139198288321 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2483828365802765, valid regret : -0.25354599952697754 \n",
      "---------------------------------------iteration: 179\n",
      "l1 decision: 0.08578649908304214\n",
      "l1 weight: 0.1600968986749649\n",
      "avg viol: 1.6807860116072697, max viol: 1.7599587412551045 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2469368726015091, valid regret : -0.23294572532176971 \n",
      "---------------------------------------iteration: 180\n",
      "l1 decision: 0.08250921219587326\n",
      "l1 weight: 0.15708453953266144\n",
      "avg viol: 1.6412321876798524, max viol: 1.7110711899586022 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23117639124393463, valid regret : -0.25596189498901367 \n",
      "---------------------------------------iteration: 181\n",
      "l1 decision: 0.08511320501565933\n",
      "l1 weight: 0.1595773547887802\n",
      "avg viol: 1.703839692516758, max viol: 1.765833674930036 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2608298361301422, valid regret : -0.2594878673553467 \n",
      "---------------------------------------iteration: 182\n",
      "l1 decision: 0.08557093143463135\n",
      "l1 weight: 0.15878088772296906\n",
      "avg viol: 1.7064889545022743, max viol: 1.7691154620260932 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2537815570831299, valid regret : -0.2457260638475418 \n",
      "---------------------------------------iteration: 183\n",
      "l1 decision: 0.08587228506803513\n",
      "l1 weight: 0.16154205799102783\n",
      "avg viol: 1.6861901169235352, max viol: 1.7476417138241231 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23580563068389893, valid regret : -0.23008354008197784 \n",
      "---------------------------------------iteration: 184\n",
      "l1 decision: 0.08292493969202042\n",
      "l1 weight: 0.15905125439167023\n",
      "avg viol: 1.6348467957344837, max viol: 1.6950683898758143 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23335805535316467, valid regret : -0.25451943278312683 \n",
      "---------------------------------------iteration: 185\n",
      "l1 decision: 0.0845780298113823\n",
      "l1 weight: 0.15854424238204956\n",
      "avg viol: 1.6879802059644136, max viol: 1.7541297001298517 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24795997142791748, valid regret : -0.25070467591285706 \n",
      "---------------------------------------iteration: 186\n",
      "l1 decision: 0.08518864214420319\n",
      "l1 weight: 0.15827937424182892\n",
      "avg viol: 1.685453721617232, max viol: 1.763216977706179 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2567976713180542, valid regret : -0.25639739632606506 \n",
      "---------------------------------------iteration: 187\n",
      "l1 decision: 0.08559852838516235\n",
      "l1 weight: 0.1598072648048401\n",
      "avg viol: 1.7038494096009527, max viol: 1.7689814904588275 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26293709874153137, valid regret : -0.25633952021598816 \n",
      "---------------------------------------iteration: 188\n",
      "l1 decision: 0.08537459373474121\n",
      "l1 weight: 0.15755027532577515\n",
      "avg viol: 1.6778286833688616, max viol: 1.766376243205741 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24642905592918396, valid regret : -0.24630247056484222 \n",
      "---------------------------------------iteration: 189\n",
      "l1 decision: 0.08359869569540024\n",
      "l1 weight: 0.15849755704402924\n",
      "avg viol: 1.6762061492691283, max viol: 1.737964870641008 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23776474595069885, valid regret : -0.2513255178928375 \n",
      "---------------------------------------iteration: 190\n",
      "l1 decision: 0.08633111417293549\n",
      "l1 weight: 0.15860724449157715\n",
      "avg viol: 1.6800166641682153, max viol: 1.7641962487250566 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25143787264823914, valid regret : -0.2386118471622467 \n",
      "---------------------------------------iteration: 191\n",
      "l1 decision: 0.08172034472227097\n",
      "l1 weight: 0.15951263904571533\n",
      "avg viol: 1.6384765008999966, max viol: 1.6836655244696885 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23575538396835327, valid regret : -0.2502012550830841 \n",
      "---------------------------------------iteration: 192\n",
      "l1 decision: 0.08634912222623825\n",
      "l1 weight: 0.1577303111553192\n",
      "avg viol: 1.690090034927125, max viol: 1.7671651616692543 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24703842401504517, valid regret : -0.2507355511188507 \n",
      "---------------------------------------iteration: 193\n",
      "l1 decision: 0.08396074175834656\n",
      "l1 weight: 0.15967608988285065\n",
      "avg viol: 1.687099911934638, max viol: 1.7381514897570014 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25542858242988586, valid regret : -0.2621054947376251 \n",
      "---------------------------------------iteration: 194\n",
      "l1 decision: 0.0866842120885849\n",
      "l1 weight: 0.15888775885105133\n",
      "avg viol: 1.712939896361204, max viol: 1.7704518348909914 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25588876008987427, valid regret : -0.25671637058258057 \n",
      "---------------------------------------iteration: 195\n",
      "l1 decision: 0.08581893891096115\n",
      "l1 weight: 0.16124936938285828\n",
      "avg viol: 1.7172792481805663, max viol: 1.772452998207882 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24772033095359802, valid regret : -0.2611573040485382 \n",
      "---------------------------------------iteration: 196\n",
      "l1 decision: 0.0859784334897995\n",
      "l1 weight: 0.15869681537151337\n",
      "avg viol: 1.707480460582301, max viol: 1.7784315514727496 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26462578773498535, valid regret : -0.2605394721031189 \n",
      "---------------------------------------iteration: 197\n",
      "l1 decision: 0.08653109520673752\n",
      "l1 weight: 0.15870946645736694\n",
      "avg viol: 1.7089248406948536, max viol: 1.7647060989984311 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2528594136238098, valid regret : -0.22411467134952545 \n",
      "---------------------------------------iteration: 198\n",
      "l1 decision: 0.08199427276849747\n",
      "l1 weight: 0.1571509838104248\n",
      "avg viol: 1.624512068257318, max viol: 1.685726893832907 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23083961009979248, valid regret : -0.25998198986053467 \n",
      "---------------------------------------iteration: 199\n",
      "l1 decision: 0.08582092076539993\n",
      "l1 weight: 0.1589893400669098\n",
      "avg viol: 1.7081530375566216, max viol: 1.7679484514519572 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26475727558135986, valid regret : -0.26149338483810425 \n",
      "---------------------------------------iteration: 200\n",
      "l1 decision: 0.08519475162029266\n",
      "l1 weight: 0.15729890763759613\n",
      "avg viol: 1.697356220467518, max viol: 1.7774517112411559 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25458890199661255, valid regret : -0.25526976585388184 \n",
      "---------------------------------------iteration: 201\n",
      "l1 decision: 0.08539381623268127\n",
      "l1 weight: 0.1588570773601532\n",
      "avg viol: 1.705032776244916, max viol: 1.7685700100846589 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24587108194828033, valid regret : -0.2543925642967224 \n",
      "---------------------------------------iteration: 202\n",
      "l1 decision: 0.08588001877069473\n",
      "l1 weight: 0.1579550802707672\n",
      "avg viol: 1.685355374268256, max viol: 1.769656200427562 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.254373162984848, valid regret : -0.24737827479839325 \n",
      "---------------------------------------iteration: 203\n",
      "l1 decision: 0.08319763839244843\n",
      "l1 weight: 0.15888991951942444\n",
      "avg viol: 1.6611703456903342, max viol: 1.7208544861059636 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2431616634130478, valid regret : -0.24579904973506927 \n",
      "---------------------------------------iteration: 204\n",
      "l1 decision: 0.08735646307468414\n",
      "l1 weight: 0.15693597495555878\n",
      "avg viol: 1.6860043829592177, max viol: 1.758106854511425 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24395936727523804, valid regret : -0.23144134879112244 \n",
      "---------------------------------------iteration: 205\n",
      "l1 decision: 0.08062752336263657\n",
      "l1 weight: 0.15957002341747284\n",
      "avg viol: 1.6201899379940006, max viol: 1.65993677591905 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23568902909755707, valid regret : -0.2545679211616516 \n",
      "---------------------------------------iteration: 206\n",
      "l1 decision: 0.08740933984518051\n",
      "l1 weight: 0.15936993062496185\n",
      "avg viol: 1.6924380807729904, max viol: 1.7492584872525185 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24651668965816498, valid regret : -0.23803317546844482 \n",
      "---------------------------------------iteration: 207\n",
      "l1 decision: 0.08287520706653595\n",
      "l1 weight: 0.16080322861671448\n",
      "avg viol: 1.6649122375843581, max viol: 1.7178330458700657 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2289821058511734, valid regret : -0.25334233045578003 \n",
      "---------------------------------------iteration: 208\n",
      "l1 decision: 0.08559567481279373\n",
      "l1 weight: 0.15894843637943268\n",
      "avg viol: 1.694543407469464, max viol: 1.7417765410500579 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2571025490760803, valid regret : -0.24924308061599731 \n",
      "---------------------------------------iteration: 209\n",
      "l1 decision: 0.08319167792797089\n",
      "l1 weight: 0.1569427102804184\n",
      "avg viol: 1.6684801377955591, max viol: 1.7146282473113388 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24139542877674103, valid regret : -0.2527436912059784 \n",
      "---------------------------------------iteration: 210\n",
      "l1 decision: 0.08533627539873123\n",
      "l1 weight: 0.15816491842269897\n",
      "avg viol: 1.7005623391367408, max viol: 1.7619580200407654 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2594987452030182, valid regret : -0.25479280948638916 \n",
      "---------------------------------------iteration: 211\n",
      "l1 decision: 0.08436792343854904\n",
      "l1 weight: 0.15874449908733368\n",
      "avg viol: 1.686243634869461, max viol: 1.7471603276208043 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2591898739337921, valid regret : -0.2605435848236084 \n",
      "---------------------------------------iteration: 212\n",
      "l1 decision: 0.08582831174135208\n",
      "l1 weight: 0.15804743766784668\n",
      "avg viol: 1.700655961727025, max viol: 1.760305777657777 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2513783872127533, valid regret : -0.24471935629844666 \n",
      "---------------------------------------iteration: 213\n",
      "l1 decision: 0.0836276113986969\n",
      "l1 weight: 0.15811794996261597\n",
      "avg viol: 1.6719573687424418, max viol: 1.7429237300530076 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23618441820144653, valid regret : -0.2582117021083832 \n",
      "---------------------------------------iteration: 214\n",
      "l1 decision: 0.08544588088989258\n",
      "l1 weight: 0.15849772095680237\n",
      "avg viol: 1.7033386527188121, max viol: 1.7625065767788328 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2577991187572479, valid regret : -0.25937846302986145 \n",
      "---------------------------------------iteration: 215\n",
      "l1 decision: 0.085057333111763\n",
      "l1 weight: 0.15883874893188477\n",
      "avg viol: 1.6844399016088574, max viol: 1.7675110073760152 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25243493914604187, valid regret : -0.24442973732948303 \n",
      "---------------------------------------iteration: 216\n",
      "l1 decision: 0.08581674844026566\n",
      "l1 weight: 0.15702520310878754\n",
      "avg viol: 1.6861770269821863, max viol: 1.7536110747605562 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24551445245742798, valid regret : -0.23236283659934998 \n",
      "---------------------------------------iteration: 217\n",
      "l1 decision: 0.08200861513614655\n",
      "l1 weight: 0.15842582285404205\n",
      "avg viol: 1.6343515966145787, max viol: 1.687337351962924 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2335018664598465, valid regret : -0.2584056556224823 \n",
      "---------------------------------------iteration: 218\n",
      "l1 decision: 0.08462576568126678\n",
      "l1 weight: 0.15853571891784668\n",
      "avg viol: 1.6976655909779947, max viol: 1.7566502019762993 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2513718903064728, valid regret : -0.2552432119846344 \n",
      "---------------------------------------iteration: 219\n",
      "l1 decision: 0.08584421873092651\n",
      "l1 weight: 0.16075126826763153\n",
      "avg viol: 1.7105485215195222, max viol: 1.7690922617912292 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24655616283416748, valid regret : -0.26443421840667725 \n",
      "---------------------------------------iteration: 220\n",
      "l1 decision: 0.08574114739894867\n",
      "l1 weight: 0.15805020928382874\n",
      "avg viol: 1.7140984819006189, max viol: 1.7809180617332458 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2653207778930664, valid regret : -0.2628072500228882 \n",
      "---------------------------------------iteration: 221\n",
      "l1 decision: 0.08601629734039307\n",
      "l1 weight: 0.15751585364341736\n",
      "avg viol: 1.7071599998748934, max viol: 1.7733799864072353 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2548442780971527, valid regret : -0.25044703483581543 \n",
      "---------------------------------------iteration: 222\n",
      "l1 decision: 0.08502190560102463\n",
      "l1 weight: 0.15804161131381989\n",
      "avg viol: 1.694117356042043, max viol: 1.7496524704620242 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2567782998085022, valid regret : -0.2519841194152832 \n",
      "---------------------------------------iteration: 223\n",
      "l1 decision: 0.08456647396087646\n",
      "l1 weight: 0.1585300862789154\n",
      "avg viol: 1.6849601291539147, max viol: 1.7461488418048248 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25712600350379944, valid regret : -0.26120224595069885 \n",
      "---------------------------------------iteration: 224\n",
      "l1 decision: 0.08641321957111359\n",
      "l1 weight: 0.15764006972312927\n",
      "avg viol: 1.7031764342088718, max viol: 1.7630685435142368 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25279000401496887, valid regret : -0.23484653234481812 \n",
      "---------------------------------------iteration: 225\n",
      "l1 decision: 0.0821077898144722\n",
      "l1 weight: 0.1579558551311493\n",
      "avg viol: 1.6474212489259663, max viol: 1.71810410823673 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2283286154270172, valid regret : -0.26149457693099976 \n",
      "---------------------------------------iteration: 226\n",
      "l1 decision: 0.08578865230083466\n",
      "l1 weight: 0.15796619653701782\n",
      "avg viol: 1.7108969142334536, max viol: 1.770679121138528 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2609008550643921, valid regret : -0.26370713114738464 \n",
      "---------------------------------------iteration: 227\n",
      "l1 decision: 0.08523343503475189\n",
      "l1 weight: 0.15893977880477905\n",
      "avg viol: 1.6956440362724243, max viol: 1.7776798391714692 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2573983669281006, valid regret : -0.25085175037384033 \n",
      "---------------------------------------iteration: 228\n",
      "l1 decision: 0.08539426326751709\n",
      "l1 weight: 0.15662215650081635\n",
      "avg viol: 1.6978118183847983, max viol: 1.756738604977727 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24993032217025757, valid regret : -0.25642117857933044 \n",
      "---------------------------------------iteration: 229\n",
      "l1 decision: 0.08577477931976318\n",
      "l1 weight: 0.1589883416891098\n",
      "avg viol: 1.6937755639571697, max viol: 1.773495995090343 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2586922347545624, valid regret : -0.24273578822612762 \n",
      "---------------------------------------iteration: 230\n",
      "l1 decision: 0.08323763310909271\n",
      "l1 weight: 0.15764154493808746\n",
      "avg viol: 1.6608727682108293, max viol: 1.7017938955686986 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23624974489212036, valid regret : -0.25584110617637634 \n",
      "---------------------------------------iteration: 231\n",
      "l1 decision: 0.08508972823619843\n",
      "l1 weight: 0.1602081060409546\n",
      "avg viol: 1.7067072609477327, max viol: 1.7713970355689526 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24633361399173737, valid regret : -0.2641834318637848 \n",
      "---------------------------------------iteration: 232\n",
      "l1 decision: 0.08620660752058029\n",
      "l1 weight: 0.15843574702739716\n",
      "avg viol: 1.7191680158668896, max viol: 1.7771531840553507 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2658538520336151, valid regret : -0.2630140781402588 \n",
      "---------------------------------------iteration: 233\n",
      "l1 decision: 0.08519712090492249\n",
      "l1 weight: 0.15786422789096832\n",
      "avg viol: 1.7087785012612584, max viol: 1.7662258928176016 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25671303272247314, valid regret : -0.25385582447052 \n",
      "---------------------------------------iteration: 234\n",
      "l1 decision: 0.08641176670789719\n",
      "l1 weight: 0.15748442709445953\n",
      "avg viol: 1.702801463820142, max viol: 1.7716563541907817 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25980570912361145, valid regret : -0.24218952655792236 \n",
      "---------------------------------------iteration: 235\n",
      "l1 decision: 0.0822937935590744\n",
      "l1 weight: 0.1577373594045639\n",
      "avg viol: 1.64887621506874, max viol: 1.7159344446845353 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.248839870095253, valid regret : -0.2623332142829895 \n",
      "---------------------------------------iteration: 236\n",
      "l1 decision: 0.08531197905540466\n",
      "l1 weight: 0.15782530605793\n",
      "avg viol: 1.7049872793344547, max viol: 1.7711393018253148 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25363850593566895, valid regret : -0.2551845610141754 \n",
      "---------------------------------------iteration: 237\n",
      "l1 decision: 0.08488722890615463\n",
      "l1 weight: 0.1580355167388916\n",
      "avg viol: 1.698354020503466, max viol: 1.7680758598726243 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.247462198138237, valid regret : -0.25942084193229675 \n",
      "---------------------------------------iteration: 238\n",
      "l1 decision: 0.08575154840946198\n",
      "l1 weight: 0.1580844670534134\n",
      "avg viol: 1.7049202078924282, max viol: 1.7720711277797818 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.258992463350296, valid regret : -0.24578814208507538 \n",
      "---------------------------------------iteration: 239\n",
      "l1 decision: 0.08369040489196777\n",
      "l1 weight: 0.1584053784608841\n",
      "avg viol: 1.6583696274360409, max viol: 1.7147388856392354 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24060901999473572, valid regret : -0.2560521364212036 \n",
      "---------------------------------------iteration: 240\n",
      "l1 decision: 0.08493397384881973\n",
      "l1 weight: 0.15626682341098785\n",
      "avg viol: 1.7035479414850123, max viol: 1.770637706387788 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25425198674201965, valid regret : -0.26420190930366516 \n",
      "---------------------------------------iteration: 241\n",
      "l1 decision: 0.08695036917924881\n",
      "l1 weight: 0.1589001566171646\n",
      "avg viol: 1.7200111867842498, max viol: 1.7791695947526023 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26495540142059326, valid regret : -0.2567039132118225 \n",
      "---------------------------------------iteration: 242\n",
      "l1 decision: 0.08376602828502655\n",
      "l1 weight: 0.15809407830238342\n",
      "avg viol: 1.68181791463634, max viol: 1.7257720618508756 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2510530948638916, valid regret : -0.2507670223712921 \n",
      "---------------------------------------iteration: 243\n",
      "l1 decision: 0.08777526021003723\n",
      "l1 weight: 0.16084544360637665\n",
      "avg viol: 1.70057091689785, max viol: 1.7559640360996127 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23782703280448914, valid regret : -0.24018697440624237 \n",
      "---------------------------------------iteration: 244\n",
      "l1 decision: 0.08138316869735718\n",
      "l1 weight: 0.1582268476486206\n",
      "avg viol: 1.6333422354540743, max viol: 1.6743675917387009 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24375014007091522, valid regret : -0.25860917568206787 \n",
      "---------------------------------------iteration: 245\n",
      "l1 decision: 0.08858776837587357\n",
      "l1 weight: 0.15819787979125977\n",
      "avg viol: 1.7186100649280707, max viol: 1.7643361742375419 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25320374965667725, valid regret : -0.23922210931777954 \n",
      "---------------------------------------iteration: 246\n",
      "l1 decision: 0.0819210484623909\n",
      "l1 weight: 0.15779922902584076\n",
      "avg viol: 1.6461691909402725, max viol: 1.733658931683749 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2468881756067276, valid regret : -0.2548394501209259 \n",
      "---------------------------------------iteration: 247\n",
      "l1 decision: 0.08778364211320877\n",
      "l1 weight: 0.15903910994529724\n",
      "avg viol: 1.7067871627700515, max viol: 1.7652949253097177 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26112252473831177, valid regret : -0.24629825353622437 \n",
      "---------------------------------------iteration: 248\n",
      "l1 decision: 0.08250822126865387\n",
      "l1 weight: 0.15705248713493347\n",
      "avg viol: 1.6607848797319458, max viol: 1.7175877091940492 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24168682098388672, valid regret : -0.2568354308605194 \n",
      "---------------------------------------iteration: 249\n",
      "l1 decision: 0.08649492263793945\n",
      "l1 weight: 0.159096822142601\n",
      "avg viol: 1.7130122263819794, max viol: 1.7694891829742119 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24671082198619843, valid regret : -0.24971792101860046 \n",
      "---------------------------------------iteration: 250\n",
      "l1 decision: 0.08356261253356934\n",
      "l1 weight: 0.1571502536535263\n",
      "avg viol: 1.6804463774783653, max viol: 1.7405363626312464 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25260642170906067, valid regret : -0.2619118094444275 \n",
      "---------------------------------------iteration: 251\n",
      "l1 decision: 0.08638417720794678\n",
      "l1 weight: 0.15828360617160797\n",
      "avg viol: 1.7129726763349935, max viol: 1.7704652614193037 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2596794068813324, valid regret : -0.2474392056465149 \n",
      "---------------------------------------iteration: 252\n",
      "l1 decision: 0.08445443958044052\n",
      "l1 weight: 0.15682408213615417\n",
      "avg viol: 1.6910089318541577, max viol: 1.7507643217686564 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24772003293037415, valid regret : -0.2614554464817047 \n",
      "---------------------------------------iteration: 253\n",
      "l1 decision: 0.08642605692148209\n",
      "l1 weight: 0.1593068391084671\n",
      "avg viol: 1.72182141250727, max viol: 1.774397664819844 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2649770677089691, valid regret : -0.25279152393341064 \n",
      "---------------------------------------iteration: 254\n",
      "l1 decision: 0.08458444476127625\n",
      "l1 weight: 0.15762712061405182\n",
      "avg viol: 1.6866694086731877, max viol: 1.738984102383256 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2466096132993698, valid regret : -0.2578887641429901 \n",
      "---------------------------------------iteration: 255\n",
      "l1 decision: 0.08611804991960526\n",
      "l1 weight: 0.16096222400665283\n",
      "avg viol: 1.7186647690823884, max viol: 1.7749303302261978 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24699978530406952, valid regret : -0.2562825679779053 \n",
      "---------------------------------------iteration: 256\n",
      "l1 decision: 0.08496758341789246\n",
      "l1 weight: 0.15795621275901794\n",
      "avg viol: 1.6957583400112344, max viol: 1.762707658112049 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2593345642089844, valid regret : -0.2542024552822113 \n",
      "---------------------------------------iteration: 257\n",
      "l1 decision: 0.08654932677745819\n",
      "l1 weight: 0.15742948651313782\n",
      "avg viol: 1.7028654011200706, max viol: 1.762324828421697 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2503013610839844, valid regret : -0.22899238765239716 \n",
      "---------------------------------------iteration: 258\n",
      "l1 decision: 0.08208705484867096\n",
      "l1 weight: 0.1564887911081314\n",
      "avg viol: 1.644360260620597, max viol: 1.691696961177513 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2377409040927887, valid regret : -0.2575961947441101 \n",
      "---------------------------------------iteration: 259\n",
      "l1 decision: 0.08471529185771942\n",
      "l1 weight: 0.15814684331417084\n",
      "avg viol: 1.7005139570403844, max viol: 1.7626480073668063 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26419597864151, valid regret : -0.2623574137687683 \n",
      "---------------------------------------iteration: 260\n",
      "l1 decision: 0.08569357544183731\n",
      "l1 weight: 0.15749529004096985\n",
      "avg viol: 1.699118701631669, max viol: 1.7689034509239718 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25339728593826294, valid regret : -0.25562945008277893 \n",
      "---------------------------------------iteration: 261\n",
      "l1 decision: 0.08543476462364197\n",
      "l1 weight: 0.15819227695465088\n",
      "avg viol: 1.7080842589118401, max viol: 1.7684783334843814 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24900172650814056, valid regret : -0.25926071405410767 \n",
      "---------------------------------------iteration: 262\n",
      "l1 decision: 0.08583133667707443\n",
      "l1 weight: 0.15807044506072998\n",
      "avg viol: 1.707277742078877, max viol: 1.7719174474477768 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26098868250846863, valid regret : -0.24979698657989502 \n",
      "---------------------------------------iteration: 263\n",
      "l1 decision: 0.08368786424398422\n",
      "l1 weight: 0.1585657000541687\n",
      "avg viol: 1.6749044409854106, max viol: 1.729594366857782 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24737419188022614, valid regret : -0.25712940096855164 \n",
      "---------------------------------------iteration: 264\n",
      "l1 decision: 0.08547862619161606\n",
      "l1 weight: 0.1567399948835373\n",
      "avg viol: 1.710102952013476, max viol: 1.780201313784346 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25493040680885315, valid regret : -0.26443639397621155 \n",
      "---------------------------------------iteration: 265\n",
      "l1 decision: 0.08678402751684189\n",
      "l1 weight: 0.15919345617294312\n",
      "avg viol: 1.7306341651896946, max viol: 1.7823918682988733 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2687481641769409, valid regret : -0.2649732232093811 \n",
      "---------------------------------------iteration: 266\n",
      "l1 decision: 0.08607063442468643\n",
      "l1 weight: 0.15871118009090424\n",
      "avg viol: 1.7154597907601419, max viol: 1.7664198321290314 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2583574950695038, valid regret : -0.24615588784217834 \n",
      "---------------------------------------iteration: 267\n",
      "l1 decision: 0.0846184715628624\n",
      "l1 weight: 0.15994885563850403\n",
      "avg viol: 1.6900460362667218, max viol: 1.7370398312341422 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2382020801305771, valid regret : -0.26226311922073364 \n",
      "---------------------------------------iteration: 268\n",
      "l1 decision: 0.08572680503129959\n",
      "l1 weight: 0.15835174918174744\n",
      "avg viol: 1.7121469436681946, max viol: 1.7731675733812153 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26571425795555115, valid regret : -0.262663334608078 \n",
      "---------------------------------------iteration: 269\n",
      "l1 decision: 0.08705901354551315\n",
      "l1 weight: 0.15778227150440216\n",
      "avg viol: 1.7249634220224106, max viol: 1.7766994410194457 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2606017589569092, valid regret : -0.2525404691696167 \n",
      "---------------------------------------iteration: 270\n",
      "l1 decision: 0.08562073856592178\n",
      "l1 weight: 0.1579001247882843\n",
      "avg viol: 1.6939325028000167, max viol: 1.7507369946688414 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2583083510398865, valid regret : -0.2427755892276764 \n",
      "---------------------------------------iteration: 271\n",
      "l1 decision: 0.08367489278316498\n",
      "l1 weight: 0.15786193311214447\n",
      "avg viol: 1.6614979261835106, max viol: 1.7290101250400767 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24946606159210205, valid regret : -0.25920096039772034 \n",
      "---------------------------------------iteration: 272\n",
      "l1 decision: 0.08527550101280212\n",
      "l1 weight: 0.1568632870912552\n",
      "avg viol: 1.6997343370282032, max viol: 1.768274410162121 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25221338868141174, valid regret : -0.25689423084259033 \n",
      "---------------------------------------iteration: 273\n",
      "l1 decision: 0.08562338352203369\n",
      "l1 weight: 0.15795880556106567\n",
      "avg viol: 1.7060307547391858, max viol: 1.783178273937665 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24877555668354034, valid regret : -0.26125022768974304 \n",
      "---------------------------------------iteration: 274\n",
      "l1 decision: 0.08598557859659195\n",
      "l1 weight: 0.1576843410730362\n",
      "avg viol: 1.711038017946994, max viol: 1.7706646070582792 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2620690166950226, valid regret : -0.2533777952194214 \n",
      "---------------------------------------iteration: 275\n",
      "l1 decision: 0.08409067243337631\n",
      "l1 weight: 0.15825669467449188\n",
      "avg viol: 1.6781510915287072, max viol: 1.7493458203971386 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25056397914886475, valid regret : -0.2593074440956116 \n",
      "---------------------------------------iteration: 276\n",
      "l1 decision: 0.08647370338439941\n",
      "l1 weight: 0.1572306752204895\n",
      "avg viol: 1.720845127936991, max viol: 1.7655304528598208 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2567014992237091, valid regret : -0.2513883709907532 \n",
      "---------------------------------------iteration: 277\n",
      "l1 decision: 0.08443161845207214\n",
      "l1 weight: 0.1585436314344406\n",
      "avg viol: 1.6895536773646018, max viol: 1.749440383631736 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25499752163887024, valid regret : -0.26492926478385925 \n",
      "---------------------------------------iteration: 278\n",
      "l1 decision: 0.0862257182598114\n",
      "l1 weight: 0.1584712564945221\n",
      "avg viol: 1.712334123523615, max viol: 1.7669932791031897 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.256282240152359, valid regret : -0.24035274982452393 \n",
      "---------------------------------------iteration: 279\n",
      "l1 decision: 0.0829554870724678\n",
      "l1 weight: 0.15955881774425507\n",
      "avg viol: 1.667522360967705, max viol: 1.7078386850189418 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23275180160999298, valid regret : -0.26299920678138733 \n",
      "---------------------------------------iteration: 280\n",
      "l1 decision: 0.08603497594594955\n",
      "l1 weight: 0.15815597772598267\n",
      "avg viol: 1.7208900890307997, max viol: 1.7772935384418815 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26736149191856384, valid regret : -0.2691012918949127 \n",
      "---------------------------------------iteration: 281\n",
      "l1 decision: 0.08685722202062607\n",
      "l1 weight: 0.15762943029403687\n",
      "avg viol: 1.737680624397508, max viol: 1.7821786381537095 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2652120888233185, valid regret : -0.26098552346229553 \n",
      "---------------------------------------iteration: 282\n",
      "l1 decision: 0.08614084124565125\n",
      "l1 weight: 0.15768186748027802\n",
      "avg viol: 1.7238371669588377, max viol: 1.7809674958698452 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26897236704826355, valid regret : -0.26131004095077515 \n",
      "---------------------------------------iteration: 283\n",
      "l1 decision: 0.08676532655954361\n",
      "l1 weight: 0.15904134511947632\n",
      "avg viol: 1.7097123117739101, max viol: 1.7648865175433457 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26749491691589355, valid regret : -0.24469444155693054 \n",
      "---------------------------------------iteration: 284\n",
      "l1 decision: 0.08359983563423157\n",
      "l1 weight: 0.15671932697296143\n",
      "avg viol: 1.6715606499300337, max viol: 1.7148171989247203 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24122202396392822, valid regret : -0.2591327726840973 \n",
      "---------------------------------------iteration: 285\n",
      "l1 decision: 0.08503305912017822\n",
      "l1 weight: 0.15776441991329193\n",
      "avg viol: 1.7064299884578213, max viol: 1.7712643179111183 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24973441660404205, valid regret : -0.26636093854904175 \n",
      "---------------------------------------iteration: 286\n",
      "l1 decision: 0.08678209781646729\n",
      "l1 weight: 0.15825341641902924\n",
      "avg viol: 1.7272274119319626, max viol: 1.7781337816268206 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26607856154441833, valid regret : -0.2562709450721741 \n",
      "---------------------------------------iteration: 287\n",
      "l1 decision: 0.08435498923063278\n",
      "l1 weight: 0.15841218829154968\n",
      "avg viol: 1.6903608565864852, max viol: 1.7511683499906212 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2550855875015259, valid regret : -0.2604963779449463 \n",
      "---------------------------------------iteration: 288\n",
      "l1 decision: 0.0866696909070015\n",
      "l1 weight: 0.1575145125389099\n",
      "avg viol: 1.7210892865806817, max viol: 1.7784681575139984 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25714460015296936, valid regret : -0.2489273101091385 \n",
      "---------------------------------------iteration: 289\n",
      "l1 decision: 0.08337105810642242\n",
      "l1 weight: 0.15840595960617065\n",
      "avg viol: 1.6751920935227826, max viol: 1.7166005893377587 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2529856562614441, valid regret : -0.2668008804321289 \n",
      "---------------------------------------iteration: 290\n",
      "l1 decision: 0.0866256132721901\n",
      "l1 weight: 0.15847642719745636\n",
      "avg viol: 1.729117384632409, max viol: 1.7820288946386427 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.261726975440979, valid regret : -0.2589316964149475 \n",
      "---------------------------------------iteration: 291\n",
      "l1 decision: 0.08547652512788773\n",
      "l1 weight: 0.1598518341779709\n",
      "avg viol: 1.712500473584805, max viol: 1.7698369601275772 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2481011152267456, valid regret : -0.25924205780029297 \n",
      "---------------------------------------iteration: 292\n",
      "l1 decision: 0.08742650598287582\n",
      "l1 weight: 0.15845084190368652\n",
      "avg viol: 1.7164103353949032, max viol: 1.7727864787448198 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26470890641212463, valid regret : -0.24531607329845428 \n",
      "---------------------------------------iteration: 293\n",
      "l1 decision: 0.08254271745681763\n",
      "l1 weight: 0.15730874240398407\n",
      "avg viol: 1.65739169530083, max viol: 1.7007811100920662 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2407107949256897, valid regret : -0.2605222761631012 \n",
      "---------------------------------------iteration: 294\n",
      "l1 decision: 0.08570465445518494\n",
      "l1 weight: 0.15753981471061707\n",
      "avg viol: 1.7141335137130227, max viol: 1.7784412817563862 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26465800404548645, valid regret : -0.2643997371196747 \n",
      "---------------------------------------iteration: 295\n",
      "l1 decision: 0.08630586415529251\n",
      "l1 weight: 0.15946058928966522\n",
      "avg viol: 1.7212409135483904, max viol: 1.7790633705444634 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2716611623764038, valid regret : -0.2584965229034424 \n",
      "---------------------------------------iteration: 296\n",
      "l1 decision: 0.08512786030769348\n",
      "l1 weight: 0.15753374993801117\n",
      "avg viol: 1.700738901727018, max viol: 1.753154929028824 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25222277641296387, valid regret : -0.2605149447917938 \n",
      "---------------------------------------iteration: 297\n",
      "l1 decision: 0.08629114925861359\n",
      "l1 weight: 0.158868208527565\n",
      "avg viol: 1.7211035426377022, max viol: 1.7763685976387933 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2525419592857361, valid regret : -0.25656166672706604 \n",
      "---------------------------------------iteration: 298\n",
      "l1 decision: 0.08544822037220001\n",
      "l1 weight: 0.15757788717746735\n",
      "avg viol: 1.7077211715671001, max viol: 1.764270304236561 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2609637677669525, valid regret : -0.2625564932823181 \n",
      "---------------------------------------iteration: 299\n",
      "l1 decision: 0.08616434782743454\n",
      "l1 weight: 0.15879759192466736\n",
      "avg viol: 1.7024540412332863, max viol: 1.7715762300649658 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2575676441192627, valid regret : -0.24003654718399048 \n",
      "---------------------------------------iteration: 300\n",
      "l1 decision: 0.08266635984182358\n",
      "l1 weight: 0.15633007884025574\n",
      "avg viol: 1.6574659189837986, max viol: 1.7328331090975553 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2393360584974289, valid regret : -0.2609468102455139 \n",
      "---------------------------------------iteration: 301\n",
      "l1 decision: 0.08605868369340897\n",
      "l1 weight: 0.15904520452022552\n",
      "avg viol: 1.7249500490387435, max viol: 1.7795484701637179 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26615726947784424, valid regret : -0.2634344696998596 \n",
      "---------------------------------------iteration: 302\n",
      "l1 decision: 0.08685992658138275\n",
      "l1 weight: 0.15871889889240265\n",
      "avg viol: 1.7142873020871776, max viol: 1.777528097270988 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2572684586048126, valid regret : -0.24269641935825348 \n",
      "---------------------------------------iteration: 303\n",
      "l1 decision: 0.08371555805206299\n",
      "l1 weight: 0.16033616662025452\n",
      "avg viol: 1.6809238761791494, max viol: 1.7231870878022164 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23481911420822144, valid regret : -0.2613149583339691 \n",
      "---------------------------------------iteration: 304\n",
      "l1 decision: 0.0856439620256424\n",
      "l1 weight: 0.15810345113277435\n",
      "avg viol: 1.7165690427192748, max viol: 1.7814861404476687 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2672647535800934, valid regret : -0.26861533522605896 \n",
      "---------------------------------------iteration: 305\n",
      "l1 decision: 0.08717221021652222\n",
      "l1 weight: 0.15793585777282715\n",
      "avg viol: 1.7402952861427912, max viol: 1.7872432200238109 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26450225710868835, valid regret : -0.25925180315971375 \n",
      "---------------------------------------iteration: 306\n",
      "l1 decision: 0.08508972823619843\n",
      "l1 weight: 0.15749123692512512\n",
      "avg viol: 1.7079054600698873, max viol: 1.7790838000364602 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2650207281112671, valid regret : -0.2576045095920563 \n",
      "---------------------------------------iteration: 307\n",
      "l1 decision: 0.08754465728998184\n",
      "l1 weight: 0.15944208204746246\n",
      "avg viol: 1.7118757518939673, max viol: 1.7628031328786165 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26461994647979736, valid regret : -0.24452166259288788 \n",
      "---------------------------------------iteration: 308\n",
      "l1 decision: 0.08209101110696793\n",
      "l1 weight: 0.15665121376514435\n",
      "avg viol: 1.650177116015111, max viol: 1.6910798959434032 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23977641761302948, valid regret : -0.2588859796524048 \n",
      "---------------------------------------iteration: 309\n",
      "l1 decision: 0.08585897088050842\n",
      "l1 weight: 0.15790070593357086\n",
      "avg viol: 1.7181685924902559, max viol: 1.7804274978116155 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2503959536552429, valid regret : -0.2618285119533539 \n",
      "---------------------------------------iteration: 310\n",
      "l1 decision: 0.08584419637918472\n",
      "l1 weight: 0.15802593529224396\n",
      "avg viol: 1.7114658737646824, max viol: 1.7709636288927868 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26423269510269165, valid regret : -0.25453948974609375 \n",
      "---------------------------------------iteration: 311\n",
      "l1 decision: 0.08531901240348816\n",
      "l1 weight: 0.15812966227531433\n",
      "avg viol: 1.7002760887576733, max viol: 1.7410055734217167 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25260451436042786, valid regret : -0.2586831748485565 \n",
      "---------------------------------------iteration: 312\n",
      "l1 decision: 0.08507869392633438\n",
      "l1 weight: 0.15674880146980286\n",
      "avg viol: 1.7034936193272006, max viol: 1.769456411479041 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25539326667785645, valid regret : -0.26167187094688416 \n",
      "---------------------------------------iteration: 313\n",
      "l1 decision: 0.0873972550034523\n",
      "l1 weight: 0.15871185064315796\n",
      "avg viol: 1.7304928018088686, max viol: 1.7807910783449188 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26718682050704956, valid regret : -0.2609931230545044 \n",
      "---------------------------------------iteration: 314\n",
      "l1 decision: 0.08545910567045212\n",
      "l1 weight: 0.15846742689609528\n",
      "avg viol: 1.7013851804693696, max viol: 1.7629862013272941 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2555551528930664, valid regret : -0.24791881442070007 \n",
      "---------------------------------------iteration: 315\n",
      "l1 decision: 0.08624840527772903\n",
      "l1 weight: 0.15982846915721893\n",
      "avg viol: 1.704966099821322, max viol: 1.7472978045698255 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24003002047538757, valid regret : -0.2593691349029541 \n",
      "---------------------------------------iteration: 316\n",
      "l1 decision: 0.08521275967359543\n",
      "l1 weight: 0.1585218906402588\n",
      "avg viol: 1.7033733767629018, max viol: 1.7576312976889312 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26490557193756104, valid regret : -0.25783979892730713 \n",
      "---------------------------------------iteration: 317\n",
      "l1 decision: 0.08678047358989716\n",
      "l1 weight: 0.1573275327682495\n",
      "avg viol: 1.7193581981619355, max viol: 1.758198822150007 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2546912431716919, valid regret : -0.256518691778183 \n",
      "---------------------------------------iteration: 318\n",
      "l1 decision: 0.08539595454931259\n",
      "l1 weight: 0.15793675184249878\n",
      "avg viol: 1.7026953659056745, max viol: 1.7646220466122031 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2634110450744629, valid regret : -0.2528286278247833 \n",
      "---------------------------------------iteration: 319\n",
      "l1 decision: 0.08499627560377121\n",
      "l1 weight: 0.1589265763759613\n",
      "avg viol: 1.7015405858185841, max viol: 1.7523316615261137 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26165416836738586, valid regret : -0.26511624455451965 \n",
      "---------------------------------------iteration: 320\n",
      "l1 decision: 0.08635055273771286\n",
      "l1 weight: 0.15700478851795197\n",
      "avg viol: 1.7135552953151636, max viol: 1.7853551318403333 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2596900463104248, valid regret : -0.24687261879444122 \n",
      "---------------------------------------iteration: 321\n",
      "l1 decision: 0.08366665989160538\n",
      "l1 weight: 0.15764449536800385\n",
      "avg viol: 1.6812060922558885, max viol: 1.743209965992719 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24073463678359985, valid regret : -0.2650042474269867 \n",
      "---------------------------------------iteration: 322\n",
      "l1 decision: 0.08670852333307266\n",
      "l1 weight: 0.157772496342659\n",
      "avg viol: 1.7240216915868223, max viol: 1.7857304064091295 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26723170280456543, valid regret : -0.26493415236473083 \n",
      "---------------------------------------iteration: 323\n",
      "l1 decision: 0.08556873351335526\n",
      "l1 weight: 0.15840880572795868\n",
      "avg viol: 1.7134252667098189, max viol: 1.7781676137819886 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2630632519721985, valid regret : -0.25831279158592224 \n",
      "---------------------------------------iteration: 324\n",
      "l1 decision: 0.0873439833521843\n",
      "l1 weight: 0.15719839930534363\n",
      "avg viol: 1.71581338044547, max viol: 1.7800631305435672 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2562282383441925, valid regret : -0.2418336421251297 \n",
      "---------------------------------------iteration: 325\n",
      "l1 decision: 0.08239685744047165\n",
      "l1 weight: 0.1585734337568283\n",
      "avg viol: 1.6573930543556343, max viol: 1.706090975087136 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24668125808238983, valid regret : -0.26625943183898926 \n",
      "---------------------------------------iteration: 326\n",
      "l1 decision: 0.08680351078510284\n",
      "l1 weight: 0.15864527225494385\n",
      "avg viol: 1.7285554025229066, max viol: 1.7848407806595787 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26190313696861267, valid regret : -0.25561290979385376 \n",
      "---------------------------------------iteration: 327\n",
      "l1 decision: 0.08525876700878143\n",
      "l1 weight: 0.16053225100040436\n",
      "avg viol: 1.7086261743388604, max viol: 1.753733397461474 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24772900342941284, valid regret : -0.26618149876594543 \n",
      "---------------------------------------iteration: 328\n",
      "l1 decision: 0.0874401330947876\n",
      "l1 weight: 0.15852168202400208\n",
      "avg viol: 1.7311059256655972, max viol: 1.7849665326066315 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2717044949531555, valid regret : -0.258968710899353 \n",
      "---------------------------------------iteration: 329\n",
      "l1 decision: 0.08470582962036133\n",
      "l1 weight: 0.15805001556873322\n",
      "avg viol: 1.6993844801629894, max viol: 1.755770772928372 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2550289034843445, valid regret : -0.25457966327667236 \n",
      "---------------------------------------iteration: 330\n",
      "l1 decision: 0.08730591088533401\n",
      "l1 weight: 0.15792495012283325\n",
      "avg viol: 1.7077458438908797, max viol: 1.768912267871201 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2614006996154785, valid regret : -0.24208517372608185 \n",
      "---------------------------------------iteration: 331\n",
      "l1 decision: 0.0822448804974556\n",
      "l1 weight: 0.15855729579925537\n",
      "avg viol: 1.6487229959858813, max viol: 1.6909422113094479 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2503993809223175, valid regret : -0.2636251747608185 \n",
      "---------------------------------------iteration: 332\n",
      "l1 decision: 0.08717501163482666\n",
      "l1 weight: 0.15796034038066864\n",
      "avg viol: 1.71543823589338, max viol: 1.7808171313954517 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25770303606987, valid regret : -0.2540276348590851 \n",
      "---------------------------------------iteration: 333\n",
      "l1 decision: 0.08448927104473114\n",
      "l1 weight: 0.15824513137340546\n",
      "avg viol: 1.6922133909078911, max viol: 1.759553793235682 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24515940248966217, valid regret : -0.2609730064868927 \n",
      "---------------------------------------iteration: 334\n",
      "l1 decision: 0.0873347669839859\n",
      "l1 weight: 0.15819326043128967\n",
      "avg viol: 1.7134289578567405, max viol: 1.7778187810909003 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2636064291000366, valid regret : -0.24079972505569458 \n",
      "---------------------------------------iteration: 335\n",
      "l1 decision: 0.08205663412809372\n",
      "l1 weight: 0.15777409076690674\n",
      "avg viol: 1.6520042960799766, max viol: 1.6942171999253333 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23775501549243927, valid regret : -0.2603243291378021 \n",
      "---------------------------------------iteration: 336\n",
      "l1 decision: 0.08602847158908844\n",
      "l1 weight: 0.15761277079582214\n",
      "avg viol: 1.7200271290035745, max viol: 1.7821077974513173 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25899219512939453, valid regret : -0.26611560583114624 \n",
      "---------------------------------------iteration: 337\n",
      "l1 decision: 0.08717089891433716\n",
      "l1 weight: 0.15921665728092194\n",
      "avg viol: 1.7309593120327917, max viol: 1.7819482303457335 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2701364755630493, valid regret : -0.261129230260849 \n",
      "---------------------------------------iteration: 338\n",
      "l1 decision: 0.08518452197313309\n",
      "l1 weight: 0.15854598581790924\n",
      "avg viol: 1.7076402143377345, max viol: 1.76346783246845 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2560635805130005, valid regret : -0.2613094449043274 \n",
      "---------------------------------------iteration: 339\n",
      "l1 decision: 0.08688811957836151\n",
      "l1 weight: 0.1605360507965088\n",
      "avg viol: 1.7235124528963934, max viol: 1.7733338286634535 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2498643547296524, valid regret : -0.24662965536117554 \n",
      "---------------------------------------iteration: 340\n",
      "l1 decision: 0.08360237628221512\n",
      "l1 weight: 0.15803788602352142\n",
      "avg viol: 1.6761619048792635, max viol: 1.7208474598592147 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2514937222003937, valid regret : -0.2677781581878662 \n",
      "---------------------------------------iteration: 341\n",
      "l1 decision: 0.08644459396600723\n",
      "l1 weight: 0.15774083137512207\n",
      "avg viol: 1.7286382227158175, max viol: 1.7746787457726896 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2626757323741913, valid regret : -0.26369956135749817 \n",
      "---------------------------------------iteration: 342\n",
      "l1 decision: 0.08717168122529984\n",
      "l1 weight: 0.1573653221130371\n",
      "avg viol: 1.7282791013162933, max viol: 1.7845127959735692 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2696627676486969, valid regret : -0.26443707942962646 \n",
      "---------------------------------------iteration: 343\n",
      "l1 decision: 0.08551590144634247\n",
      "l1 weight: 0.159010648727417\n",
      "avg viol: 1.7108439514652127, max viol: 1.7674667038954794 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27046898007392883, valid regret : -0.2679159343242645 \n",
      "---------------------------------------iteration: 344\n",
      "l1 decision: 0.0866137370467186\n",
      "l1 weight: 0.15722984075546265\n",
      "avg viol: 1.7178784471163089, max viol: 1.7814130546757951 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2595190107822418, valid regret : -0.24525348842144012 \n",
      "---------------------------------------iteration: 345\n",
      "l1 decision: 0.0839289128780365\n",
      "l1 weight: 0.15761007368564606\n",
      "avg viol: 1.6816573962429537, max viol: 1.731346338056028 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23866137862205505, valid regret : -0.2649680972099304 \n",
      "---------------------------------------iteration: 346\n",
      "l1 decision: 0.08560460060834885\n",
      "l1 weight: 0.15787652134895325\n",
      "avg viol: 1.7139518866175785, max viol: 1.772392541053705 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2652503252029419, valid regret : -0.26578661799430847 \n",
      "---------------------------------------iteration: 347\n",
      "l1 decision: 0.08683691173791885\n",
      "l1 weight: 0.1589033156633377\n",
      "avg viol: 1.7258166909037391, max viol: 1.785832850728184 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2635735273361206, valid regret : -0.25773102045059204 \n",
      "---------------------------------------iteration: 348\n",
      "l1 decision: 0.08601950109004974\n",
      "l1 weight: 0.15815451741218567\n",
      "avg viol: 1.7103684745291685, max viol: 1.774264117819257 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25555485486984253, valid regret : -0.24909129738807678 \n",
      "---------------------------------------iteration: 349\n",
      "l1 decision: 0.08420438319444656\n",
      "l1 weight: 0.15887458622455597\n",
      "avg viol: 1.6861027372680837, max viol: 1.740672263666056 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2499772310256958, valid regret : -0.2677994668483734 \n",
      "---------------------------------------iteration: 350\n",
      "l1 decision: 0.08645602315664291\n",
      "l1 weight: 0.15843237936496735\n",
      "avg viol: 1.7266540630965028, max viol: 1.780502854147926 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26282891631126404, valid regret : -0.26238206028938293 \n",
      "---------------------------------------iteration: 351\n",
      "l1 decision: 0.08711183816194534\n",
      "l1 weight: 0.16059301793575287\n",
      "avg viol: 1.7348457514628535, max viol: 1.7811570018529892 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25166016817092896, valid regret : -0.26305556297302246 \n",
      "---------------------------------------iteration: 352\n",
      "l1 decision: 0.08651089668273926\n",
      "l1 weight: 0.1588839590549469\n",
      "avg viol: 1.7134690420235348, max viol: 1.7668441701680422 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26725396513938904, valid regret : -0.25061383843421936 \n",
      "---------------------------------------iteration: 353\n",
      "l1 decision: 0.08477044850587845\n",
      "l1 weight: 0.1574830710887909\n",
      "avg viol: 1.6883392575278413, max viol: 1.7337908598128706 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24637050926685333, valid regret : -0.2613551616668701 \n",
      "---------------------------------------iteration: 354\n",
      "l1 decision: 0.0857718214392662\n",
      "l1 weight: 0.157666876912117\n",
      "avg viol: 1.719816688640276, max viol: 1.7851634530816227 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26891449093818665, valid regret : -0.2646467983722687 \n",
      "---------------------------------------iteration: 355\n",
      "l1 decision: 0.08734592795372009\n",
      "l1 weight: 0.1591196358203888\n",
      "avg viol: 1.7235661314363824, max viol: 1.7851901641115546 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2706124782562256, valid regret : -0.25785529613494873 \n",
      "---------------------------------------iteration: 356\n",
      "l1 decision: 0.08427868783473969\n",
      "l1 weight: 0.15658776462078094\n",
      "avg viol: 1.6922316912008681, max viol: 1.747956627048552 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25471553206443787, valid regret : -0.256663978099823 \n",
      "---------------------------------------iteration: 357\n",
      "l1 decision: 0.08819790929555893\n",
      "l1 weight: 0.1579161137342453\n",
      "avg viol: 1.7164466593938414, max viol: 1.773080457933247 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24813911318778992, valid regret : -0.23783141374588013 \n",
      "---------------------------------------iteration: 358\n",
      "l1 decision: 0.08152448385953903\n",
      "l1 weight: 0.15749605000019073\n",
      "avg viol: 1.6380234889147687, max viol: 1.6789799523539841 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24133683741092682, valid regret : -0.2613038718700409 \n",
      "---------------------------------------iteration: 359\n",
      "l1 decision: 0.08681339770555496\n",
      "l1 weight: 0.15894627571105957\n",
      "avg viol: 1.7147626985888929, max viol: 1.7777196534443647 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2591252028942108, valid regret : -0.2548365592956543 \n",
      "---------------------------------------iteration: 360\n",
      "l1 decision: 0.08535066992044449\n",
      "l1 weight: 0.15740366280078888\n",
      "avg viol: 1.7064057461681659, max viol: 1.7581813880824484 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25564318895339966, valid regret : -0.2613055109977722 \n",
      "---------------------------------------iteration: 361\n",
      "l1 decision: 0.08716168254613876\n",
      "l1 weight: 0.15898287296295166\n",
      "avg viol: 1.7299774660653202, max viol: 1.7742318660020828 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.266844779253006, valid regret : -0.25821515917778015 \n",
      "---------------------------------------iteration: 362\n",
      "l1 decision: 0.08720113337039948\n",
      "l1 weight: 0.1591724008321762\n",
      "avg viol: 1.7041582466068212, max viol: 1.7479503732174635 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2548326849937439, valid regret : -0.2394445538520813 \n",
      "---------------------------------------iteration: 363\n",
      "l1 decision: 0.08327335119247437\n",
      "l1 weight: 0.1604282706975937\n",
      "avg viol: 1.666682778953691, max viol: 1.7052086252951995 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23131975531578064, valid regret : -0.26244938373565674 \n",
      "---------------------------------------iteration: 364\n",
      "l1 decision: 0.08534018695354462\n",
      "l1 weight: 0.15869417786598206\n",
      "avg viol: 1.7133143409021432, max viol: 1.7723642350174487 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2673516571521759, valid regret : -0.26543107628822327 \n",
      "---------------------------------------iteration: 365\n",
      "l1 decision: 0.0878450945019722\n",
      "l1 weight: 0.15800026059150696\n",
      "avg viol: 1.7231340976245701, max viol: 1.7693710068706423 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2606123685836792, valid regret : -0.23972247540950775 \n",
      "---------------------------------------iteration: 366\n",
      "l1 decision: 0.08230473101139069\n",
      "l1 weight: 0.15744361281394958\n",
      "avg viol: 1.6532941820658744, max viol: 1.6990513125201687 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24866324663162231, valid regret : -0.26532912254333496 \n",
      "---------------------------------------iteration: 367\n",
      "l1 decision: 0.08680156618356705\n",
      "l1 weight: 0.15941931307315826\n",
      "avg viol: 1.7277665888977936, max viol: 1.7842488862806931 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2728312611579895, valid regret : -0.26491135358810425 \n",
      "---------------------------------------iteration: 368\n",
      "l1 decision: 0.08674011379480362\n",
      "l1 weight: 0.1579122245311737\n",
      "avg viol: 1.7183069023897406, max viol: 1.7703274069353938 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2595449686050415, valid regret : -0.24728459119796753 \n",
      "---------------------------------------iteration: 369\n",
      "l1 decision: 0.08386288583278656\n",
      "l1 weight: 0.15777626633644104\n",
      "avg viol: 1.6821821481565713, max viol: 1.7362355150980875 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24055929481983185, valid regret : -0.26614487171173096 \n",
      "---------------------------------------iteration: 370\n",
      "l1 decision: 0.08574701100587845\n",
      "l1 weight: 0.15832597017288208\n",
      "avg viol: 1.7196759199473308, max viol: 1.7752537818159908 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26788821816444397, valid regret : -0.2646964192390442 \n",
      "---------------------------------------iteration: 371\n",
      "l1 decision: 0.08793693035840988\n",
      "l1 weight: 0.1591884195804596\n",
      "avg viol: 1.718822141760029, max viol: 1.7736886909697205 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.262449711561203, valid regret : -0.24162331223487854 \n",
      "---------------------------------------iteration: 372\n",
      "l1 decision: 0.08237627148628235\n",
      "l1 weight: 0.15680575370788574\n",
      "avg viol: 1.653221191552002, max viol: 1.7051229166099802 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.243021622300148, valid regret : -0.26546818017959595 \n",
      "---------------------------------------iteration: 373\n",
      "l1 decision: 0.08787111192941666\n",
      "l1 weight: 0.16017083823680878\n",
      "avg viol: 1.7362173968571006, max viol: 1.7849182336358353 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26876023411750793, valid regret : -0.2609846591949463 \n",
      "---------------------------------------iteration: 374\n",
      "l1 decision: 0.08556115627288818\n",
      "l1 weight: 0.15908266603946686\n",
      "avg viol: 1.7046830855036388, max viol: 1.760601657209918 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25579699873924255, valid regret : -0.24928349256515503 \n",
      "---------------------------------------iteration: 375\n",
      "l1 decision: 0.08585990220308304\n",
      "l1 weight: 0.16094370186328888\n",
      "avg viol: 1.7059492047922686, max viol: 1.7489006575196981 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24069470167160034, valid regret : -0.26636916399002075 \n",
      "---------------------------------------iteration: 376\n",
      "l1 decision: 0.08580195903778076\n",
      "l1 weight: 0.15871912240982056\n",
      "avg viol: 1.7194411850230973, max viol: 1.7804844889324158 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2706870138645172, valid regret : -0.2650374174118042 \n",
      "---------------------------------------iteration: 377\n",
      "l1 decision: 0.08853572607040405\n",
      "l1 weight: 0.15798863768577576\n",
      "avg viol: 1.7309967140923255, max viol: 1.7781575361732394 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2609418034553528, valid regret : -0.2406870275735855 \n",
      "---------------------------------------iteration: 378\n",
      "l1 decision: 0.08301229029893875\n",
      "l1 weight: 0.1576659083366394\n",
      "avg viol: 1.6705019990087022, max viol: 1.710616823635064 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2510245442390442, valid regret : -0.2623184323310852 \n",
      "---------------------------------------iteration: 379\n",
      "l1 decision: 0.08659201115369797\n",
      "l1 weight: 0.1588427573442459\n",
      "avg viol: 1.7212770440115128, max viol: 1.7790671352704521 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2701714336872101, valid regret : -0.261089950799942 \n",
      "---------------------------------------iteration: 380\n",
      "l1 decision: 0.08471419662237167\n",
      "l1 weight: 0.15774253010749817\n",
      "avg viol: 1.6977064761932708, max viol: 1.777466929052025 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2552759051322937, valid regret : -0.258453369140625 \n",
      "---------------------------------------iteration: 381\n",
      "l1 decision: 0.08722120523452759\n",
      "l1 weight: 0.15834885835647583\n",
      "avg viol: 1.7230821958591696, max viol: 1.785365974297747 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2519848048686981, valid regret : -0.2502255141735077 \n",
      "---------------------------------------iteration: 382\n",
      "l1 decision: 0.08344971388578415\n",
      "l1 weight: 0.1575392633676529\n",
      "avg viol: 1.67781326817465, max viol: 1.7383540668524802 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2538682222366333, valid regret : -0.2681012749671936 \n",
      "---------------------------------------iteration: 383\n",
      "l1 decision: 0.08666055649518967\n",
      "l1 weight: 0.15894165635108948\n",
      "avg viol: 1.7229440367345523, max viol: 1.786667356500402 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26430487632751465, valid regret : -0.25430935621261597 \n",
      "---------------------------------------iteration: 384\n",
      "l1 decision: 0.08460814505815506\n",
      "l1 weight: 0.15724386274814606\n",
      "avg viol: 1.6995677952631376, max viol: 1.7636958996299654 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25530996918678284, valid regret : -0.2591281235218048 \n",
      "---------------------------------------iteration: 385\n",
      "l1 decision: 0.08810343593358994\n",
      "l1 weight: 0.15931165218353271\n",
      "avg viol: 1.7232753544510342, max viol: 1.771253576502204 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26435521245002747, valid regret : -0.24452413618564606 \n",
      "---------------------------------------iteration: 386\n",
      "l1 decision: 0.08193204551935196\n",
      "l1 weight: 0.15784285962581635\n",
      "avg viol: 1.6475748553231824, max viol: 1.6809383714571595 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23998433351516724, valid regret : -0.2537933588027954 \n",
      "---------------------------------------iteration: 387\n",
      "l1 decision: 0.08741547912359238\n",
      "l1 weight: 0.16032856702804565\n",
      "avg viol: 1.7212422822753433, max viol: 1.767888866364956 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24727459251880646, valid regret : -0.25952857732772827 \n",
      "---------------------------------------iteration: 388\n",
      "l1 decision: 0.08577750623226166\n",
      "l1 weight: 0.15866117179393768\n",
      "avg viol: 1.7088476689218077, max viol: 1.7596521391533315 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26548445224761963, valid regret : -0.25773584842681885 \n",
      "---------------------------------------iteration: 389\n",
      "l1 decision: 0.08663293719291687\n",
      "l1 weight: 0.1579471230506897\n",
      "avg viol: 1.7107119515084195, max viol: 1.7560993788065389 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2527325451374054, valid regret : -0.25820237398147583 \n",
      "---------------------------------------iteration: 390\n",
      "l1 decision: 0.08562427759170532\n",
      "l1 weight: 0.15792232751846313\n",
      "avg viol: 1.7106034717449803, max viol: 1.7732823598198593 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2667974829673767, valid regret : -0.2606033682823181 \n",
      "---------------------------------------iteration: 391\n",
      "l1 decision: 0.08691085129976273\n",
      "l1 weight: 0.1586781144142151\n",
      "avg viol: 1.726284715612419, max viol: 1.7781712524592876 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27156662940979004, valid regret : -0.2662522494792938 \n",
      "---------------------------------------iteration: 392\n",
      "l1 decision: 0.08675868064165115\n",
      "l1 weight: 0.1572171151638031\n",
      "avg viol: 1.714381474816182, max viol: 1.7749973820755258 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2594836950302124, valid regret : -0.24475929141044617 \n",
      "---------------------------------------iteration: 393\n",
      "l1 decision: 0.08374107629060745\n",
      "l1 weight: 0.15726274251937866\n",
      "avg viol: 1.680740286593791, max viol: 1.7207669143099338 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24123941361904144, valid regret : -0.2669122815132141 \n",
      "---------------------------------------iteration: 394\n",
      "l1 decision: 0.08617707341909409\n",
      "l1 weight: 0.15786491334438324\n",
      "avg viol: 1.7250751034255518, max viol: 1.7859330628998578 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26840275526046753, valid regret : -0.2672729194164276 \n",
      "---------------------------------------iteration: 395\n",
      "l1 decision: 0.08737891912460327\n",
      "l1 weight: 0.158225879073143\n",
      "avg viol: 1.7205235146195628, max viol: 1.781369793578051 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26381373405456543, valid regret : -0.24409429728984833 \n",
      "---------------------------------------iteration: 396\n",
      "l1 decision: 0.0831090658903122\n",
      "l1 weight: 0.15603409707546234\n",
      "avg viol: 1.669631325090886, max viol: 1.72406625142321 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24581849575042725, valid regret : -0.26610997319221497 \n",
      "---------------------------------------iteration: 397\n",
      "l1 decision: 0.08746512979269028\n",
      "l1 weight: 0.15892097353935242\n",
      "avg viol: 1.7444874548207736, max viol: 1.7874385855393484 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27263617515563965, valid regret : -0.2670895457267761 \n",
      "---------------------------------------iteration: 398\n",
      "l1 decision: 0.08612661808729172\n",
      "l1 weight: 0.15876735746860504\n",
      "avg viol: 1.7200114416878205, max viol: 1.775819839676842 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2613712251186371, valid regret : -0.2546621263027191 \n",
      "---------------------------------------iteration: 399\n",
      "l1 decision: 0.08654854446649551\n",
      "l1 weight: 0.16045565903186798\n",
      "avg viol: 1.7128213069750928, max viol: 1.7632628061110154 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24434298276901245, valid regret : -0.2631169259548187 \n",
      "---------------------------------------iteration: 400\n",
      "l1 decision: 0.08636002242565155\n",
      "l1 weight: 0.15848317742347717\n",
      "avg viol: 1.715195773152518, max viol: 1.7662362952250987 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26784422993659973, valid regret : -0.25589412450790405 \n",
      "---------------------------------------iteration: 401\n",
      "l1 decision: 0.08574032783508301\n",
      "l1 weight: 0.15690572559833527\n",
      "avg viol: 1.7005462493316736, max viol: 1.740943269454874 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25124090909957886, valid regret : -0.26191282272338867 \n",
      "---------------------------------------iteration: 402\n",
      "l1 decision: 0.0859130322933197\n",
      "l1 weight: 0.15718019008636475\n",
      "avg viol: 1.7216638949187473, max viol: 1.7749979891814291 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2713339924812317, valid regret : -0.2646084427833557 \n",
      "---------------------------------------iteration: 403\n",
      "l1 decision: 0.08834972977638245\n",
      "l1 weight: 0.15853841602802277\n",
      "avg viol: 1.7307119568035705, max viol: 1.7792489831335843 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27316784858703613, valid regret : -0.25180625915527344 \n",
      "---------------------------------------iteration: 404\n",
      "l1 decision: 0.08297102153301239\n",
      "l1 weight: 0.1567235141992569\n",
      "avg viol: 1.6695042385082344, max viol: 1.714326540241018 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2462480217218399, valid regret : -0.2631203830242157 \n",
      "---------------------------------------iteration: 405\n",
      "l1 decision: 0.087430439889431\n",
      "l1 weight: 0.1574063003063202\n",
      "avg viol: 1.7335539361927659, max viol: 1.7822684552520514 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2561051845550537, valid regret : -0.26006147265434265 \n",
      "---------------------------------------iteration: 406\n",
      "l1 decision: 0.08516091108322144\n",
      "l1 weight: 0.1577298641204834\n",
      "avg viol: 1.7097713736299192, max viol: 1.7598643032833934 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26409754157066345, valid regret : -0.26958420872688293 \n",
      "---------------------------------------iteration: 407\n",
      "l1 decision: 0.08749373257160187\n",
      "l1 weight: 0.1575685441493988\n",
      "avg viol: 1.7292613144224742, max viol: 1.7803860215935856 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26720309257507324, valid regret : -0.24701549112796783 \n",
      "---------------------------------------iteration: 408\n",
      "l1 decision: 0.08371224254369736\n",
      "l1 weight: 0.15625038743019104\n",
      "avg viol: 1.6821184861605798, max viol: 1.7254791036248207 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2489587813615799, valid regret : -0.26780685782432556 \n",
      "---------------------------------------iteration: 409\n",
      "l1 decision: 0.08687558770179749\n",
      "l1 weight: 0.1597183644771576\n",
      "avg viol: 1.7375509886888358, max viol: 1.783977378392592 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27275350689888, valid regret : -0.26992079615592957 \n",
      "---------------------------------------iteration: 410\n",
      "l1 decision: 0.08724427968263626\n",
      "l1 weight: 0.15833093225955963\n",
      "avg viol: 1.7375561082878266, max viol: 1.784547035524156 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26591619849205017, valid regret : -0.25297361612319946 \n",
      "---------------------------------------iteration: 411\n",
      "l1 decision: 0.08508910238742828\n",
      "l1 weight: 0.16005519032478333\n",
      "avg viol: 1.7049689014954492, max viol: 1.7519931276328862 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24361774325370789, valid regret : -0.266062468290329 \n",
      "---------------------------------------iteration: 412\n",
      "l1 decision: 0.08647244423627853\n",
      "l1 weight: 0.1586274355649948\n",
      "avg viol: 1.7267053977329487, max viol: 1.780825133959297 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2712593376636505, valid regret : -0.26479244232177734 \n",
      "---------------------------------------iteration: 413\n",
      "l1 decision: 0.08697184175252914\n",
      "l1 weight: 0.15677377581596375\n",
      "avg viol: 1.7352043558086734, max viol: 1.770713187288493 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2628539204597473, valid regret : -0.26194125413894653 \n",
      "---------------------------------------iteration: 414\n",
      "l1 decision: 0.08667921274900436\n",
      "l1 weight: 0.15712158381938934\n",
      "avg viol: 1.724538948382542, max viol: 1.7735283037181944 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26960405707359314, valid regret : -0.2571118175983429 \n",
      "---------------------------------------iteration: 415\n",
      "l1 decision: 0.08529090136289597\n",
      "l1 weight: 0.1568392515182495\n",
      "avg viol: 1.7087949389283312, max viol: 1.750554746715352 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2654869556427002, valid regret : -0.2687820494174957 \n",
      "---------------------------------------iteration: 416\n",
      "l1 decision: 0.08748997002840042\n",
      "l1 weight: 0.15670111775398254\n",
      "avg viol: 1.728876651924511, max viol: 1.7819822619203478 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26441943645477295, valid regret : -0.2468644082546234 \n",
      "---------------------------------------iteration: 417\n",
      "l1 decision: 0.08362662047147751\n",
      "l1 weight: 0.1565464437007904\n",
      "avg viol: 1.6787250536691862, max viol: 1.722807097248733 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24150016903877258, valid regret : -0.2705595791339874 \n",
      "---------------------------------------iteration: 418\n",
      "l1 decision: 0.08699963241815567\n",
      "l1 weight: 0.15768574178218842\n",
      "avg viol: 1.7345110527472571, max viol: 1.7901766919530928 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2710188031196594, valid regret : -0.2705763876438141 \n",
      "---------------------------------------iteration: 419\n",
      "l1 decision: 0.0872291699051857\n",
      "l1 weight: 0.1573197990655899\n",
      "avg viol: 1.7385754659619852, max viol: 1.7882336300099269 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2709192931652069, valid regret : -0.25648126006126404 \n",
      "---------------------------------------iteration: 420\n",
      "l1 decision: 0.0854448527097702\n",
      "l1 weight: 0.15626996755599976\n",
      "avg viol: 1.7125644130894215, max viol: 1.7607021471485496 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2565337121486664, valid regret : -0.2675057351589203 \n",
      "---------------------------------------iteration: 421\n",
      "l1 decision: 0.08762423694133759\n",
      "l1 weight: 0.15894319117069244\n",
      "avg viol: 1.7346662707085487, max viol: 1.7810711120255291 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2717788815498352, valid regret : -0.25052252411842346 \n",
      "---------------------------------------iteration: 422\n",
      "l1 decision: 0.08337357640266418\n",
      "l1 weight: 0.15790043771266937\n",
      "avg viol: 1.6748946986312512, max viol: 1.7084055796731263 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2466384321451187, valid regret : -0.26357337832450867 \n",
      "---------------------------------------iteration: 423\n",
      "l1 decision: 0.08745460212230682\n",
      "l1 weight: 0.15929752588272095\n",
      "avg viol: 1.7460109698417363, max viol: 1.7860618066042662 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2565946877002716, valid regret : -0.2666754722595215 \n",
      "---------------------------------------iteration: 424\n",
      "l1 decision: 0.08685893565416336\n",
      "l1 weight: 0.15791617333889008\n",
      "avg viol: 1.7280423923884518, max viol: 1.7757438437547535 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27261969447135925, valid regret : -0.26116594672203064 \n",
      "---------------------------------------iteration: 425\n",
      "l1 decision: 0.08634072542190552\n",
      "l1 weight: 0.156797856092453\n",
      "avg viol: 1.7197320085135288, max viol: 1.7599512366577983 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25810495018959045, valid regret : -0.2624835968017578 \n",
      "---------------------------------------iteration: 426\n",
      "l1 decision: 0.08642547577619553\n",
      "l1 weight: 0.15695586800575256\n",
      "avg viol: 1.727999037760892, max viol: 1.7800837603863329 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.272736132144928, valid regret : -0.2619078755378723 \n",
      "---------------------------------------iteration: 427\n",
      "l1 decision: 0.08727278560400009\n",
      "l1 weight: 0.1577361822128296\n",
      "avg viol: 1.7240010709804483, max viol: 1.7737221091520041 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2704877555370331, valid regret : -0.262420117855072 \n",
      "---------------------------------------iteration: 428\n",
      "l1 decision: 0.08670399338006973\n",
      "l1 weight: 0.1564554125070572\n",
      "avg viol: 1.713182685493084, max viol: 1.7651317855343223 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2588895559310913, valid regret : -0.24173402786254883 \n",
      "---------------------------------------iteration: 429\n",
      "l1 decision: 0.08342336863279343\n",
      "l1 weight: 0.15711380541324615\n",
      "avg viol: 1.6693179456924554, max viol: 1.701979449018836 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23746509850025177, valid regret : -0.265062540769577 \n",
      "---------------------------------------iteration: 430\n",
      "l1 decision: 0.08581168949604034\n",
      "l1 weight: 0.15742477774620056\n",
      "avg viol: 1.7216162475862076, max viol: 1.7775199194438756 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2678104341030121, valid regret : -0.2663177251815796 \n",
      "---------------------------------------iteration: 431\n",
      "l1 decision: 0.08826567232608795\n",
      "l1 weight: 0.15770865976810455\n",
      "avg viol: 1.7320152903988493, max viol: 1.77843177318573 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26732149720191956, valid regret : -0.24086102843284607 \n",
      "---------------------------------------iteration: 432\n",
      "l1 decision: 0.08229276537895203\n",
      "l1 weight: 0.15678958594799042\n",
      "avg viol: 1.6504827760643093, max viol: 1.6908188504166901 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24185936152935028, valid regret : -0.2671182155609131 \n",
      "---------------------------------------iteration: 433\n",
      "l1 decision: 0.08801707625389099\n",
      "l1 weight: 0.1588362455368042\n",
      "avg viol: 1.7379228979823529, max viol: 1.7821325401309878 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27006983757019043, valid regret : -0.26546233892440796 \n",
      "---------------------------------------iteration: 434\n",
      "l1 decision: 0.08695431798696518\n",
      "l1 weight: 0.15874366462230682\n",
      "avg viol: 1.7245498540492554, max viol: 1.7699831710197031 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2618933618068695, valid regret : -0.2520906925201416 \n",
      "---------------------------------------iteration: 435\n",
      "l1 decision: 0.08545920997858047\n",
      "l1 weight: 0.15952271223068237\n",
      "avg viol: 1.7095490484882612, max viol: 1.7489693677052855 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24563468992710114, valid regret : -0.27035394310951233 \n",
      "---------------------------------------iteration: 436\n",
      "l1 decision: 0.0870589166879654\n",
      "l1 weight: 0.15836432576179504\n",
      "avg viol: 1.7400526104975143, max viol: 1.7923734674113803 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2759439945220947, valid regret : -0.2703522741794586 \n",
      "---------------------------------------iteration: 437\n",
      "l1 decision: 0.08810556679964066\n",
      "l1 weight: 0.1571277230978012\n",
      "avg viol: 1.7508250389472233, max viol: 1.7904074479592964 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2691729664802551, valid regret : -0.2533235251903534 \n",
      "---------------------------------------iteration: 438\n",
      "l1 decision: 0.08449970185756683\n",
      "l1 weight: 0.1564989984035492\n",
      "avg viol: 1.697006332941528, max viol: 1.7523693842813373 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26275214552879333, valid regret : -0.26675480604171753 \n",
      "---------------------------------------iteration: 439\n",
      "l1 decision: 0.08846621960401535\n",
      "l1 weight: 0.15804529190063477\n",
      "avg viol: 1.7333530036557931, max viol: 1.7787359396461397 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27462342381477356, valid regret : -0.2509022057056427 \n",
      "---------------------------------------iteration: 440\n",
      "l1 decision: 0.08277919143438339\n",
      "l1 weight: 0.15568214654922485\n",
      "avg viol: 1.660474253372522, max viol: 1.7065400152932853 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24801546335220337, valid regret : -0.2621191442012787 \n",
      "---------------------------------------iteration: 441\n",
      "l1 decision: 0.08861465752124786\n",
      "l1 weight: 0.15683989226818085\n",
      "avg viol: 1.7342305334022967, max viol: 1.7809495001565665 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2556200325489044, valid regret : -0.2591325640678406 \n",
      "---------------------------------------iteration: 442\n",
      "l1 decision: 0.08475392311811447\n",
      "l1 weight: 0.1570626199245453\n",
      "avg viol: 1.7010867351904744, max viol: 1.7486416813917458 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2620829641819, valid regret : -0.2669040858745575 \n",
      "---------------------------------------iteration: 443\n",
      "l1 decision: 0.08870930969715118\n",
      "l1 weight: 0.1571924239397049\n",
      "avg viol: 1.730629311692901, max viol: 1.776132084080018 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2656761705875397, valid regret : -0.24735505878925323 \n",
      "---------------------------------------iteration: 444\n",
      "l1 decision: 0.08317843824625015\n",
      "l1 weight: 0.15670491755008698\n",
      "avg viol: 1.6704217929957121, max viol: 1.7122921103145927 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24705633521080017, valid regret : -0.26918068528175354 \n",
      "---------------------------------------iteration: 445\n",
      "l1 decision: 0.08838719874620438\n",
      "l1 weight: 0.15830639004707336\n",
      "avg viol: 1.7432436151779256, max viol: 1.7842009200248867 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2727234363555908, valid regret : -0.26577115058898926 \n",
      "---------------------------------------iteration: 446\n",
      "l1 decision: 0.08563605695962906\n",
      "l1 weight: 0.1572709083557129\n",
      "avg viol: 1.7182194749545305, max viol: 1.758722925093025 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26180651783943176, valid regret : -0.2641979157924652 \n",
      "---------------------------------------iteration: 447\n",
      "l1 decision: 0.08868733048439026\n",
      "l1 weight: 0.15867185592651367\n",
      "avg viol: 1.7316800027294084, max viol: 1.775834186701104 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2514767050743103, valid regret : -0.24771718680858612 \n",
      "---------------------------------------iteration: 448\n",
      "l1 decision: 0.08292175084352493\n",
      "l1 weight: 0.15668126940727234\n",
      "avg viol: 1.6641873942292296, max viol: 1.700232517789118 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2536216676235199, valid regret : -0.27552273869514465 \n",
      "---------------------------------------iteration: 449\n",
      "l1 decision: 0.08847096562385559\n",
      "l1 weight: 0.1566181778907776\n",
      "avg viol: 1.7514270674809813, max viol: 1.788772440457251 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26905110478401184, valid regret : -0.26039746403694153 \n",
      "---------------------------------------iteration: 450\n",
      "l1 decision: 0.08558277040719986\n",
      "l1 weight: 0.15718582272529602\n",
      "avg viol: 1.7154863926229154, max viol: 1.7573724556714296 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26969897747039795, valid regret : -0.26422494649887085 \n",
      "---------------------------------------iteration: 451\n",
      "l1 decision: 0.08973093330860138\n",
      "l1 weight: 0.15739500522613525\n",
      "avg viol: 1.7302204109821469, max viol: 1.7698401913512498 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27280792593955994, valid regret : -0.24804580211639404 \n",
      "---------------------------------------iteration: 452\n",
      "l1 decision: 0.0821956917643547\n",
      "l1 weight: 0.15597371757030487\n",
      "avg viol: 1.647459907490993, max viol: 1.6833346362691373 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24287904798984528, valid regret : -0.2647542655467987 \n",
      "---------------------------------------iteration: 453\n",
      "l1 decision: 0.08831166476011276\n",
      "l1 weight: 0.15579354763031006\n",
      "avg viol: 1.7394493287036312, max viol: 1.784029926173389 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2579352855682373, valid regret : -0.2669508457183838 \n",
      "---------------------------------------iteration: 454\n",
      "l1 decision: 0.08637610822916031\n",
      "l1 weight: 0.15705546736717224\n",
      "avg viol: 1.725354570082127, max viol: 1.7744320211932063 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26973778009414673, valid regret : -0.26817309856414795 \n",
      "---------------------------------------iteration: 455\n",
      "l1 decision: 0.08982348442077637\n",
      "l1 weight: 0.15722240507602692\n",
      "avg viol: 1.7292223791882861, max viol: 1.76932030916214 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2650717496871948, valid regret : -0.24325956404209137 \n",
      "---------------------------------------iteration: 456\n",
      "l1 decision: 0.08260610699653625\n",
      "l1 weight: 0.15722860395908356\n",
      "avg viol: 1.6576281905395445, max viol: 1.7054222652222961 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2436097115278244, valid regret : -0.27149462699890137 \n",
      "---------------------------------------iteration: 457\n",
      "l1 decision: 0.08805688470602036\n",
      "l1 weight: 0.1593894511461258\n",
      "avg viol: 1.7443689103290672, max viol: 1.7847175381612033 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2733237147331238, valid regret : -0.27188241481781006 \n",
      "---------------------------------------iteration: 458\n",
      "l1 decision: 0.08730458468198776\n",
      "l1 weight: 0.15780086815357208\n",
      "avg viol: 1.7235858667787398, max viol: 1.7676834391895682 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2614602744579315, valid regret : -0.25819116830825806 \n",
      "---------------------------------------iteration: 459\n",
      "l1 decision: 0.08588582277297974\n",
      "l1 weight: 0.15886318683624268\n",
      "avg viol: 1.7150151959538926, max viol: 1.7478120410814881 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24677719175815582, valid regret : -0.27449679374694824 \n",
      "---------------------------------------iteration: 460\n",
      "l1 decision: 0.08662141859531403\n",
      "l1 weight: 0.15730297565460205\n",
      "avg viol: 1.7255139368008532, max viol: 1.781962081324309 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2710965871810913, valid regret : -0.2677276134490967 \n",
      "---------------------------------------iteration: 461\n",
      "l1 decision: 0.08638298511505127\n",
      "l1 weight: 0.15571342408657074\n",
      "avg viol: 1.7221363908005878, max viol: 1.7591827447758988 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26031553745269775, valid regret : -0.2677834928035736 \n",
      "---------------------------------------iteration: 462\n",
      "l1 decision: 0.08758854866027832\n",
      "l1 weight: 0.15636757016181946\n",
      "avg viol: 1.7270473969430895, max viol: 1.7727838798891753 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2714214622974396, valid regret : -0.24961918592453003 \n",
      "---------------------------------------iteration: 463\n",
      "l1 decision: 0.08351541310548782\n",
      "l1 weight: 0.15580344200134277\n",
      "avg viol: 1.6746105011389592, max viol: 1.7030790757853538 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2574297785758972, valid regret : -0.2792748212814331 \n",
      "---------------------------------------iteration: 464\n",
      "l1 decision: 0.08788260817527771\n",
      "l1 weight: 0.15481851994991302\n",
      "avg viol: 1.7499598341668026, max viol: 1.789309504441917 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27043333649635315, valid regret : -0.2728300988674164 \n",
      "---------------------------------------iteration: 465\n",
      "l1 decision: 0.08751272410154343\n",
      "l1 weight: 0.1549232006072998\n",
      "avg viol: 1.7486806414590683, max viol: 1.781527291983366 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26384490728378296, valid regret : -0.26800984144210815 \n",
      "---------------------------------------iteration: 466\n",
      "l1 decision: 0.08814071863889694\n",
      "l1 weight: 0.15625502169132233\n",
      "avg viol: 1.730117445938522, max viol: 1.77225305698812 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2665492296218872, valid regret : -0.26871562004089355 \n",
      "---------------------------------------iteration: 467\n",
      "l1 decision: 0.08736472576856613\n",
      "l1 weight: 0.15723693370819092\n",
      "avg viol: 1.727694489035639, max viol: 1.763024899410084 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26693060994148254, valid regret : -0.24630507826805115 \n",
      "---------------------------------------iteration: 468\n",
      "l1 decision: 0.08431816846132278\n",
      "l1 weight: 0.15627703070640564\n",
      "avg viol: 1.6849168997700326, max viol: 1.7146507571451366 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24626220762729645, valid regret : -0.268799751996994 \n",
      "---------------------------------------iteration: 469\n",
      "l1 decision: 0.08645744621753693\n",
      "l1 weight: 0.15875039994716644\n",
      "avg viol: 1.7330264774255921, max viol: 1.7839261065237224 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2723081707954407, valid regret : -0.27017199993133545 \n",
      "---------------------------------------iteration: 470\n",
      "l1 decision: 0.08890125900506973\n",
      "l1 weight: 0.15786756575107574\n",
      "avg viol: 1.7436825421301183, max viol: 1.7833970342762768 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26725924015045166, valid regret : -0.24945874512195587 \n",
      "---------------------------------------iteration: 471\n",
      "l1 decision: 0.0838841125369072\n",
      "l1 weight: 0.15895314514636993\n",
      "avg viol: 1.6841194929147605, max viol: 1.7153392215259373 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24229438602924347, valid regret : -0.27006852626800537 \n",
      "---------------------------------------iteration: 472\n",
      "l1 decision: 0.08795138448476791\n",
      "l1 weight: 0.15757285058498383\n",
      "avg viol: 1.7435714073150301, max viol: 1.7877395633258857 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27594810724258423, valid regret : -0.2681504189968109 \n",
      "---------------------------------------iteration: 473\n",
      "l1 decision: 0.0865134596824646\n",
      "l1 weight: 0.1565144807100296\n",
      "avg viol: 1.733657811054145, max viol: 1.7706448689568788 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2672078013420105, valid regret : -0.25401902198791504 \n",
      "---------------------------------------iteration: 474\n",
      "l1 decision: 0.09017228335142136\n",
      "l1 weight: 0.1559199094772339\n",
      "avg viol: 1.7251795712707099, max viol: 1.7632104544900358 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2657933235168457, valid regret : -0.23968344926834106 \n",
      "---------------------------------------iteration: 475\n",
      "l1 decision: 0.08147280663251877\n",
      "l1 weight: 0.15624801814556122\n",
      "avg viol: 1.6333796911596437, max viol: 1.6582768857479095 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2484825700521469, valid regret : -0.26538020372390747 \n",
      "---------------------------------------iteration: 476\n",
      "l1 decision: 0.08927667886018753\n",
      "l1 weight: 0.15517938137054443\n",
      "avg viol: 1.7410714544530492, max viol: 1.7795275257667527 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26424846053123474, valid regret : -0.26179683208465576 \n",
      "---------------------------------------iteration: 477\n",
      "l1 decision: 0.08640386909246445\n",
      "l1 weight: 0.15624408423900604\n",
      "avg viol: 1.7225629533425673, max viol: 1.7641159381018952 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25704070925712585, valid regret : -0.269620418548584 \n",
      "---------------------------------------iteration: 478\n",
      "l1 decision: 0.08908465504646301\n",
      "l1 weight: 0.15760129690170288\n",
      "avg viol: 1.7463919385944608, max viol: 1.7846568437526003 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2736915647983551, valid regret : -0.2644507586956024 \n",
      "---------------------------------------iteration: 479\n",
      "l1 decision: 0.08545392006635666\n",
      "l1 weight: 0.1571476310491562\n",
      "avg viol: 1.7136449466506019, max viol: 1.7582125840708613 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26495787501335144, valid regret : -0.2642720341682434 \n",
      "---------------------------------------iteration: 480\n",
      "l1 decision: 0.08864310383796692\n",
      "l1 weight: 0.1567831188440323\n",
      "avg viol: 1.7411141412536382, max viol: 1.784646230749786 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2642025649547577, valid regret : -0.2505232095718384 \n",
      "---------------------------------------iteration: 481\n",
      "l1 decision: 0.08368414640426636\n",
      "l1 weight: 0.15878625214099884\n",
      "avg viol: 1.6814128542819526, max viol: 1.7227919769939035 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25658470392227173, valid regret : -0.2723435163497925 \n",
      "---------------------------------------iteration: 482\n",
      "l1 decision: 0.08804196864366531\n",
      "l1 weight: 0.15812896192073822\n",
      "avg viol: 1.7457891119457782, max viol: 1.790015587466769 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26906874775886536, valid regret : -0.25926700234413147 \n",
      "---------------------------------------iteration: 483\n",
      "l1 decision: 0.08557700365781784\n",
      "l1 weight: 0.1584884375333786\n",
      "avg viol: 1.717244809641852, max viol: 1.7565194346243516 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25161251425743103, valid regret : -0.26550400257110596 \n",
      "---------------------------------------iteration: 484\n",
      "l1 decision: 0.08891385048627853\n",
      "l1 weight: 0.15791447460651398\n",
      "avg viol: 1.7332127395237331, max viol: 1.7737145898863673 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27198678255081177, valid regret : -0.25349169969558716 \n",
      "---------------------------------------iteration: 485\n",
      "l1 decision: 0.0834464505314827\n",
      "l1 weight: 0.15642507374286652\n",
      "avg viol: 1.673176031302428, max viol: 1.6996049406006932 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24960482120513916, valid regret : -0.26556557416915894 \n",
      "---------------------------------------iteration: 486\n",
      "l1 decision: 0.08845077455043793\n",
      "l1 weight: 0.15636080503463745\n",
      "avg viol: 1.743922056456795, max viol: 1.7849343706620857 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27536633610725403, valid regret : -0.26729828119277954 \n",
      "---------------------------------------iteration: 487\n",
      "l1 decision: 0.08645925670862198\n",
      "l1 weight: 0.15754714608192444\n",
      "avg viol: 1.7300272407781814, max viol: 1.7808067880105227 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.275610089302063, valid regret : -0.2705090045928955 \n",
      "---------------------------------------iteration: 488\n",
      "l1 decision: 0.08921916037797928\n",
      "l1 weight: 0.15563982725143433\n",
      "avg viol: 1.7357067336922045, max viol: 1.7818390810862184 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26411545276641846, valid regret : -0.2504567801952362 \n",
      "---------------------------------------iteration: 489\n",
      "l1 decision: 0.08363724499940872\n",
      "l1 weight: 0.1561792641878128\n",
      "avg viol: 1.6794023185962579, max viol: 1.7235462891403586 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24461759626865387, valid regret : -0.2759864032268524 \n",
      "---------------------------------------iteration: 490\n",
      "l1 decision: 0.08845333755016327\n",
      "l1 weight: 0.15559343993663788\n",
      "avg viol: 1.7481081324073602, max viol: 1.7893365935888141 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2752540409564972, valid regret : -0.2751418948173523 \n",
      "---------------------------------------iteration: 491\n",
      "l1 decision: 0.08618156611919403\n",
      "l1 weight: 0.15683791041374207\n",
      "avg viol: 1.7273458135128021, max viol: 1.7728112153708935 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26893720030784607, valid regret : -0.26517972350120544 \n",
      "---------------------------------------iteration: 492\n",
      "l1 decision: 0.09003280848264694\n",
      "l1 weight: 0.15612316131591797\n",
      "avg viol: 1.742248798243818, max viol: 1.7734358010347933 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26353004574775696, valid regret : -0.24696852266788483 \n",
      "---------------------------------------iteration: 493\n",
      "l1 decision: 0.08280328661203384\n",
      "l1 weight: 0.15820452570915222\n",
      "avg viol: 1.66319039686583, max viol: 1.7052968360949308 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2516430914402008, valid regret : -0.27060413360595703 \n",
      "---------------------------------------iteration: 494\n",
      "l1 decision: 0.0878763496875763\n",
      "l1 weight: 0.1575675755739212\n",
      "avg viol: 1.7433135152727481, max viol: 1.7871341435820796 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26684436202049255, valid regret : -0.26969072222709656 \n",
      "---------------------------------------iteration: 495\n",
      "l1 decision: 0.08703575283288956\n",
      "l1 weight: 0.15961739420890808\n",
      "avg viol: 1.7414746366968938, max viol: 1.782644695835188 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25790879130363464, valid regret : -0.27205514907836914 \n",
      "---------------------------------------iteration: 496\n",
      "l1 decision: 0.08876475691795349\n",
      "l1 weight: 0.1564140021800995\n",
      "avg viol: 1.7472802331740969, max viol: 1.7842928445897996 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27580443024635315, valid regret : -0.2756510078907013 \n",
      "---------------------------------------iteration: 497\n",
      "l1 decision: 0.08740882575511932\n",
      "l1 weight: 0.15584425628185272\n",
      "avg viol: 1.7326307911844925, max viol: 1.7656150883994997 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2659570574760437, valid regret : -0.2515043318271637 \n",
      "---------------------------------------iteration: 498\n",
      "l1 decision: 0.08623457700014114\n",
      "l1 weight: 0.15550082921981812\n",
      "avg viol: 1.7045720320614055, max viol: 1.73591150122229 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25983911752700806, valid regret : -0.2756330370903015 \n",
      "---------------------------------------iteration: 499\n",
      "l1 decision: 0.08729689568281174\n",
      "l1 weight: 0.15649069845676422\n",
      "avg viol: 1.7411875561618944, max viol: 1.7809513048268855 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27873629331588745, valid regret : -0.27061817049980164 \n",
      "---------------------------------------iteration: 500\n",
      "l1 decision: 0.0869826152920723\n",
      "l1 weight: 0.15531255304813385\n",
      "avg viol: 1.7274371196131688, max viol: 1.7615618701092899 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26272356510162354, valid regret : -0.26853102445602417 \n",
      "---------------------------------------iteration: 501\n",
      "l1 decision: 0.08779453486204147\n",
      "l1 weight: 0.1555115282535553\n",
      "avg viol: 1.741785101792193, max viol: 1.7717856701929122 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26089608669281006, valid regret : -0.2507399916648865 \n",
      "---------------------------------------iteration: 502\n",
      "l1 decision: 0.0844988077878952\n",
      "l1 weight: 0.15559372305870056\n",
      "avg viol: 1.6877559425809887, max viol: 1.71748656174168 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2545154392719269, valid regret : -0.27557194232940674 \n",
      "---------------------------------------iteration: 503\n",
      "l1 decision: 0.08743775635957718\n",
      "l1 weight: 0.15692660212516785\n",
      "avg viol: 1.745257670309802, max viol: 1.7898671300208662 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27301761507987976, valid regret : -0.2705343961715698 \n",
      "---------------------------------------iteration: 504\n",
      "l1 decision: 0.08717387169599533\n",
      "l1 weight: 0.15609386563301086\n",
      "avg viol: 1.7429753572876507, max viol: 1.7912610156927258 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2677454948425293, valid regret : -0.2731049358844757 \n",
      "---------------------------------------iteration: 505\n",
      "l1 decision: 0.0882587879896164\n",
      "l1 weight: 0.15742257237434387\n",
      "avg viol: 1.7539205562340794, max viol: 1.7888538026018068 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2768561840057373, valid regret : -0.276125431060791 \n",
      "---------------------------------------iteration: 506\n",
      "l1 decision: 0.08811831474304199\n",
      "l1 weight: 0.1567802131175995\n",
      "avg viol: 1.751260223519057, max viol: 1.780946841230616 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2711831033229828, valid regret : -0.2557096779346466 \n",
      "---------------------------------------iteration: 507\n",
      "l1 decision: 0.08604063838720322\n",
      "l1 weight: 0.15864455699920654\n",
      "avg viol: 1.7177482710342156, max viol: 1.7481620302423835 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24819859862327576, valid regret : -0.2698116600513458 \n",
      "---------------------------------------iteration: 508\n",
      "l1 decision: 0.08797259628772736\n",
      "l1 weight: 0.15565438568592072\n",
      "avg viol: 1.7409851144941058, max viol: 1.766294417437166 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2749921381473541, valid regret : -0.2598196566104889 \n",
      "---------------------------------------iteration: 509\n",
      "l1 decision: 0.08546067029237747\n",
      "l1 weight: 0.15523973107337952\n",
      "avg viol: 1.7044364962587133, max viol: 1.7368194055743515 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2548978328704834, valid regret : -0.2705326974391937 \n",
      "---------------------------------------iteration: 510\n",
      "l1 decision: 0.08805620670318604\n",
      "l1 weight: 0.15596844255924225\n",
      "avg viol: 1.7554780239936736, max viol: 1.7900752456625924 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2801537811756134, valid regret : -0.27091509103775024 \n",
      "---------------------------------------iteration: 511\n",
      "l1 decision: 0.08681964874267578\n",
      "l1 weight: 0.1563190072774887\n",
      "avg viol: 1.7382401535660028, max viol: 1.7745136604644358 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27816712856292725, valid regret : -0.27083462476730347 \n",
      "---------------------------------------iteration: 512\n",
      "l1 decision: 0.08913490921258926\n",
      "l1 weight: 0.1553506702184677\n",
      "avg viol: 1.7319255518441787, max viol: 1.769322712905705 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26374927163124084, valid regret : -0.24110107123851776 \n",
      "---------------------------------------iteration: 513\n",
      "l1 decision: 0.08239325135946274\n",
      "l1 weight: 0.15456847846508026\n",
      "avg viol: 1.6510146138182609, max viol: 1.6807202713098377 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.23794378340244293, valid regret : -0.26998546719551086 \n",
      "---------------------------------------iteration: 514\n",
      "l1 decision: 0.08808135986328125\n",
      "l1 weight: 0.15601177513599396\n",
      "avg viol: 1.735978939505294, max viol: 1.7842470346949995 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2692647874355316, valid regret : -0.2749926745891571 \n",
      "---------------------------------------iteration: 515\n",
      "l1 decision: 0.08680230379104614\n",
      "l1 weight: 0.15605975687503815\n",
      "avg viol: 1.7376724628428928, max viol: 1.7742718670051545 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27157482504844666, valid regret : -0.2723994553089142 \n",
      "---------------------------------------iteration: 516\n",
      "l1 decision: 0.08973953127861023\n",
      "l1 weight: 0.15585021674633026\n",
      "avg viol: 1.7625757093066932, max viol: 1.7892127800150774 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2717769145965576, valid regret : -0.2651952803134918 \n",
      "---------------------------------------iteration: 517\n",
      "l1 decision: 0.08555781096220016\n",
      "l1 weight: 0.1573570817708969\n",
      "avg viol: 1.715294321991969, max viol: 1.7447159853763878 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2693648338317871, valid regret : -0.2764348089694977 \n",
      "---------------------------------------iteration: 518\n",
      "l1 decision: 0.08908917009830475\n",
      "l1 weight: 0.15693989396095276\n",
      "avg viol: 1.749152557947673, max viol: 1.7824841334950179 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2689986228942871, valid regret : -0.2511827349662781 \n",
      "---------------------------------------iteration: 519\n",
      "l1 decision: 0.0842016264796257\n",
      "l1 weight: 0.15788261592388153\n",
      "avg viol: 1.6890422125527402, max viol: 1.7219481719657779 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24318209290504456, valid regret : -0.2720213234424591 \n",
      "---------------------------------------iteration: 520\n",
      "l1 decision: 0.08880498260259628\n",
      "l1 weight: 0.1562357097864151\n",
      "avg viol: 1.7466559880028945, max viol: 1.7855166723020375 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2761397659778595, valid regret : -0.2614542543888092 \n",
      "---------------------------------------iteration: 521\n",
      "l1 decision: 0.08484672009944916\n",
      "l1 weight: 0.15586870908737183\n",
      "avg viol: 1.7045647264254513, max viol: 1.7379766507074237 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25775593519210815, valid regret : -0.26467272639274597 \n",
      "---------------------------------------iteration: 522\n",
      "l1 decision: 0.08855221420526505\n",
      "l1 weight: 0.155868262052536\n",
      "avg viol: 1.735047404948855, max viol: 1.7753893700428307 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.272578626871109, valid regret : -0.24846987426280975 \n",
      "---------------------------------------iteration: 523\n",
      "l1 decision: 0.08278614282608032\n",
      "l1 weight: 0.15586596727371216\n",
      "avg viol: 1.6624670360272285, max viol: 1.697884778957814 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25537312030792236, valid regret : -0.27461928129196167 \n",
      "---------------------------------------iteration: 524\n",
      "l1 decision: 0.08901426196098328\n",
      "l1 weight: 0.1539670079946518\n",
      "avg viol: 1.75805792693689, max viol: 1.7858695572940633 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2713682949542999, valid regret : -0.25703924894332886 \n",
      "---------------------------------------iteration: 525\n",
      "l1 decision: 0.08528576791286469\n",
      "l1 weight: 0.15627562999725342\n",
      "avg viol: 1.7098487538978224, max viol: 1.7506694679614156 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25209397077560425, valid regret : -0.27330148220062256 \n",
      "---------------------------------------iteration: 526\n",
      "l1 decision: 0.08849473297595978\n",
      "l1 weight: 0.15598183870315552\n",
      "avg viol: 1.7473291550471912, max viol: 1.7880512054543942 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2741141617298126, valid regret : -0.26174235343933105 \n",
      "---------------------------------------iteration: 527\n",
      "l1 decision: 0.08505230396986008\n",
      "l1 weight: 0.1565546840429306\n",
      "avg viol: 1.7074793775042054, max viol: 1.742376061156392 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26251086592674255, valid regret : -0.26990699768066406 \n",
      "---------------------------------------iteration: 528\n",
      "l1 decision: 0.08957760781049728\n",
      "l1 weight: 0.15661516785621643\n",
      "avg viol: 1.755477771088481, max viol: 1.787897507660091 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26797962188720703, valid regret : -0.254125714302063 \n",
      "---------------------------------------iteration: 529\n",
      "l1 decision: 0.08365491032600403\n",
      "l1 weight: 0.1574128270149231\n",
      "avg viol: 1.6784201854816638, max viol: 1.7148960852064192 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2580943703651428, valid regret : -0.2729627192020416 \n",
      "---------------------------------------iteration: 530\n",
      "l1 decision: 0.08922246098518372\n",
      "l1 weight: 0.15727248787879944\n",
      "avg viol: 1.7504692412598524, max viol: 1.7819306985475123 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26874276995658875, valid regret : -0.26222652196884155 \n",
      "---------------------------------------iteration: 531\n",
      "l1 decision: 0.08604782074689865\n",
      "l1 weight: 0.15700484812259674\n",
      "avg viol: 1.726543579735444, max viol: 1.7607444780878723 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2543826997280121, valid regret : -0.26667556166648865 \n",
      "---------------------------------------iteration: 532\n",
      "l1 decision: 0.09035513550043106\n",
      "l1 weight: 0.15651920437812805\n",
      "avg viol: 1.7383361516555305, max viol: 1.7708343712147325 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27133309841156006, valid regret : -0.2482563853263855 \n",
      "---------------------------------------iteration: 533\n",
      "l1 decision: 0.08258533477783203\n",
      "l1 weight: 0.15619783103466034\n",
      "avg viol: 1.656535310848849, max viol: 1.682856122031808 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24491676688194275, valid regret : -0.26873502135276794 \n",
      "---------------------------------------iteration: 534\n",
      "l1 decision: 0.0890779048204422\n",
      "l1 weight: 0.15566396713256836\n",
      "avg viol: 1.7466030252154452, max viol: 1.7838029507547617 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27530550956726074, valid regret : -0.26820969581604004 \n",
      "---------------------------------------iteration: 535\n",
      "l1 decision: 0.0871054008603096\n",
      "l1 weight: 0.15586362779140472\n",
      "avg viol: 1.733695229915029, max viol: 1.769732809625566 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27582550048828125, valid regret : -0.28080588579177856 \n",
      "---------------------------------------iteration: 536\n",
      "l1 decision: 0.08845119923353195\n",
      "l1 weight: 0.153892382979393\n",
      "avg viol: 1.7514570386719424, max viol: 1.7877542665228248 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2713538408279419, valid regret : -0.2651056945323944 \n",
      "---------------------------------------iteration: 537\n",
      "l1 decision: 0.08716435730457306\n",
      "l1 weight: 0.1544349044561386\n",
      "avg viol: 1.738133889393066, max viol: 1.7622910982463509 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25894394516944885, valid regret : -0.25956764817237854 \n",
      "---------------------------------------iteration: 538\n",
      "l1 decision: 0.08914864808320999\n",
      "l1 weight: 0.15623755753040314\n",
      "avg viol: 1.7153741713927593, max viol: 1.7486005257815123 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2623489499092102, valid regret : -0.2515788972377777 \n",
      "---------------------------------------iteration: 539\n",
      "l1 decision: 0.08403664827346802\n",
      "l1 weight: 0.15485891699790955\n",
      "avg viol: 1.6801992593414616, max viol: 1.6996017806231976 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24954406917095184, valid regret : -0.26936429738998413 \n",
      "---------------------------------------iteration: 540\n",
      "l1 decision: 0.08689963072538376\n",
      "l1 weight: 0.15581132471561432\n",
      "avg viol: 1.7409444309727404, max viol: 1.7716067880392075 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2659556269645691, valid regret : -0.2729732096195221 \n",
      "---------------------------------------iteration: 541\n",
      "l1 decision: 0.08882945030927658\n",
      "l1 weight: 0.155600905418396\n",
      "avg viol: 1.7574670838518067, max viol: 1.7852790862089023 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.278793066740036, valid regret : -0.26245105266571045 \n",
      "---------------------------------------iteration: 542\n",
      "l1 decision: 0.08528804779052734\n",
      "l1 weight: 0.15656067430973053\n",
      "avg viol: 1.7093712398433127, max viol: 1.730706903967075 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2575264871120453, valid regret : -0.27068892121315 \n",
      "---------------------------------------iteration: 543\n",
      "l1 decision: 0.08860146254301071\n",
      "l1 weight: 0.1586376130580902\n",
      "avg viol: 1.7506714487128192, max viol: 1.7805510035250336 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2593197524547577, valid regret : -0.2619558274745941 \n",
      "---------------------------------------iteration: 544\n",
      "l1 decision: 0.08578383177518845\n",
      "l1 weight: 0.15538622438907623\n",
      "avg viol: 1.7185107726982096, max viol: 1.7543477802537382 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2673286497592926, valid regret : -0.27236437797546387 \n",
      "---------------------------------------iteration: 545\n",
      "l1 decision: 0.08995936810970306\n",
      "l1 weight: 0.1549864262342453\n",
      "avg viol: 1.7386804949119687, max viol: 1.7653499455191195 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26592469215393066, valid regret : -0.2393724024295807 \n",
      "---------------------------------------iteration: 546\n",
      "l1 decision: 0.0823732540011406\n",
      "l1 weight: 0.15415558218955994\n",
      "avg viol: 1.657317934470484, max viol: 1.6847891039215028 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24764789640903473, valid regret : -0.2683756947517395 \n",
      "---------------------------------------iteration: 547\n",
      "l1 decision: 0.08666668832302094\n",
      "l1 weight: 0.15486091375350952\n",
      "avg viol: 1.7373028459155466, max viol: 1.7717317850328982 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27576401829719543, valid regret : -0.27779173851013184 \n",
      "---------------------------------------iteration: 548\n",
      "l1 decision: 0.0887368768453598\n",
      "l1 weight: 0.1536131054162979\n",
      "avg viol: 1.747804186962312, max viol: 1.780974839348346 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2692510783672333, valid regret : -0.2536812722682953 \n",
      "---------------------------------------iteration: 549\n",
      "l1 decision: 0.08443271368741989\n",
      "l1 weight: 0.15426971018314362\n",
      "avg viol: 1.6954788539063883, max viol: 1.7270547673106194 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24840137362480164, valid regret : -0.2732698917388916 \n",
      "---------------------------------------iteration: 550\n",
      "l1 decision: 0.08813665807247162\n",
      "l1 weight: 0.15575337409973145\n",
      "avg viol: 1.7518969909346196, max viol: 1.7881908987183124 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27658340334892273, valid regret : -0.27348843216896057 \n",
      "---------------------------------------iteration: 551\n",
      "l1 decision: 0.08745390921831131\n",
      "l1 weight: 0.15534339845180511\n",
      "avg viol: 1.741413465323858, max viol: 1.775296437786892 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27144837379455566, valid regret : -0.2676713466644287 \n",
      "---------------------------------------iteration: 552\n",
      "l1 decision: 0.08889215439558029\n",
      "l1 weight: 0.15547889471054077\n",
      "avg viol: 1.748661277042702, max viol: 1.77582251932472 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26808562874794006, valid regret : -0.25411856174468994 \n",
      "---------------------------------------iteration: 553\n",
      "l1 decision: 0.08455825597047806\n",
      "l1 weight: 0.15613357722759247\n",
      "avg viol: 1.6905716849351302, max viol: 1.7208642060868442 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.256206750869751, valid regret : -0.2786152958869934 \n",
      "---------------------------------------iteration: 554\n",
      "l1 decision: 0.08708692342042923\n",
      "l1 weight: 0.1560715138912201\n",
      "avg viol: 1.741772011837529, max viol: 1.7773579668719321 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26973310112953186, valid regret : -0.27121132612228394 \n",
      "---------------------------------------iteration: 555\n",
      "l1 decision: 0.08929911255836487\n",
      "l1 weight: 0.15703319013118744\n",
      "avg viol: 1.7575060669449158, max viol: 1.7863812202122062 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2591910660266876, valid regret : -0.2677896022796631 \n",
      "---------------------------------------iteration: 556\n",
      "l1 decision: 0.08582273125648499\n",
      "l1 weight: 0.15545925498008728\n",
      "avg viol: 1.720296990434872, max viol: 1.7454238110221922 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2721191942691803, valid regret : -0.2750694453716278 \n",
      "---------------------------------------iteration: 557\n",
      "l1 decision: 0.0896724984049797\n",
      "l1 weight: 0.15479496121406555\n",
      "avg viol: 1.7463945714314468, max viol: 1.7735038897953928 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2664196193218231, valid regret : -0.25438427925109863 \n",
      "---------------------------------------iteration: 558\n",
      "l1 decision: 0.0843777135014534\n",
      "l1 weight: 0.1549406200647354\n",
      "avg viol: 1.6935171251604333, max viol: 1.7309206407517195 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2626279592514038, valid regret : -0.2734011709690094 \n",
      "---------------------------------------iteration: 559\n",
      "l1 decision: 0.08883500099182129\n",
      "l1 weight: 0.1548868864774704\n",
      "avg viol: 1.746174885489745, max viol: 1.7782791833160445 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27972128987312317, valid regret : -0.27111542224884033 \n",
      "---------------------------------------iteration: 560\n",
      "l1 decision: 0.08653609454631805\n",
      "l1 weight: 0.1532672792673111\n",
      "avg viol: 1.731298721799394, max viol: 1.7623266270384192 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26340049505233765, valid regret : -0.26693859696388245 \n",
      "---------------------------------------iteration: 561\n",
      "l1 decision: 0.08871757239103317\n",
      "l1 weight: 0.15435516834259033\n",
      "avg viol: 1.7410236072418046, max viol: 1.771728964522481 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25867921113967896, valid regret : -0.25391486287117004 \n",
      "---------------------------------------iteration: 562\n",
      "l1 decision: 0.08479665964841843\n",
      "l1 weight: 0.1545124500989914\n",
      "avg viol: 1.6976938827743289, max viol: 1.7282072445377707 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25687751173973083, valid regret : -0.27695730328559875 \n",
      "---------------------------------------iteration: 563\n",
      "l1 decision: 0.08754314482212067\n",
      "l1 weight: 0.15569749474525452\n",
      "avg viol: 1.7467924719773509, max viol: 1.7835558028891683 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2752060890197754, valid regret : -0.2681778371334076 \n",
      "---------------------------------------iteration: 564\n",
      "l1 decision: 0.08814436197280884\n",
      "l1 weight: 0.15584909915924072\n",
      "avg viol: 1.7508428443042794, max viol: 1.7818708419799805 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2669159471988678, valid regret : -0.272516667842865 \n",
      "---------------------------------------iteration: 565\n",
      "l1 decision: 0.08780411630868912\n",
      "l1 weight: 0.15593084692955017\n",
      "avg viol: 1.7416312402312177, max viol: 1.7765174449887127 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2739184498786926, valid regret : -0.25763365626335144 \n",
      "---------------------------------------iteration: 566\n",
      "l1 decision: 0.08599597960710526\n",
      "l1 weight: 0.15565773844718933\n",
      "avg viol: 1.7081602939974982, max viol: 1.7329490566626191 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2548101246356964, valid regret : -0.2710479497909546 \n",
      "---------------------------------------iteration: 567\n",
      "l1 decision: 0.08805181831121445\n",
      "l1 weight: 0.15712636709213257\n",
      "avg viol: 1.754581528964336, max viol: 1.787797057419084 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2601972818374634, valid regret : -0.2662867605686188 \n",
      "---------------------------------------iteration: 568\n",
      "l1 decision: 0.0867900475859642\n",
      "l1 weight: 0.1543474793434143\n",
      "avg viol: 1.7331598249421223, max viol: 1.7647750754840672 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2706558108329773, valid regret : -0.2704778015613556 \n",
      "---------------------------------------iteration: 569\n",
      "l1 decision: 0.08859077095985413\n",
      "l1 weight: 0.15478360652923584\n",
      "avg viol: 1.7308624701818918, max viol: 1.7675403690664098 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26200827956199646, valid regret : -0.24902477860450745 \n",
      "---------------------------------------iteration: 570\n",
      "l1 decision: 0.0841417983174324\n",
      "l1 weight: 0.15462543070316315\n",
      "avg viol: 1.6943194913619664, max viol: 1.7233953569084406 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25892841815948486, valid regret : -0.27525442838668823 \n",
      "---------------------------------------iteration: 571\n",
      "l1 decision: 0.08833277225494385\n",
      "l1 weight: 0.15471528470516205\n",
      "avg viol: 1.7547526814508456, max viol: 1.7864628970564809 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28277722001075745, valid regret : -0.28216660022735596 \n",
      "---------------------------------------iteration: 572\n",
      "l1 decision: 0.0874355360865593\n",
      "l1 weight: 0.15399353206157684\n",
      "avg viol: 1.7497478171082912, max viol: 1.7888987355399877 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27081596851348877, valid regret : -0.2711406648159027 \n",
      "---------------------------------------iteration: 573\n",
      "l1 decision: 0.08978057652711868\n",
      "l1 weight: 0.15458795428276062\n",
      "avg viol: 1.7536672469275072, max viol: 1.7827141848392785 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2624639570713043, valid regret : -0.25507551431655884 \n",
      "---------------------------------------iteration: 574\n",
      "l1 decision: 0.08410733193159103\n",
      "l1 weight: 0.15413840115070343\n",
      "avg viol: 1.6907113118702546, max viol: 1.7193889804184437 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2590424418449402, valid regret : -0.27765125036239624 \n",
      "---------------------------------------iteration: 575\n",
      "l1 decision: 0.08930451422929764\n",
      "l1 weight: 0.15506811439990997\n",
      "avg viol: 1.7518664926628116, max viol: 1.7840878542046994 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2741650342941284, valid regret : -0.2622423470020294 \n",
      "---------------------------------------iteration: 576\n",
      "l1 decision: 0.08538489043712616\n",
      "l1 weight: 0.15460246801376343\n",
      "avg viol: 1.7143545371573419, max viol: 1.7490195208229125 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.260073721408844, valid regret : -0.2681112587451935 \n",
      "---------------------------------------iteration: 577\n",
      "l1 decision: 0.09055927395820618\n",
      "l1 weight: 0.15539705753326416\n",
      "avg viol: 1.743583872281597, max viol: 1.7673345194198191 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2704320251941681, valid regret : -0.25110089778900146 \n",
      "---------------------------------------iteration: 578\n",
      "l1 decision: 0.08243176341056824\n",
      "l1 weight: 0.15633690357208252\n",
      "avg viol: 1.6531478269654327, max viol: 1.680853147059679 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2446245551109314, valid regret : -0.2693483233451843 \n",
      "---------------------------------------iteration: 579\n",
      "l1 decision: 0.08920027315616608\n",
      "l1 weight: 0.15675663948059082\n",
      "avg viol: 1.7570294733770424, max viol: 1.7810826224740595 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25919464230537415, valid regret : -0.2734391987323761 \n",
      "---------------------------------------iteration: 580\n",
      "l1 decision: 0.08714701235294342\n",
      "l1 weight: 0.15485653281211853\n",
      "avg viol: 1.7456607366312529, max viol: 1.776192509685643 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2780606150627136, valid regret : -0.27608561515808105 \n",
      "---------------------------------------iteration: 581\n",
      "l1 decision: 0.09068546444177628\n",
      "l1 weight: 0.1542186439037323\n",
      "avg viol: 1.7539833894849288, max viol: 1.779578622430563 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2692817449569702, valid regret : -0.25772997736930847 \n",
      "---------------------------------------iteration: 582\n",
      "l1 decision: 0.08490388840436935\n",
      "l1 weight: 0.15504510700702667\n",
      "avg viol: 1.7035510489769512, max viol: 1.7281394102610648 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2666400074958801, valid regret : -0.27245476841926575 \n",
      "---------------------------------------iteration: 583\n",
      "l1 decision: 0.0900685116648674\n",
      "l1 weight: 0.1549844890832901\n",
      "avg viol: 1.748713620371418, max viol: 1.7787510603666306 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27930304408073425, valid regret : -0.2692984342575073 \n",
      "---------------------------------------iteration: 584\n",
      "l1 decision: 0.08565797656774521\n",
      "l1 weight: 0.15292111039161682\n",
      "avg viol: 1.7190537911106367, max viol: 1.747684542555362 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26295006275177, valid regret : -0.26924073696136475 \n",
      "---------------------------------------iteration: 585\n",
      "l1 decision: 0.09000351279973984\n",
      "l1 weight: 0.15401065349578857\n",
      "avg viol: 1.7505825814098352, max viol: 1.779449368477799 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26155921816825867, valid regret : -0.2514384984970093 \n",
      "---------------------------------------iteration: 586\n",
      "l1 decision: 0.08363790065050125\n",
      "l1 weight: 0.1545393466949463\n",
      "avg viol: 1.6835767436493188, max viol: 1.7117757799569517 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25476664304733276, valid regret : -0.28002598881721497 \n",
      "---------------------------------------iteration: 587\n",
      "l1 decision: 0.08886883407831192\n",
      "l1 weight: 0.15500691533088684\n",
      "avg viol: 1.7608475668009487, max viol: 1.7885393146425486 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27899548411369324, valid regret : -0.2642084062099457 \n",
      "---------------------------------------iteration: 588\n",
      "l1 decision: 0.08749090880155563\n",
      "l1 weight: 0.15508653223514557\n",
      "avg viol: 1.7410121872182935, max viol: 1.7691272175870836 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26400160789489746, valid regret : -0.2686522603034973 \n",
      "---------------------------------------iteration: 589\n",
      "l1 decision: 0.08858250826597214\n",
      "l1 weight: 0.1560082882642746\n",
      "avg viol: 1.7405953136680181, max viol: 1.7749730073846877 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2735051214694977, valid regret : -0.25562718510627747 \n",
      "---------------------------------------iteration: 590\n",
      "l1 decision: 0.08501000702381134\n",
      "l1 weight: 0.1552579402923584\n",
      "avg viol: 1.6962381353095406, max viol: 1.7204997660592198 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2518344819545746, valid regret : -0.2693535387516022 \n",
      "---------------------------------------iteration: 591\n",
      "l1 decision: 0.08752097934484482\n",
      "l1 weight: 0.15718995034694672\n",
      "avg viol: 1.7488984636586247, max viol: 1.7849029143108055 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25949591398239136, valid regret : -0.27362704277038574 \n",
      "---------------------------------------iteration: 592\n",
      "l1 decision: 0.08870667219161987\n",
      "l1 weight: 0.1553937792778015\n",
      "avg viol: 1.7586894329672214, max viol: 1.7882612273097038 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28093189001083374, valid regret : -0.2705645263195038 \n",
      "---------------------------------------iteration: 593\n",
      "l1 decision: 0.08872967213392258\n",
      "l1 weight: 0.1543460190296173\n",
      "avg viol: 1.7402489100955427, max viol: 1.7672077305614948 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26806673407554626, valid regret : -0.24454902112483978 \n",
      "---------------------------------------iteration: 594\n",
      "l1 decision: 0.08408385515213013\n",
      "l1 weight: 0.15540103614330292\n",
      "avg viol: 1.684146921208594, max viol: 1.7066267058253288 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25517451763153076, valid regret : -0.2723470628261566 \n",
      "---------------------------------------iteration: 595\n",
      "l1 decision: 0.08720765262842178\n",
      "l1 weight: 0.154332235455513\n",
      "avg viol: 1.7434852701035561, max viol: 1.780280805658549 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2799495756626129, valid regret : -0.2801065444946289 \n",
      "---------------------------------------iteration: 596\n",
      "l1 decision: 0.0894361138343811\n",
      "l1 weight: 0.15318214893341064\n",
      "avg viol: 1.761994059960125, max viol: 1.787854812340811 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27367308735847473, valid regret : -0.25437772274017334 \n",
      "---------------------------------------iteration: 597\n",
      "l1 decision: 0.08483448624610901\n",
      "l1 weight: 0.15377983450889587\n",
      "avg viol: 1.7054175119899446, max viol: 1.7334617795422673 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2501831650733948, valid regret : -0.27459490299224854 \n",
      "---------------------------------------iteration: 598\n",
      "l1 decision: 0.08808481693267822\n",
      "l1 weight: 0.1547679305076599\n",
      "avg viol: 1.7539038438448915, max viol: 1.7877390556968749 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27690550684928894, valid regret : -0.2751041650772095 \n",
      "---------------------------------------iteration: 599\n",
      "l1 decision: 0.08778373152017593\n",
      "l1 weight: 0.1542332023382187\n",
      "avg viol: 1.7530928532936378, max viol: 1.7813372099772096 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2760622501373291, valid regret : -0.26661360263824463 \n",
      "---------------------------------------iteration: 600\n",
      "l1 decision: 0.08917737007141113\n",
      "l1 weight: 0.15543727576732635\n",
      "avg viol: 1.7461104785901262, max viol: 1.7790977980475873 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26671671867370605, valid regret : -0.25507691502571106 \n",
      "---------------------------------------iteration: 601\n",
      "l1 decision: 0.08506917208433151\n",
      "l1 weight: 0.15600495040416718\n",
      "avg viol: 1.7046850372792688, max viol: 1.730042836163193 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2606346309185028, valid regret : -0.2755984663963318 \n",
      "---------------------------------------iteration: 602\n",
      "l1 decision: 0.08757345378398895\n",
      "l1 weight: 0.15638379752635956\n",
      "avg viol: 1.7473444290907354, max viol: 1.78248836833518 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27100667357444763, valid regret : -0.2682744264602661 \n",
      "---------------------------------------iteration: 603\n",
      "l1 decision: 0.0889357402920723\n",
      "l1 weight: 0.15724408626556396\n",
      "avg viol: 1.7511633905432973, max viol: 1.7811557134264149 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2575088441371918, valid regret : -0.2644273042678833 \n",
      "---------------------------------------iteration: 604\n",
      "l1 decision: 0.08627432584762573\n",
      "l1 weight: 0.15546303987503052\n",
      "avg viol: 1.7183610524327377, max viol: 1.7465002741664648 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2699904143810272, valid regret : -0.26761558651924133 \n",
      "---------------------------------------iteration: 605\n",
      "l1 decision: 0.08819293230772018\n",
      "l1 weight: 0.15455275774002075\n",
      "avg viol: 1.7303220052912365, max viol: 1.7581108512822539 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2601805031299591, valid regret : -0.2606443166732788 \n",
      "---------------------------------------iteration: 606\n",
      "l1 decision: 0.08804833143949509\n",
      "l1 weight: 0.15429452061653137\n",
      "avg viol: 1.724071186228539, max viol: 1.7470211163163185 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2703677713871002, valid regret : -0.2531360983848572 \n",
      "---------------------------------------iteration: 607\n",
      "l1 decision: 0.08527660369873047\n",
      "l1 weight: 0.15387187898159027\n",
      "avg viol: 1.6993829187774099, max viol: 1.7233679266646504 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26303333044052124, valid regret : -0.28042489290237427 \n",
      "---------------------------------------iteration: 608\n",
      "l1 decision: 0.08827435225248337\n",
      "l1 weight: 0.15293952822685242\n",
      "avg viol: 1.7594061583834992, max viol: 1.7891168042551726 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.273686021566391, valid regret : -0.27522286772727966 \n",
      "---------------------------------------iteration: 609\n",
      "l1 decision: 0.0884709507226944\n",
      "l1 weight: 0.15344788134098053\n",
      "avg viol: 1.7666766880936484, max viol: 1.791114630876109 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26888325810432434, valid regret : -0.278044730424881 \n",
      "---------------------------------------iteration: 610\n",
      "l1 decision: 0.08834688365459442\n",
      "l1 weight: 0.15424317121505737\n",
      "avg viol: 1.7562246601279548, max viol: 1.7930143834091723 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2778013348579407, valid regret : -0.279145747423172 \n",
      "---------------------------------------iteration: 611\n",
      "l1 decision: 0.08756932616233826\n",
      "l1 weight: 0.15427717566490173\n",
      "avg viol: 1.7499735119927209, max viol: 1.7820369992405176 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2746810019016266, valid regret : -0.2657887935638428 \n",
      "---------------------------------------iteration: 612\n",
      "l1 decision: 0.09047963470220566\n",
      "l1 weight: 0.15450827777385712\n",
      "avg viol: 1.7447537089179967, max viol: 1.7760305961128324 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2642047107219696, valid regret : -0.25310376286506653 \n",
      "---------------------------------------iteration: 613\n",
      "l1 decision: 0.08376172184944153\n",
      "l1 weight: 0.1543913334608078\n",
      "avg viol: 1.6841356725548393, max viol: 1.7095802967669442 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2554987370967865, valid regret : -0.2806362211704254 \n",
      "---------------------------------------iteration: 614\n",
      "l1 decision: 0.08874096721410751\n",
      "l1 weight: 0.155909925699234\n",
      "avg viol: 1.7606596351828374, max viol: 1.784833678859286 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2740355432033539, valid regret : -0.273032546043396 \n",
      "---------------------------------------iteration: 615\n",
      "l1 decision: 0.08795959502458572\n",
      "l1 weight: 0.1564653366804123\n",
      "avg viol: 1.7584021614852827, max viol: 1.7868674303172156 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2626854181289673, valid regret : -0.2731021046638489 \n",
      "---------------------------------------iteration: 616\n",
      "l1 decision: 0.09053434431552887\n",
      "l1 weight: 0.15503737330436707\n",
      "avg viol: 1.756075652075233, max viol: 1.7808780441991985 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2800017297267914, valid regret : -0.25687286257743835 \n",
      "---------------------------------------iteration: 617\n",
      "l1 decision: 0.08432735502719879\n",
      "l1 weight: 0.15342310070991516\n",
      "avg viol: 1.6885001488926354, max viol: 1.716657585464418 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24838313460350037, valid regret : -0.270092636346817 \n",
      "---------------------------------------iteration: 618\n",
      "l1 decision: 0.0881405845284462\n",
      "l1 weight: 0.15430061519145966\n",
      "avg viol: 1.7539523507666308, max viol: 1.7826629851479083 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2805849015712738, valid regret : -0.27357199788093567 \n",
      "---------------------------------------iteration: 619\n",
      "l1 decision: 0.0885256975889206\n",
      "l1 weight: 0.15412285923957825\n",
      "avg viol: 1.7515368819948707, max viol: 1.7810299762059003 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28227514028549194, valid regret : -0.2731247842311859 \n",
      "---------------------------------------iteration: 620\n",
      "l1 decision: 0.08870499581098557\n",
      "l1 weight: 0.15323156118392944\n",
      "avg viol: 1.7353544185741339, max viol: 1.7664565495215356 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2662944793701172, valid regret : -0.24983970820903778 \n",
      "---------------------------------------iteration: 621\n",
      "l1 decision: 0.08525286614894867\n",
      "l1 weight: 0.15242522954940796\n",
      "avg viol: 1.6980347884318325, max viol: 1.7198294419795275 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24534489214420319, valid regret : -0.2740716338157654 \n",
      "---------------------------------------iteration: 622\n",
      "l1 decision: 0.08776741474866867\n",
      "l1 weight: 0.15320488810539246\n",
      "avg viol: 1.7538586529862368, max viol: 1.779331622645259 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27828410267829895, valid regret : -0.27920693159103394 \n",
      "---------------------------------------iteration: 623\n",
      "l1 decision: 0.08932019770145416\n",
      "l1 weight: 0.1539107710123062\n",
      "avg viol: 1.7560193198159686, max viol: 1.7851339370245114 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27475956082344055, valid regret : -0.2683834433555603 \n",
      "---------------------------------------iteration: 624\n",
      "l1 decision: 0.0873536467552185\n",
      "l1 weight: 0.15385036170482635\n",
      "avg viol: 1.742851322620336, max viol: 1.764618928427808 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26817587018013, valid regret : -0.26823359727859497 \n",
      "---------------------------------------iteration: 625\n",
      "l1 decision: 0.08942802995443344\n",
      "l1 weight: 0.15383407473564148\n",
      "avg viol: 1.7455362888827222, max viol: 1.765495445113629 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2709975838661194, valid regret : -0.2643531560897827 \n",
      "---------------------------------------iteration: 626\n",
      "l1 decision: 0.08789552748203278\n",
      "l1 weight: 0.15673550963401794\n",
      "avg viol: 1.7140853158745448, max viol: 1.7380719212815166 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25820696353912354, valid regret : -0.25190606713294983 \n",
      "---------------------------------------iteration: 627\n",
      "l1 decision: 0.08536048233509064\n",
      "l1 weight: 0.15579959750175476\n",
      "avg viol: 1.7081140315317316, max viol: 1.732842456549406 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24431665241718292, valid regret : -0.27458176016807556 \n",
      "---------------------------------------iteration: 628\n",
      "l1 decision: 0.08768713474273682\n",
      "l1 weight: 0.1543738842010498\n",
      "avg viol: 1.7526015298940183, max viol: 1.7792876579333097 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28053364157676697, valid regret : -0.2828676104545593 \n",
      "---------------------------------------iteration: 629\n",
      "l1 decision: 0.08967465162277222\n",
      "l1 weight: 0.153403639793396\n",
      "avg viol: 1.7710839782332186, max viol: 1.7918086153222248 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27693310379981995, valid regret : -0.26138341426849365 \n",
      "---------------------------------------iteration: 630\n",
      "l1 decision: 0.08616416156291962\n",
      "l1 weight: 0.1541903018951416\n",
      "avg viol: 1.7283170163887553, max viol: 1.7551969136111438 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27147719264030457, valid regret : -0.27113890647888184 \n",
      "---------------------------------------iteration: 631\n",
      "l1 decision: 0.08974377810955048\n",
      "l1 weight: 0.15384100377559662\n",
      "avg viol: 1.745837780662696, max viol: 1.7784075010567904 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2796284556388855, valid regret : -0.2618061900138855 \n",
      "---------------------------------------iteration: 632\n",
      "l1 decision: 0.08616875112056732\n",
      "l1 weight: 0.15139140188694\n",
      "avg viol: 1.7203435802622697, max viol: 1.7423853883519769 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25787249207496643, valid regret : -0.26629847288131714 \n",
      "---------------------------------------iteration: 633\n",
      "l1 decision: 0.08863966166973114\n",
      "l1 weight: 0.15315745770931244\n",
      "avg viol: 1.7528926711081294, max viol: 1.7770718005485833 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2622241973876953, valid regret : -0.27050793170928955 \n",
      "---------------------------------------iteration: 634\n",
      "l1 decision: 0.08714469522237778\n",
      "l1 weight: 0.15321935713291168\n",
      "avg viol: 1.7465060870262095, max viol: 1.7709324271418154 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27475205063819885, valid regret : -0.2807568311691284 \n",
      "---------------------------------------iteration: 635\n",
      "l1 decision: 0.08975961059331894\n",
      "l1 weight: 0.15383997559547424\n",
      "avg viol: 1.7645322492643027, max viol: 1.7879888541065156 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27998799085617065, valid regret : -0.2621496319770813 \n",
      "---------------------------------------iteration: 636\n",
      "l1 decision: 0.08649007230997086\n",
      "l1 weight: 0.1531044989824295\n",
      "avg viol: 1.7285489825799596, max viol: 1.7604803857393563 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2609138488769531, valid regret : -0.26792848110198975 \n",
      "---------------------------------------iteration: 637\n",
      "l1 decision: 0.08836629241704941\n",
      "l1 weight: 0.15481756627559662\n",
      "avg viol: 1.7333871209388598, max viol: 1.757204060908407 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2706530690193176, valid regret : -0.2636498808860779 \n",
      "---------------------------------------iteration: 638\n",
      "l1 decision: 0.08665989339351654\n",
      "l1 weight: 0.1547573208808899\n",
      "avg viol: 1.720406175502576, max viol: 1.7431000461801887 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25832608342170715, valid regret : -0.26922208070755005 \n",
      "---------------------------------------iteration: 639\n",
      "l1 decision: 0.08824645727872849\n",
      "l1 weight: 0.15704360604286194\n",
      "avg viol: 1.7483677295513917, max viol: 1.7720227150712162 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2589726746082306, valid regret : -0.26576685905456543 \n",
      "---------------------------------------iteration: 640\n",
      "l1 decision: 0.08827120065689087\n",
      "l1 weight: 0.15410253405570984\n",
      "avg viol: 1.7391170851018978, max viol: 1.7698850762099028 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2729119062423706, valid regret : -0.2691662907600403 \n",
      "---------------------------------------iteration: 641\n",
      "l1 decision: 0.08811193704605103\n",
      "l1 weight: 0.15364417433738708\n",
      "avg viol: 1.7297754498536233, max viol: 1.7534758117981255 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26373976469039917, valid regret : -0.2522937059402466 \n",
      "---------------------------------------iteration: 642\n",
      "l1 decision: 0.08546662330627441\n",
      "l1 weight: 0.1536986231803894\n",
      "avg viol: 1.7114067810791311, max viol: 1.7361535541713238 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26336586475372314, valid regret : -0.2758798897266388 \n",
      "---------------------------------------iteration: 643\n",
      "l1 decision: 0.0886751189827919\n",
      "l1 weight: 0.15353083610534668\n",
      "avg viol: 1.7655703112471384, max viol: 1.7934623771579936 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2871263325214386, valid regret : -0.282528817653656 \n",
      "---------------------------------------iteration: 644\n",
      "l1 decision: 0.08931693434715271\n",
      "l1 weight: 0.152064248919487\n",
      "avg viol: 1.7690422972118176, max viol: 1.7952307988889515 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2762972116470337, valid regret : -0.27042868733406067 \n",
      "---------------------------------------iteration: 645\n",
      "l1 decision: 0.08750461041927338\n",
      "l1 weight: 0.1533239334821701\n",
      "avg viol: 1.7491919279472676, max viol: 1.7825001106830314 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26479023694992065, valid regret : -0.2691580057144165 \n",
      "---------------------------------------iteration: 646\n",
      "l1 decision: 0.08843521028757095\n",
      "l1 weight: 0.1536538153886795\n",
      "avg viol: 1.7490931675437604, max viol: 1.7780445900280029 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2734438180923462, valid regret : -0.2563382387161255 \n",
      "---------------------------------------iteration: 647\n",
      "l1 decision: 0.08527493476867676\n",
      "l1 weight: 0.15315867960453033\n",
      "avg viol: 1.7046308279241202, max viol: 1.724307016003877 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2564854621887207, valid regret : -0.26786479353904724 \n",
      "---------------------------------------iteration: 648\n",
      "l1 decision: 0.08759040385484695\n",
      "l1 weight: 0.15414635837078094\n",
      "avg viol: 1.7487836582469753, max viol: 1.7753421023953706 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26737505197525024, valid regret : -0.27417898178100586 \n",
      "---------------------------------------iteration: 649\n",
      "l1 decision: 0.08803713321685791\n",
      "l1 weight: 0.15359078347682953\n",
      "avg viol: 1.7619741991267075, max viol: 1.7830755249597132 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2801520824432373, valid regret : -0.27597641944885254 \n",
      "---------------------------------------iteration: 650\n",
      "l1 decision: 0.09003263711929321\n",
      "l1 weight: 0.15597772598266602\n",
      "avg viol: 1.757145758724655, max viol: 1.7871218561194837 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27227550745010376, valid regret : -0.2550552189350128 \n",
      "---------------------------------------iteration: 651\n",
      "l1 decision: 0.08562245965003967\n",
      "l1 weight: 0.15581254661083221\n",
      "avg viol: 1.7183818397519643, max viol: 1.7475590603426099 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2466326206922531, valid regret : -0.27110835909843445 \n",
      "---------------------------------------iteration: 652\n",
      "l1 decision: 0.08879069983959198\n",
      "l1 weight: 0.1539873629808426\n",
      "avg viol: 1.751181926515419, max viol: 1.7839802028611302 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27730438113212585, valid regret : -0.2737707793712616 \n",
      "---------------------------------------iteration: 653\n",
      "l1 decision: 0.08762310445308685\n",
      "l1 weight: 0.15298962593078613\n",
      "avg viol: 1.7522887039696797, max viol: 1.7782637467607856 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2713254988193512, valid regret : -0.2678031623363495 \n",
      "---------------------------------------iteration: 654\n",
      "l1 decision: 0.08941560983657837\n",
      "l1 weight: 0.1532125174999237\n",
      "avg viol: 1.7570972662814892, max viol: 1.7809111522510648 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2801138162612915, valid regret : -0.25884658098220825 \n",
      "---------------------------------------iteration: 655\n",
      "l1 decision: 0.08662349730730057\n",
      "l1 weight: 0.1527879536151886\n",
      "avg viol: 1.718405271481024, max viol: 1.7476383798057213 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2682282328605652, valid regret : -0.27639633417129517 \n",
      "---------------------------------------iteration: 656\n",
      "l1 decision: 0.08808434009552002\n",
      "l1 weight: 0.15210504829883575\n",
      "avg viol: 1.7571315199075617, max viol: 1.7883416134864092 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2733057141304016, valid regret : -0.26988938450813293 \n",
      "---------------------------------------iteration: 657\n",
      "l1 decision: 0.08944626152515411\n",
      "l1 weight: 0.15281681716442108\n",
      "avg viol: 1.7628759895877375, max viol: 1.7907568814698607 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2663605511188507, valid regret : -0.26793593168258667 \n",
      "---------------------------------------iteration: 658\n",
      "l1 decision: 0.08815892785787582\n",
      "l1 weight: 0.15443050861358643\n",
      "avg viol: 1.7424267154053086, max viol: 1.7686465727165341 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27471020817756653, valid regret : -0.2595367133617401 \n",
      "---------------------------------------iteration: 659\n",
      "l1 decision: 0.08842020481824875\n",
      "l1 weight: 0.15257813036441803\n",
      "avg viol: 1.7230112653865945, max viol: 1.7413429035805166 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26149195432662964, valid regret : -0.2683507204055786 \n",
      "---------------------------------------iteration: 660\n",
      "l1 decision: 0.08821310102939606\n",
      "l1 weight: 0.15437574684619904\n",
      "avg viol: 1.7508833542541833, max viol: 1.780503997579217 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26958706974983215, valid regret : -0.27033668756484985 \n",
      "---------------------------------------iteration: 661\n",
      "l1 decision: 0.08820197731256485\n",
      "l1 weight: 0.15450747311115265\n",
      "avg viol: 1.7553921275859465, max viol: 1.7848652035463601 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2780033349990845, valid regret : -0.2727055251598358 \n",
      "---------------------------------------iteration: 662\n",
      "l1 decision: 0.08895055949687958\n",
      "l1 weight: 0.1559399515390396\n",
      "avg viol: 1.7475560097384732, max viol: 1.775005342438817 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27028435468673706, valid regret : -0.25125065445899963 \n",
      "---------------------------------------iteration: 663\n",
      "l1 decision: 0.08593206852674484\n",
      "l1 weight: 0.15571531653404236\n",
      "avg viol: 1.706832761891419, max viol: 1.731376389041543 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24287256598472595, valid regret : -0.2714705765247345 \n",
      "---------------------------------------iteration: 664\n",
      "l1 decision: 0.08778757601976395\n",
      "l1 weight: 0.15350192785263062\n",
      "avg viol: 1.7532897503519416, max viol: 1.7847217414528131 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2807762026786804, valid regret : -0.2789020836353302 \n",
      "---------------------------------------iteration: 665\n",
      "l1 decision: 0.09000842273235321\n",
      "l1 weight: 0.15305759012699127\n",
      "avg viol: 1.767567668192205, max viol: 1.7969230731250718 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27566197514533997, valid regret : -0.26411494612693787 \n",
      "---------------------------------------iteration: 666\n",
      "l1 decision: 0.08642733842134476\n",
      "l1 weight: 0.1531449556350708\n",
      "avg viol: 1.7311260554369072, max viol: 1.76066813361831 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27530938386917114, valid regret : -0.26927268505096436 \n",
      "---------------------------------------iteration: 667\n",
      "l1 decision: 0.09004701673984528\n",
      "l1 weight: 0.15347759425640106\n",
      "avg viol: 1.7469514281611191, max viol: 1.7788666852284223 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2788548171520233, valid regret : -0.25938552618026733 \n",
      "---------------------------------------iteration: 668\n",
      "l1 decision: 0.08511314541101456\n",
      "l1 weight: 0.15179869532585144\n",
      "avg viol: 1.708334024384385, max viol: 1.7311123348772526 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2550888955593109, valid regret : -0.26872771978378296 \n",
      "---------------------------------------iteration: 669\n",
      "l1 decision: 0.08844926208257675\n",
      "l1 weight: 0.1524980515241623\n",
      "avg viol: 1.7507465470052557, max viol: 1.7834956373553723 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2632559537887573, valid regret : -0.27449506521224976 \n",
      "---------------------------------------iteration: 670\n",
      "l1 decision: 0.08772104233503342\n",
      "l1 weight: 0.15350855886936188\n",
      "avg viol: 1.7505653770739444, max viol: 1.7832193231442943 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27747678756713867, valid regret : -0.27959880232810974 \n",
      "---------------------------------------iteration: 671\n",
      "l1 decision: 0.0896480605006218\n",
      "l1 weight: 0.15326561033725739\n",
      "avg viol: 1.7586004776699702, max viol: 1.78882165835239 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27850237488746643, valid regret : -0.2612118721008301 \n",
      "---------------------------------------iteration: 672\n",
      "l1 decision: 0.08618560433387756\n",
      "l1 weight: 0.1544182300567627\n",
      "avg viol: 1.722584825392696, max viol: 1.7509584471117705 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.259646475315094, valid regret : -0.2715391218662262 \n",
      "---------------------------------------iteration: 673\n",
      "l1 decision: 0.08876312524080276\n",
      "l1 weight: 0.15338163077831268\n",
      "avg viol: 1.74310595563089, max viol: 1.7647440363653004 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2733980119228363, valid regret : -0.2639864981174469 \n",
      "---------------------------------------iteration: 674\n",
      "l1 decision: 0.08692110329866409\n",
      "l1 weight: 0.15454353392124176\n",
      "avg viol: 1.7154619654832641, max viol: 1.7392023457214236 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25687751173973083, valid regret : -0.272060364484787 \n",
      "---------------------------------------iteration: 675\n",
      "l1 decision: 0.08880434930324554\n",
      "l1 weight: 0.1559351235628128\n",
      "avg viol: 1.755738085026387, max viol: 1.7811472597531974 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26069724559783936, valid regret : -0.26901304721832275 \n",
      "---------------------------------------iteration: 676\n",
      "l1 decision: 0.0878201276063919\n",
      "l1 weight: 0.15337194502353668\n",
      "avg viol: 1.7411976083787157, max viol: 1.7638582601211965 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2742979824542999, valid regret : -0.27634650468826294 \n",
      "---------------------------------------iteration: 677\n",
      "l1 decision: 0.08822055160999298\n",
      "l1 weight: 0.1527886688709259\n",
      "avg viol: 1.7453081377391937, max viol: 1.7732946104370058 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2692105770111084, valid regret : -0.26359233260154724 \n",
      "---------------------------------------iteration: 678\n",
      "l1 decision: 0.08768058568239212\n",
      "l1 weight: 0.15313926339149475\n",
      "avg viol: 1.7364360782754376, max viol: 1.7584252967499197 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27187466621398926, valid regret : -0.27253684401512146 \n",
      "---------------------------------------iteration: 679\n",
      "l1 decision: 0.08753014355897903\n",
      "l1 weight: 0.15249103307724\n",
      "avg viol: 1.741739110222552, max viol: 1.7747151162475348 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27935492992401123, valid regret : -0.2735564112663269 \n",
      "---------------------------------------iteration: 680\n",
      "l1 decision: 0.089137002825737\n",
      "l1 weight: 0.1503962129354477\n",
      "avg viol: 1.7447480876662302, max viol: 1.766451483941637 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26621106266975403, valid regret : -0.268669992685318 \n",
      "---------------------------------------iteration: 681\n",
      "l1 decision: 0.08824945986270905\n",
      "l1 weight: 0.15271520614624023\n",
      "avg viol: 1.7392646212788532, max viol: 1.7683666297234595 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25948625802993774, valid regret : -0.26630547642707825 \n",
      "---------------------------------------iteration: 682\n",
      "l1 decision: 0.0874791145324707\n",
      "l1 weight: 0.15170006453990936\n",
      "avg viol: 1.7309151014394593, max viol: 1.7544657988473773 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26766476035118103, valid regret : -0.2799111306667328 \n",
      "---------------------------------------iteration: 683\n",
      "l1 decision: 0.08798975497484207\n",
      "l1 weight: 0.15344370901584625\n",
      "avg viol: 1.7472746785602067, max viol: 1.7792811531107873 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27319177985191345, valid regret : -0.26722583174705505 \n",
      "---------------------------------------iteration: 684\n",
      "l1 decision: 0.0889173299074173\n",
      "l1 weight: 0.15287506580352783\n",
      "avg viol: 1.7499275981623215, max viol: 1.7685953322798014 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26668620109558105, valid regret : -0.27326759696006775 \n",
      "---------------------------------------iteration: 685\n",
      "l1 decision: 0.08873300999403\n",
      "l1 weight: 0.1534990519285202\n",
      "avg viol: 1.756225069136708, max viol: 1.7765022763051093 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27697479724884033, valid regret : -0.2721305191516876 \n",
      "---------------------------------------iteration: 686\n",
      "l1 decision: 0.08806195855140686\n",
      "l1 weight: 0.15387730300426483\n",
      "avg viol: 1.7376775808655658, max viol: 1.760833254083991 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2659449875354767, valid regret : -0.2698519229888916 \n",
      "---------------------------------------iteration: 687\n",
      "l1 decision: 0.08867237716913223\n",
      "l1 weight: 0.15546287596225739\n",
      "avg viol: 1.7530842467758339, max viol: 1.7739680195227265 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25952762365341187, valid regret : -0.2684538662433624 \n",
      "---------------------------------------iteration: 688\n",
      "l1 decision: 0.08823671191930771\n",
      "l1 weight: 0.1532607078552246\n",
      "avg viol: 1.7387743038439658, max viol: 1.7650749324820936 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2739957571029663, valid regret : -0.27565401792526245 \n",
      "---------------------------------------iteration: 689\n",
      "l1 decision: 0.08795078843832016\n",
      "l1 weight: 0.1523539125919342\n",
      "avg viol: 1.7402331895648968, max viol: 1.7630076969508082 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.268818736076355, valid regret : -0.2630356252193451 \n",
      "---------------------------------------iteration: 690\n",
      "l1 decision: 0.08857543766498566\n",
      "l1 weight: 0.1530982404947281\n",
      "avg viol: 1.7383797973120818, max viol: 1.7610671462025493 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27244094014167786, valid regret : -0.273164838552475 \n",
      "---------------------------------------iteration: 691\n",
      "l1 decision: 0.08842042833566666\n",
      "l1 weight: 0.15375930070877075\n",
      "avg viol: 1.7487222877785098, max viol: 1.771042472217232 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28252801299095154, valid regret : -0.2717835605144501 \n",
      "---------------------------------------iteration: 692\n",
      "l1 decision: 0.08815477788448334\n",
      "l1 weight: 0.15019410848617554\n",
      "avg viol: 1.7384160836087539, max viol: 1.7573662898503244 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2653213441371918, valid regret : -0.2720005512237549 \n",
      "---------------------------------------iteration: 693\n",
      "l1 decision: 0.08798818290233612\n",
      "l1 weight: 0.1516830027103424\n",
      "avg viol: 1.7575378698654822, max viol: 1.780255880439654 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26715946197509766, valid regret : -0.2744695544242859 \n",
      "---------------------------------------iteration: 694\n",
      "l1 decision: 0.09021633863449097\n",
      "l1 weight: 0.15254022181034088\n",
      "avg viol: 1.764644161131291, max viol: 1.7857065972639248 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2802984118461609, valid regret : -0.2742915451526642 \n",
      "---------------------------------------iteration: 695\n",
      "l1 decision: 0.0877695083618164\n",
      "l1 weight: 0.15317915380001068\n",
      "avg viol: 1.739438851014129, max viol: 1.7653636027825996 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27322110533714294, valid regret : -0.2576027810573578 \n",
      "---------------------------------------iteration: 696\n",
      "l1 decision: 0.08934462815523148\n",
      "l1 weight: 0.15240488946437836\n",
      "avg viol: 1.7336542895971798, max viol: 1.7522187288850546 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2585749328136444, valid regret : -0.2749435603618622 \n",
      "---------------------------------------iteration: 697\n",
      "l1 decision: 0.08891808986663818\n",
      "l1 weight: 0.1535722017288208\n",
      "avg viol: 1.7575681794882985, max viol: 1.785216462565586 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27818042039871216, valid regret : -0.27822694182395935 \n",
      "---------------------------------------iteration: 698\n",
      "l1 decision: 0.08739104866981506\n",
      "l1 weight: 0.1541946679353714\n",
      "avg viol: 1.7468829889415065, max viol: 1.776171061443165 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.270770788192749, valid regret : -0.26584717631340027 \n",
      "---------------------------------------iteration: 699\n",
      "l1 decision: 0.08997515588998795\n",
      "l1 weight: 0.15527154505252838\n",
      "avg viol: 1.7481371841207147, max viol: 1.7726645367220044 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25731122493743896, valid regret : -0.2520674467086792 \n",
      "---------------------------------------iteration: 700\n",
      "l1 decision: 0.08402035385370255\n",
      "l1 weight: 0.15321460366249084\n",
      "avg viol: 1.686850536451675, max viol: 1.7156367097049952 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2574821412563324, valid regret : -0.2803581953048706 \n",
      "---------------------------------------iteration: 701\n",
      "l1 decision: 0.0881330743432045\n",
      "l1 weight: 0.15173575282096863\n",
      "avg viol: 1.7554574662791673, max viol: 1.787369828321971 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2719970941543579, valid regret : -0.276360422372818 \n",
      "---------------------------------------iteration: 702\n",
      "l1 decision: 0.08922848850488663\n",
      "l1 weight: 0.15255755186080933\n",
      "avg viol: 1.7735177160021705, max viol: 1.7984785188455135 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.285217821598053, valid regret : -0.279684841632843 \n",
      "---------------------------------------iteration: 703\n",
      "l1 decision: 0.08909124881029129\n",
      "l1 weight: 0.15148189663887024\n",
      "avg viol: 1.7703870015207759, max viol: 1.7925400474414346 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28885188698768616, valid regret : -0.2773180902004242 \n",
      "---------------------------------------iteration: 704\n",
      "l1 decision: 0.08946359902620316\n",
      "l1 weight: 0.1510871946811676\n",
      "avg viol: 1.7542125027207658, max viol: 1.7791970986872911 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27123206853866577, valid regret : -0.2462974339723587 \n",
      "---------------------------------------iteration: 705\n",
      "l1 decision: 0.08537743985652924\n",
      "l1 weight: 0.15195336937904358\n",
      "avg viol: 1.7014337235386483, max viol: 1.7247741834726185 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24331645667552948, valid regret : -0.2696843445301056 \n",
      "---------------------------------------iteration: 706\n",
      "l1 decision: 0.08719006180763245\n",
      "l1 weight: 0.15185445547103882\n",
      "avg viol: 1.743288429994136, max viol: 1.7686882426496595 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2756686806678772, valid regret : -0.2829810380935669 \n",
      "---------------------------------------iteration: 707\n",
      "l1 decision: 0.08947965502738953\n",
      "l1 weight: 0.15289318561553955\n",
      "avg viol: 1.7633506113660404, max viol: 1.794520286959596 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27738654613494873, valid regret : -0.2762424647808075 \n",
      "---------------------------------------iteration: 708\n",
      "l1 decision: 0.08826827257871628\n",
      "l1 weight: 0.15141139924526215\n",
      "avg viol: 1.7624931072471919, max viol: 1.7880699230590835 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2743721008300781, valid regret : -0.2776164710521698 \n",
      "---------------------------------------iteration: 709\n",
      "l1 decision: 0.09087901562452316\n",
      "l1 weight: 0.15271838009357452\n",
      "avg viol: 1.7736606849287637, max viol: 1.7936380363535136 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28214702010154724, valid regret : -0.2680634558200836 \n",
      "---------------------------------------iteration: 710\n",
      "l1 decision: 0.08519969135522842\n",
      "l1 weight: 0.15410251915454865\n",
      "avg viol: 1.7081292277411557, max viol: 1.732154389610514 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26167285442352295, valid regret : -0.2683371603488922 \n",
      "---------------------------------------iteration: 711\n",
      "l1 decision: 0.09112198650836945\n",
      "l1 weight: 0.1546371877193451\n",
      "avg viol: 1.7565712210256605, max viol: 1.7760735698975623 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2578495442867279, valid regret : -0.2704446315765381 \n",
      "---------------------------------------iteration: 712\n",
      "l1 decision: 0.08603036403656006\n",
      "l1 weight: 0.151899054646492\n",
      "avg viol: 1.722217150857905, max viol: 1.7565423040650785 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27408158779144287, valid regret : -0.276748925447464 \n",
      "---------------------------------------iteration: 713\n",
      "l1 decision: 0.09121255576610565\n",
      "l1 weight: 0.15065482258796692\n",
      "avg viol: 1.7532837224705144, max viol: 1.7756711804540828 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26920217275619507, valid regret : -0.2592580318450928 \n",
      "---------------------------------------iteration: 714\n",
      "l1 decision: 0.08546317368745804\n",
      "l1 weight: 0.15201535820960999\n",
      "avg viol: 1.713581712685409, max viol: 1.737948274705559 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2694239318370819, valid regret : -0.2767523527145386 \n",
      "---------------------------------------iteration: 715\n",
      "l1 decision: 0.089785635471344\n",
      "l1 weight: 0.15170186758041382\n",
      "avg viol: 1.7684565215412293, max viol: 1.7898037515114993 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2865491211414337, valid regret : -0.2827177047729492 \n",
      "---------------------------------------iteration: 716\n",
      "l1 decision: 0.0884900689125061\n",
      "l1 weight: 0.15098191797733307\n",
      "avg viol: 1.7660179342277116, max viol: 1.7933907042024657 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2762698233127594, valid regret : -0.27460888028144836 \n",
      "---------------------------------------iteration: 717\n",
      "l1 decision: 0.08981242030858994\n",
      "l1 weight: 0.15131084620952606\n",
      "avg viol: 1.7704072381870355, max viol: 1.790936468867585 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26974746584892273, valid regret : -0.26506808400154114 \n",
      "---------------------------------------iteration: 718\n",
      "l1 decision: 0.08644133806228638\n",
      "l1 weight: 0.15161629021167755\n",
      "avg viol: 1.7263758084992877, max viol: 1.756064360961318 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2669965922832489, valid regret : -0.2714077830314636 \n",
      "---------------------------------------iteration: 719\n",
      "l1 decision: 0.08952690660953522\n",
      "l1 weight: 0.15235745906829834\n",
      "avg viol: 1.7504453634715174, max viol: 1.7750601395964622 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2727295756340027, valid regret : -0.2568148374557495 \n",
      "---------------------------------------iteration: 720\n",
      "l1 decision: 0.08591112494468689\n",
      "l1 weight: 0.15204975008964539\n",
      "avg viol: 1.7213894703559345, max viol: 1.7432126839412376 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25857800245285034, valid regret : -0.2725045382976532 \n",
      "---------------------------------------iteration: 721\n",
      "l1 decision: 0.08839380741119385\n",
      "l1 weight: 0.15257930755615234\n",
      "avg viol: 1.7589834710059222, max viol: 1.7822354105301201 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2771804630756378, valid regret : -0.2824762463569641 \n",
      "---------------------------------------iteration: 722\n",
      "l1 decision: 0.08888459950685501\n",
      "l1 weight: 0.15423785150051117\n",
      "avg viol: 1.7634322588919895, max viol: 1.790586972841993 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2749256491661072, valid regret : -0.2694556713104248 \n",
      "---------------------------------------iteration: 723\n",
      "l1 decision: 0.08960127085447311\n",
      "l1 weight: 0.15580680966377258\n",
      "avg viol: 1.752328218931798, max viol: 1.7782148832920939 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.259629487991333, valid regret : -0.2568468153476715 \n",
      "---------------------------------------iteration: 724\n",
      "l1 decision: 0.08541858196258545\n",
      "l1 weight: 0.15163765847682953\n",
      "avg viol: 1.7038335682492471, max viol: 1.7275092527270317 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26057198643684387, valid regret : -0.27769267559051514 \n",
      "---------------------------------------iteration: 725\n",
      "l1 decision: 0.08839525282382965\n",
      "l1 weight: 0.15122409164905548\n",
      "avg viol: 1.7604460918076803, max viol: 1.789521868689917 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2741495966911316, valid regret : -0.2692311406135559 \n",
      "---------------------------------------iteration: 726\n",
      "l1 decision: 0.0884283259510994\n",
      "l1 weight: 0.15311956405639648\n",
      "avg viol: 1.7590177444375876, max viol: 1.792352125106845 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.281747430562973, valid regret : -0.27376267313957214 \n",
      "---------------------------------------iteration: 727\n",
      "l1 decision: 0.08931194990873337\n",
      "l1 weight: 0.15191754698753357\n",
      "avg viol: 1.763025987438159, max viol: 1.7917489223182201 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28646358847618103, valid regret : -0.27163824439048767 \n",
      "---------------------------------------iteration: 728\n",
      "l1 decision: 0.08768419176340103\n",
      "l1 weight: 0.15048126876354218\n",
      "avg viol: 1.7488925749523332, max viol: 1.7771420029457659 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2709798514842987, valid regret : -0.2682040333747864 \n",
      "---------------------------------------iteration: 729\n",
      "l1 decision: 0.08905138820409775\n",
      "l1 weight: 0.15220387279987335\n",
      "avg viol: 1.7547458797320723, max viol: 1.7853245697915554 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26454466581344604, valid regret : -0.26434266567230225 \n",
      "---------------------------------------iteration: 730\n",
      "l1 decision: 0.08693300187587738\n",
      "l1 weight: 0.1515323966741562\n",
      "avg viol: 1.732312391703017, max viol: 1.7570288747083396 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26777663826942444, valid regret : -0.2748209238052368 \n",
      "---------------------------------------iteration: 731\n",
      "l1 decision: 0.08876509964466095\n",
      "l1 weight: 0.15291599929332733\n",
      "avg viol: 1.7525579347554594, max viol: 1.7804888905957341 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2739262878894806, valid regret : -0.2621991038322449 \n",
      "---------------------------------------iteration: 732\n",
      "l1 decision: 0.08691771328449249\n",
      "l1 weight: 0.15197540819644928\n",
      "avg viol: 1.7388400139508304, max viol: 1.760280942544341 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26411277055740356, valid regret : -0.2767176926136017 \n",
      "---------------------------------------iteration: 733\n",
      "l1 decision: 0.08952493965625763\n",
      "l1 weight: 0.1526433676481247\n",
      "avg viol: 1.7666978510230547, max viol: 1.7916517379926518 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2803117632865906, valid regret : -0.2720578610897064 \n",
      "---------------------------------------iteration: 734\n",
      "l1 decision: 0.08756709843873978\n",
      "l1 weight: 0.15469962358474731\n",
      "avg viol: 1.7432722714717965, max viol: 1.7690931428223848 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2682773172855377, valid regret : -0.26603618264198303 \n",
      "---------------------------------------iteration: 735\n",
      "l1 decision: 0.08885630965232849\n",
      "l1 weight: 0.15548084676265717\n",
      "avg viol: 1.7450189292279539, max viol: 1.772235654760152 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2572220265865326, valid regret : -0.2602224349975586 \n",
      "---------------------------------------iteration: 736\n",
      "l1 decision: 0.08666093647480011\n",
      "l1 weight: 0.15211671590805054\n",
      "avg viol: 1.7232066307909555, max viol: 1.7438071154756472 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2666754126548767, valid regret : -0.2799544930458069 \n",
      "---------------------------------------iteration: 737\n",
      "l1 decision: 0.08797602355480194\n",
      "l1 weight: 0.15181772410869598\n",
      "avg viol: 1.7565853737267572, max viol: 1.787971087731421 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27408531308174133, valid regret : -0.27302035689353943 \n",
      "---------------------------------------iteration: 738\n",
      "l1 decision: 0.08934973180294037\n",
      "l1 weight: 0.15265987813472748\n",
      "avg viol: 1.769796805370097, max viol: 1.7992183234309778 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2840381860733032, valid regret : -0.27858009934425354 \n",
      "---------------------------------------iteration: 739\n",
      "l1 decision: 0.08896514773368835\n",
      "l1 weight: 0.15190081298351288\n",
      "avg viol: 1.772205279423506, max viol: 1.7952245299238712 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2896765470504761, valid regret : -0.28260350227355957 \n",
      "---------------------------------------iteration: 740\n",
      "l1 decision: 0.08913565427064896\n",
      "l1 weight: 0.1505744308233261\n",
      "avg viol: 1.7688854220308712, max viol: 1.7969954905565828 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2767564654350281, valid regret : -0.26890334486961365 \n",
      "---------------------------------------iteration: 741\n",
      "l1 decision: 0.08995477110147476\n",
      "l1 weight: 0.15150845050811768\n",
      "avg viol: 1.7610637384041912, max viol: 1.7858633850701153 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2662458121776581, valid regret : -0.26160871982574463 \n",
      "---------------------------------------iteration: 742\n",
      "l1 decision: 0.08608289808034897\n",
      "l1 weight: 0.1521710753440857\n",
      "avg viol: 1.7231899094412801, max viol: 1.7428209451027215 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26551583409309387, valid regret : -0.27942603826522827 \n",
      "---------------------------------------iteration: 743\n",
      "l1 decision: 0.08893398195505142\n",
      "l1 weight: 0.1519872397184372\n",
      "avg viol: 1.7623803623787535, max viol: 1.788824415882118 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2783201038837433, valid regret : -0.2692224979400635 \n",
      "---------------------------------------iteration: 744\n",
      "l1 decision: 0.08780676126480103\n",
      "l1 weight: 0.15177278220653534\n",
      "avg viol: 1.7521154198184377, max viol: 1.7842219746671617 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26831093430519104, valid regret : -0.2764612138271332 \n",
      "---------------------------------------iteration: 745\n",
      "l1 decision: 0.0902089774608612\n",
      "l1 weight: 0.15210090577602386\n",
      "avg viol: 1.7666098164836876, max viol: 1.7910196100128815 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.280543714761734, valid regret : -0.26692160964012146 \n",
      "---------------------------------------iteration: 746\n",
      "l1 decision: 0.08599649369716644\n",
      "l1 weight: 0.15368489921092987\n",
      "avg viol: 1.725150709716836, max viol: 1.748153179883957 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2617805600166321, valid regret : -0.2691781520843506 \n",
      "---------------------------------------iteration: 747\n",
      "l1 decision: 0.08909942954778671\n",
      "l1 weight: 0.15480126440525055\n",
      "avg viol: 1.7615698254771996, max viol: 1.790960019105114 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26111212372779846, valid regret : -0.27316799759864807 \n",
      "---------------------------------------iteration: 748\n",
      "l1 decision: 0.08760233223438263\n",
      "l1 weight: 0.1518097072839737\n",
      "avg viol: 1.7508693957340438, max viol: 1.782392772845924 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28014859557151794, valid regret : -0.27655401825904846 \n",
      "---------------------------------------iteration: 749\n",
      "l1 decision: 0.09039786458015442\n",
      "l1 weight: 0.15190643072128296\n",
      "avg viol: 1.758595917482162, max viol: 1.788536611944437 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2716565430164337, valid regret : -0.2563280761241913 \n",
      "---------------------------------------iteration: 750\n",
      "l1 decision: 0.0851796418428421\n",
      "l1 weight: 0.1517917364835739\n",
      "avg viol: 1.709493411682779, max viol: 1.7416086100274697 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2661192715167999, valid regret : -0.27428799867630005 \n",
      "---------------------------------------iteration: 751\n",
      "l1 decision: 0.0882103443145752\n",
      "l1 weight: 0.15157562494277954\n",
      "avg viol: 1.7587814556329977, max viol: 1.7893332419916987 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2855238914489746, valid regret : -0.27986061573028564 \n",
      "---------------------------------------iteration: 752\n",
      "l1 decision: 0.08901721984148026\n",
      "l1 weight: 0.15057173371315002\n",
      "avg viol: 1.7673976669313196, max viol: 1.7987766573787667 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27625706791877747, valid regret : -0.2716734707355499 \n",
      "---------------------------------------iteration: 753\n",
      "l1 decision: 0.08904807269573212\n",
      "l1 weight: 0.1518683135509491\n",
      "avg viol: 1.760845186676015, max viol: 1.7940871892496943 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2671371400356293, valid regret : -0.27020490169525146 \n",
      "---------------------------------------iteration: 754\n",
      "l1 decision: 0.08738583326339722\n",
      "l1 weight: 0.15199021995067596\n",
      "avg viol: 1.7458737945801113, max viol: 1.772891528904438 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2747900187969208, valid regret : -0.2772436738014221 \n",
      "---------------------------------------iteration: 755\n",
      "l1 decision: 0.08918321877717972\n",
      "l1 weight: 0.15249879658222198\n",
      "avg viol: 1.7558630243712106, max viol: 1.7852804912254214 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2757076025009155, valid regret : -0.25792014598846436 \n",
      "---------------------------------------iteration: 756\n",
      "l1 decision: 0.0869993045926094\n",
      "l1 weight: 0.15198983252048492\n",
      "avg viol: 1.7292867532849778, max viol: 1.749365503899753 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2599072754383087, valid regret : -0.27362242341041565 \n",
      "---------------------------------------iteration: 757\n",
      "l1 decision: 0.08807569742202759\n",
      "l1 weight: 0.1531182825565338\n",
      "avg viol: 1.7552095751673915, max viol: 1.7817560802213848 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27881738543510437, valid regret : -0.2782071828842163 \n",
      "---------------------------------------iteration: 758\n",
      "l1 decision: 0.08923967182636261\n",
      "l1 weight: 0.15403741598129272\n",
      "avg viol: 1.7633081335811949, max viol: 1.7911606733650842 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2752268612384796, valid regret : -0.2707882225513458 \n",
      "---------------------------------------iteration: 759\n",
      "l1 decision: 0.0891757607460022\n",
      "l1 weight: 0.15412814915180206\n",
      "avg viol: 1.7581425254786154, max viol: 1.782212593127042 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2625163495540619, valid regret : -0.26405003666877747 \n",
      "---------------------------------------iteration: 760\n",
      "l1 decision: 0.08745436370372772\n",
      "l1 weight: 0.15164345502853394\n",
      "avg viol: 1.7321972312999423, max viol: 1.7558377557434142 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27131298184394836, valid regret : -0.2783726751804352 \n",
      "---------------------------------------iteration: 761\n",
      "l1 decision: 0.08823991566896439\n",
      "l1 weight: 0.1515292227268219\n",
      "avg viol: 1.7618214932008414, max viol: 1.7918870500288904 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2748277187347412, valid regret : -0.27194279432296753 \n",
      "---------------------------------------iteration: 762\n",
      "l1 decision: 0.0894441157579422\n",
      "l1 weight: 0.15214334428310394\n",
      "avg viol: 1.7602505474176542, max viol: 1.7923620657529682 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2806544005870819, valid regret : -0.27388644218444824 \n",
      "---------------------------------------iteration: 763\n",
      "l1 decision: 0.08890672028064728\n",
      "l1 weight: 0.15197809040546417\n",
      "avg viol: 1.756944352251012, max viol: 1.7789420207263902 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2841936945915222, valid regret : -0.2689349055290222 \n",
      "---------------------------------------iteration: 764\n",
      "l1 decision: 0.08781708031892776\n",
      "l1 weight: 0.1507757604122162\n",
      "avg viol: 1.7271232800994767, max viol: 1.7509853281080723 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2619512677192688, valid regret : -0.27050673961639404 \n",
      "---------------------------------------iteration: 765\n",
      "l1 decision: 0.08794018626213074\n",
      "l1 weight: 0.1521575152873993\n",
      "avg viol: 1.7549224386032438, max viol: 1.7818890601629391 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26648107171058655, valid regret : -0.2787834107875824 \n",
      "---------------------------------------iteration: 766\n",
      "l1 decision: 0.08910692483186722\n",
      "l1 weight: 0.15258006751537323\n",
      "avg viol: 1.7666539428074248, max viol: 1.7981493367115036 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2802707552909851, valid regret : -0.28481388092041016 \n",
      "---------------------------------------iteration: 767\n",
      "l1 decision: 0.08882502466440201\n",
      "l1 weight: 0.1522235870361328\n",
      "avg viol: 1.7683527938250336, max viol: 1.799070507637225 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2821615934371948, valid regret : -0.2769039571285248 \n",
      "---------------------------------------iteration: 768\n",
      "l1 decision: 0.08912641555070877\n",
      "l1 weight: 0.152334526181221\n",
      "avg viol: 1.7722190620289622, max viol: 1.7979067448177375 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2753353714942932, valid regret : -0.2757589519023895 \n",
      "---------------------------------------iteration: 769\n",
      "l1 decision: 0.08928317576646805\n",
      "l1 weight: 0.15235011279582977\n",
      "avg viol: 1.764708605579217, max viol: 1.7861811721231788 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2812880277633667, valid regret : -0.2683877646923065 \n",
      "---------------------------------------iteration: 770\n",
      "l1 decision: 0.08833056688308716\n",
      "l1 weight: 0.15408021211624146\n",
      "avg viol: 1.7308751394803403, max viol: 1.7540873568505049 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2626016139984131, valid regret : -0.27298685908317566 \n",
      "---------------------------------------iteration: 771\n",
      "l1 decision: 0.08841898292303085\n",
      "l1 weight: 0.15512807667255402\n",
      "avg viol: 1.7600364470592467, max viol: 1.7859104019589722 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.262760728597641, valid regret : -0.27658751606941223 \n",
      "---------------------------------------iteration: 772\n",
      "l1 decision: 0.08890987187623978\n",
      "l1 weight: 0.15227554738521576\n",
      "avg viol: 1.7665920330496738, max viol: 1.7885250397957861 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2835805118083954, valid regret : -0.2760013937950134 \n",
      "---------------------------------------iteration: 773\n",
      "l1 decision: 0.08947679400444031\n",
      "l1 weight: 0.1514943540096283\n",
      "avg viol: 1.7465253692871192, max viol: 1.7744507337920368 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.269292414188385, valid regret : -0.2501146197319031 \n",
      "---------------------------------------iteration: 774\n",
      "l1 decision: 0.08482148498296738\n",
      "l1 weight: 0.15161852538585663\n",
      "avg viol: 1.7005705395550468, max viol: 1.7238878686912358 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2607628107070923, valid regret : -0.27420103549957275 \n",
      "---------------------------------------iteration: 775\n",
      "l1 decision: 0.08791811764240265\n",
      "l1 weight: 0.1516413539648056\n",
      "avg viol: 1.7541655885782348, max viol: 1.7829762482724618 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.284153550863266, valid regret : -0.28487229347229004 \n",
      "---------------------------------------iteration: 776\n",
      "l1 decision: 0.08932032436132431\n",
      "l1 weight: 0.15065978467464447\n",
      "avg viol: 1.7690390526194824, max viol: 1.8002768764272332 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2763527035713196, valid regret : -0.27770107984542847 \n",
      "---------------------------------------iteration: 777\n",
      "l1 decision: 0.0888843685388565\n",
      "l1 weight: 0.150997593998909\n",
      "avg viol: 1.7721934965247055, max viol: 1.7964065504493192 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2717800438404083, valid regret : -0.28215035796165466 \n",
      "---------------------------------------iteration: 778\n",
      "l1 decision: 0.08960437029600143\n",
      "l1 weight: 0.151630237698555\n",
      "avg viol: 1.776480902502226, max viol: 1.8036593089345843 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2841779589653015, valid regret : -0.28534865379333496 \n",
      "---------------------------------------iteration: 779\n",
      "l1 decision: 0.08889760076999664\n",
      "l1 weight: 0.1515481024980545\n",
      "avg viol: 1.7740254084675688, max viol: 1.7966724468860775 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28412121534347534, valid regret : -0.27592742443084717 \n",
      "---------------------------------------iteration: 780\n",
      "l1 decision: 0.0902690514922142\n",
      "l1 weight: 0.15197746455669403\n",
      "avg viol: 1.7675520162016618, max viol: 1.7971833581104875 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2721420228481293, valid regret : -0.26776236295700073 \n",
      "---------------------------------------iteration: 781\n",
      "l1 decision: 0.08622440695762634\n",
      "l1 weight: 0.15098503232002258\n",
      "avg viol: 1.727611285580788, max viol: 1.747660230845213 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27119770646095276, valid regret : -0.2824258804321289 \n",
      "---------------------------------------iteration: 782\n",
      "l1 decision: 0.08998452872037888\n",
      "l1 weight: 0.1539475917816162\n",
      "avg viol: 1.7631850618653697, max viol: 1.7891692437697202 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27551549673080444, valid regret : -0.2676495909690857 \n",
      "---------------------------------------iteration: 783\n",
      "l1 decision: 0.08792097866535187\n",
      "l1 weight: 0.1532515436410904\n",
      "avg viol: 1.7504977766308003, max viol: 1.7683024764992297 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2591569721698761, valid regret : -0.27160224318504333 \n",
      "---------------------------------------iteration: 784\n",
      "l1 decision: 0.0887112244963646\n",
      "l1 weight: 0.15210749208927155\n",
      "avg viol: 1.744203587269294, max viol: 1.7708338722586632 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27573299407958984, valid regret : -0.2688317596912384 \n",
      "---------------------------------------iteration: 785\n",
      "l1 decision: 0.08803727477788925\n",
      "l1 weight: 0.15041577816009521\n",
      "avg viol: 1.7318043815955753, max viol: 1.7521147886291146 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26257196068763733, valid regret : -0.271986186504364 \n",
      "---------------------------------------iteration: 786\n",
      "l1 decision: 0.08866417407989502\n",
      "l1 weight: 0.1518535017967224\n",
      "avg viol: 1.7595704878645484, max viol: 1.7874380181310698 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2815396189689636, valid regret : -0.27568644285202026 \n",
      "---------------------------------------iteration: 787\n",
      "l1 decision: 0.08883277326822281\n",
      "l1 weight: 0.15118718147277832\n",
      "avg viol: 1.7603972248220816, max viol: 1.7835119706578553 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.285152792930603, valid regret : -0.27823972702026367 \n",
      "---------------------------------------iteration: 788\n",
      "l1 decision: 0.08958535641431808\n",
      "l1 weight: 0.1498500555753708\n",
      "avg viol: 1.7551791199832223, max viol: 1.7778133100364357 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2729000747203827, valid regret : -0.2532116770744324 \n",
      "---------------------------------------iteration: 789\n",
      "l1 decision: 0.08578558266162872\n",
      "l1 weight: 0.15029649436473846\n",
      "avg viol: 1.7095112543014692, max viol: 1.727569936774671 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.24863140285015106, valid regret : -0.27629929780960083 \n",
      "---------------------------------------iteration: 790\n",
      "l1 decision: 0.088088259100914\n",
      "l1 weight: 0.15114563703536987\n",
      "avg viol: 1.7587475458007975, max viol: 1.7876759455539286 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2801682651042938, valid regret : -0.2850143313407898 \n",
      "---------------------------------------iteration: 791\n",
      "l1 decision: 0.08962064981460571\n",
      "l1 weight: 0.15168432891368866\n",
      "avg viol: 1.775234289921882, max viol: 1.7991294129751623 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28273046016693115, valid regret : -0.27530163526535034 \n",
      "---------------------------------------iteration: 792\n",
      "l1 decision: 0.08867203444242477\n",
      "l1 weight: 0.15102453529834747\n",
      "avg viol: 1.768846516446065, max viol: 1.798864478012547 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2762649655342102, valid regret : -0.27916035056114197 \n",
      "---------------------------------------iteration: 793\n",
      "l1 decision: 0.09043608605861664\n",
      "l1 weight: 0.15163221955299377\n",
      "avg viol: 1.7787656442896695, max viol: 1.797408452956006 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2841762602329254, valid regret : -0.26761627197265625 \n",
      "---------------------------------------iteration: 794\n",
      "l1 decision: 0.08591825515031815\n",
      "l1 weight: 0.15311607718467712\n",
      "avg viol: 1.721471586438711, max viol: 1.7447279039770365 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26248911023139954, valid regret : -0.272168904542923 \n",
      "---------------------------------------iteration: 795\n",
      "l1 decision: 0.08932550251483917\n",
      "l1 weight: 0.1543281227350235\n",
      "avg viol: 1.7667233298730571, max viol: 1.792236908338964 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2642989456653595, valid regret : -0.2769700288772583 \n",
      "---------------------------------------iteration: 796\n",
      "l1 decision: 0.08808528631925583\n",
      "l1 weight: 0.15174983441829681\n",
      "avg viol: 1.760467365250879, max viol: 1.7881115805357695 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28369367122650146, valid regret : -0.28004977107048035 \n",
      "---------------------------------------iteration: 797\n",
      "l1 decision: 0.09097927808761597\n",
      "l1 weight: 0.15104162693023682\n",
      "avg viol: 1.7662742286419961, max viol: 1.7867807147558779 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27426743507385254, valid regret : -0.2574353516101837 \n",
      "---------------------------------------iteration: 798\n",
      "l1 decision: 0.08540622144937515\n",
      "l1 weight: 0.15115568041801453\n",
      "avg viol: 1.7120442169962917, max viol: 1.7393277850933373 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2670867443084717, valid regret : -0.2758755087852478 \n",
      "---------------------------------------iteration: 799\n",
      "l1 decision: 0.08907065540552139\n",
      "l1 weight: 0.1512310802936554\n",
      "avg viol: 1.765508489002823, max viol: 1.7881711561931297 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2873409390449524, valid regret : -0.2821449637413025 \n",
      "---------------------------------------iteration: 800\n",
      "l1 decision: 0.08890531212091446\n",
      "l1 weight: 0.14891844987869263\n",
      "avg viol: 1.767811246016463, max viol: 1.786864729365334 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27704599499702454, valid regret : -0.2664968967437744 \n",
      "---------------------------------------iteration: 801\n",
      "l1 decision: 0.08930732309818268\n",
      "l1 weight: 0.15104363858699799\n",
      "avg viol: 1.7500712810386903, max viol: 1.7762649008072913 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2631669342517853, valid regret : -0.2549477517604828 \n",
      "---------------------------------------iteration: 802\n",
      "l1 decision: 0.08548223227262497\n",
      "l1 weight: 0.15007896721363068\n",
      "avg viol: 1.7047380973037798, max viol: 1.7266582397278398 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2580457031726837, valid regret : -0.2794917821884155 \n",
      "---------------------------------------iteration: 803\n",
      "l1 decision: 0.08787551522254944\n",
      "l1 weight: 0.15115392208099365\n",
      "avg viol: 1.7555970121301652, max viol: 1.7852686728583649 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2790842354297638, valid regret : -0.2735719084739685 \n",
      "---------------------------------------iteration: 804\n",
      "l1 decision: 0.08976419270038605\n",
      "l1 weight: 0.15243665874004364\n",
      "avg viol: 1.7692489396195743, max viol: 1.7968205112265423 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27296873927116394, valid regret : -0.27860134840011597 \n",
      "---------------------------------------iteration: 805\n",
      "l1 decision: 0.08862223476171494\n",
      "l1 weight: 0.15110939741134644\n",
      "avg viol: 1.7698726269560574, max viol: 1.792493227054365 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2845989763736725, valid regret : -0.2822974920272827 \n",
      "---------------------------------------iteration: 806\n",
      "l1 decision: 0.09090006351470947\n",
      "l1 weight: 0.1539040058851242\n",
      "avg viol: 1.7718429372261744, max viol: 1.7933458497282118 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2779686748981476, valid regret : -0.26580530405044556 \n",
      "---------------------------------------iteration: 807\n",
      "l1 decision: 0.086931012570858\n",
      "l1 weight: 0.15467733144760132\n",
      "avg viol: 1.7389637418976054, max viol: 1.7595985301304609 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2579963505268097, valid regret : -0.2776486873626709 \n",
      "---------------------------------------iteration: 808\n",
      "l1 decision: 0.08954837173223495\n",
      "l1 weight: 0.15191707015037537\n",
      "avg viol: 1.7701301970821806, max viol: 1.7942876680754125 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28471803665161133, valid regret : -0.28490760922431946 \n",
      "---------------------------------------iteration: 809\n",
      "l1 decision: 0.08884977549314499\n",
      "l1 weight: 0.15055085718631744\n",
      "avg viol: 1.7721533577927766, max viol: 1.7990165540250018 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27899283170700073, valid regret : -0.27404823899269104 \n",
      "---------------------------------------iteration: 810\n",
      "l1 decision: 0.0901000127196312\n",
      "l1 weight: 0.151839941740036\n",
      "avg viol: 1.7732919883704745, max viol: 1.7971427193842828 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2856312096118927, valid regret : -0.2714712619781494 \n",
      "---------------------------------------iteration: 811\n",
      "l1 decision: 0.08660674095153809\n",
      "l1 weight: 0.15093378722667694\n",
      "avg viol: 1.7328132169512174, max viol: 1.7629377488046885 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27925318479537964, valid regret : -0.27391865849494934 \n",
      "---------------------------------------iteration: 812\n",
      "l1 decision: 0.09018153697252274\n",
      "l1 weight: 0.15064725279808044\n",
      "avg viol: 1.7437258859124267, max viol: 1.773699585814029 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.266329288482666, valid regret : -0.2594570517539978 \n",
      "---------------------------------------iteration: 813\n",
      "l1 decision: 0.08680881559848785\n",
      "l1 weight: 0.1501539945602417\n",
      "avg viol: 1.733895553111215, max viol: 1.7537666945718229 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2573655843734741, valid regret : -0.2713186740875244 \n",
      "---------------------------------------iteration: 814\n",
      "l1 decision: 0.08863374590873718\n",
      "l1 weight: 0.15070438385009766\n",
      "avg viol: 1.7580662162974476, max viol: 1.7799224122427404 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2766496241092682, valid regret : -0.27924644947052 \n",
      "---------------------------------------iteration: 815\n",
      "l1 decision: 0.08824940025806427\n",
      "l1 weight: 0.15110161900520325\n",
      "avg viol: 1.7610030297079355, max viol: 1.7804665928706527 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27881747484207153, valid regret : -0.26493754982948303 \n",
      "---------------------------------------iteration: 816\n",
      "l1 decision: 0.08933590352535248\n",
      "l1 weight: 0.15179511904716492\n",
      "avg viol: 1.7465777768346016, max viol: 1.7664800183847547 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26645997166633606, valid regret : -0.2597765624523163 \n",
      "---------------------------------------iteration: 817\n",
      "l1 decision: 0.08669863641262054\n",
      "l1 weight: 0.1516963094472885\n",
      "avg viol: 1.7294047938328003, max viol: 1.7438897078391165 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26708152890205383, valid regret : -0.2810195982456207 \n",
      "---------------------------------------iteration: 818\n",
      "l1 decision: 0.08830508589744568\n",
      "l1 weight: 0.15362119674682617\n",
      "avg viol: 1.7611958680697717, max viol: 1.7865478284657001 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2759780287742615, valid regret : -0.27413561940193176 \n",
      "---------------------------------------iteration: 819\n",
      "l1 decision: 0.08995521068572998\n",
      "l1 weight: 0.15397560596466064\n",
      "avg viol: 1.7750362728906475, max viol: 1.798624110640958 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2660101354122162, valid regret : -0.27865052223205566 \n",
      "---------------------------------------iteration: 820\n",
      "l1 decision: 0.08845318853855133\n",
      "l1 weight: 0.15181869268417358\n",
      "avg viol: 1.7638962902579807, max viol: 1.7955066609429196 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28415337204933167, valid regret : -0.28494498133659363 \n",
      "---------------------------------------iteration: 821\n",
      "l1 decision: 0.08992942422628403\n",
      "l1 weight: 0.15096932649612427\n",
      "avg viol: 1.7771437486919968, max viol: 1.8036532499827445 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2786894738674164, valid regret : -0.27515050768852234 \n",
      "---------------------------------------iteration: 822\n",
      "l1 decision: 0.08866416662931442\n",
      "l1 weight: 0.15179359912872314\n",
      "avg viol: 1.7672060765133937, max viol: 1.7950938523281366 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.284723162651062, valid regret : -0.28045082092285156 \n",
      "---------------------------------------iteration: 823\n",
      "l1 decision: 0.08979352563619614\n",
      "l1 weight: 0.1514786183834076\n",
      "avg viol: 1.7771595570953105, max viol: 1.8002995704300702 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29077208042144775, valid regret : -0.2769738733768463 \n",
      "---------------------------------------iteration: 824\n",
      "l1 decision: 0.0888432115316391\n",
      "l1 weight: 0.14993217587471008\n",
      "avg viol: 1.7474231849482749, max viol: 1.7754043450113386 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27048495411872864, valid regret : -0.2590668499469757 \n",
      "---------------------------------------iteration: 825\n",
      "l1 decision: 0.08694856613874435\n",
      "l1 weight: 0.14956550300121307\n",
      "avg viol: 1.7294388395611895, max viol: 1.7507423354545608 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2552332580089569, valid regret : -0.27516457438468933 \n",
      "---------------------------------------iteration: 826\n",
      "l1 decision: 0.08797967433929443\n",
      "l1 weight: 0.1514580249786377\n",
      "avg viol: 1.7557677153612168, max viol: 1.780725932912901 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2794867157936096, valid regret : -0.2843402922153473 \n",
      "---------------------------------------iteration: 827\n",
      "l1 decision: 0.08945087343454361\n",
      "l1 weight: 0.15071363747119904\n",
      "avg viol: 1.7702808115897277, max viol: 1.797709361766465 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2814686894416809, valid regret : -0.27534595131874084 \n",
      "---------------------------------------iteration: 828\n",
      "l1 decision: 0.08945311605930328\n",
      "l1 weight: 0.15011602640151978\n",
      "avg viol: 1.768577487228904, max viol: 1.7922150483354926 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2752474248409271, valid regret : -0.2728174924850464 \n",
      "---------------------------------------iteration: 829\n",
      "l1 decision: 0.08786678314208984\n",
      "l1 weight: 0.15166118741035461\n",
      "avg viol: 1.752734222805593, max viol: 1.7720519681461155 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27692317962646484, valid regret : -0.2714058458805084 \n",
      "---------------------------------------iteration: 830\n",
      "l1 decision: 0.08978293836116791\n",
      "l1 weight: 0.15357965230941772\n",
      "avg viol: 1.7373256654152647, max viol: 1.7538121612742543 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26747819781303406, valid regret : -0.2532568573951721 \n",
      "---------------------------------------iteration: 831\n",
      "l1 decision: 0.08546070009469986\n",
      "l1 weight: 0.1540343463420868\n",
      "avg viol: 1.7120479794195853, max viol: 1.7334483433514833 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2460094392299652, valid regret : -0.2743861675262451 \n",
      "---------------------------------------iteration: 832\n",
      "l1 decision: 0.0878349021077156\n",
      "l1 weight: 0.15023502707481384\n",
      "avg viol: 1.75507018573815, max viol: 1.7768934059422463 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28227561712265015, valid regret : -0.28508102893829346 \n",
      "---------------------------------------iteration: 833\n",
      "l1 decision: 0.09054365754127502\n",
      "l1 weight: 0.150342658162117\n",
      "avg viol: 1.7827232389582788, max viol: 1.7997095853788778 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.280118465423584, valid regret : -0.27074673771858215 \n",
      "---------------------------------------iteration: 834\n",
      "l1 decision: 0.08805309236049652\n",
      "l1 weight: 0.1511908322572708\n",
      "avg viol: 1.7595876028039492, max viol: 1.7791609999258071 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28343310952186584, valid regret : -0.2750988006591797 \n",
      "---------------------------------------iteration: 835\n",
      "l1 decision: 0.09091323614120483\n",
      "l1 weight: 0.14992356300354004\n",
      "avg viol: 1.7644688889349345, max viol: 1.7849004352465272 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28584328293800354, valid regret : -0.2601543664932251 \n",
      "---------------------------------------iteration: 836\n",
      "l1 decision: 0.0852704644203186\n",
      "l1 weight: 0.14939162135124207\n",
      "avg viol: 1.7048865439218934, max viol: 1.7234688391909003 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25450247526168823, valid regret : -0.27048081159591675 \n",
      "---------------------------------------iteration: 837\n",
      "l1 decision: 0.08839229494333267\n",
      "l1 weight: 0.15021343529224396\n",
      "avg viol: 1.762443187010067, max viol: 1.7815027405740693 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26819121837615967, valid regret : -0.27882930636405945 \n",
      "---------------------------------------iteration: 838\n",
      "l1 decision: 0.08883504569530487\n",
      "l1 weight: 0.15078483521938324\n",
      "avg viol: 1.7698807601436237, max viol: 1.7944682269589975 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28277871012687683, valid regret : -0.28114184737205505 \n",
      "---------------------------------------iteration: 839\n",
      "l1 decision: 0.0900089293718338\n",
      "l1 weight: 0.1508949249982834\n",
      "avg viol: 1.7680027303518728, max viol: 1.788228927180171 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2816598117351532, valid regret : -0.26474785804748535 \n",
      "---------------------------------------iteration: 840\n",
      "l1 decision: 0.08692832291126251\n",
      "l1 weight: 0.15115389227867126\n",
      "avg viol: 1.7367074144078651, max viol: 1.7634583106264472 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2647329568862915, valid regret : -0.2745448052883148 \n",
      "---------------------------------------iteration: 841\n",
      "l1 decision: 0.0891985148191452\n",
      "l1 weight: 0.15246838331222534\n",
      "avg viol: 1.760671550593106, max viol: 1.7836703429929912 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2784631848335266, valid regret : -0.2773674726486206 \n",
      "---------------------------------------iteration: 842\n",
      "l1 decision: 0.08804461359977722\n",
      "l1 weight: 0.1525859832763672\n",
      "avg viol: 1.7550019134092145, max viol: 1.775934026692994 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27261409163475037, valid regret : -0.2676490545272827 \n",
      "---------------------------------------iteration: 843\n",
      "l1 decision: 0.08998572081327438\n",
      "l1 weight: 0.15401919186115265\n",
      "avg viol: 1.7595436701300786, max viol: 1.782055729534477 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26071932911872864, valid regret : -0.2572312653064728 \n",
      "---------------------------------------iteration: 844\n",
      "l1 decision: 0.0856311023235321\n",
      "l1 weight: 0.1509176790714264\n",
      "avg viol: 1.7164638145489153, max viol: 1.7338556421454996 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26464390754699707, valid regret : -0.2824113368988037 \n",
      "---------------------------------------iteration: 845\n",
      "l1 decision: 0.08889973163604736\n",
      "l1 weight: 0.15104490518569946\n",
      "avg viol: 1.7676053217951266, max viol: 1.7946247218642384 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2755085527896881, valid regret : -0.2738296091556549 \n",
      "---------------------------------------iteration: 846\n",
      "l1 decision: 0.08891995251178741\n",
      "l1 weight: 0.15145274996757507\n",
      "avg viol: 1.7711972271116792, max viol: 1.796569901984185 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2852138578891754, valid regret : -0.2769998610019684 \n",
      "---------------------------------------iteration: 847\n",
      "l1 decision: 0.09030935913324356\n",
      "l1 weight: 0.15037354826927185\n",
      "avg viol: 1.7690756841597612, max viol: 1.7901650249259546 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28821510076522827, valid regret : -0.2735266387462616 \n",
      "---------------------------------------iteration: 848\n",
      "l1 decision: 0.08735659718513489\n",
      "l1 weight: 0.1491391360759735\n",
      "avg viol: 1.7443751623353456, max viol: 1.7628233800642192 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26827776432037354, valid regret : -0.2719501554965973 \n",
      "---------------------------------------iteration: 849\n",
      "l1 decision: 0.08903682231903076\n",
      "l1 weight: 0.1503959596157074\n",
      "avg viol: 1.7643294046598021, max viol: 1.7883754270151258 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26782849431037903, valid regret : -0.27735093235969543 \n",
      "---------------------------------------iteration: 850\n",
      "l1 decision: 0.08882872760295868\n",
      "l1 weight: 0.1503152847290039\n",
      "avg viol: 1.765542447717671, max viol: 1.7897362837102264 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2812028229236603, valid regret : -0.2783142328262329 \n",
      "---------------------------------------iteration: 851\n",
      "l1 decision: 0.08949816972017288\n",
      "l1 weight: 0.15131776034832\n",
      "avg viol: 1.7563142482057446, max viol: 1.7766435421071947 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27802905440330505, valid regret : -0.2545498013496399 \n",
      "---------------------------------------iteration: 852\n",
      "l1 decision: 0.0861312672495842\n",
      "l1 weight: 0.14968670904636383\n",
      "avg viol: 1.7144463090237696, max viol: 1.733097294345498 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2560214698314667, valid regret : -0.2783924639225006 \n",
      "---------------------------------------iteration: 853\n",
      "l1 decision: 0.08876793086528778\n",
      "l1 weight: 0.15082013607025146\n",
      "avg viol: 1.7709915541337977, max viol: 1.7893277072580531 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28356555104255676, valid regret : -0.2859877645969391 \n",
      "---------------------------------------iteration: 854\n",
      "l1 decision: 0.08992141485214233\n",
      "l1 weight: 0.15288762748241425\n",
      "avg viol: 1.781932813015883, max viol: 1.802882131189108 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2811702787876129, valid regret : -0.2737950086593628 \n",
      "---------------------------------------iteration: 855\n",
      "l1 decision: 0.08848804980516434\n",
      "l1 weight: 0.15359723567962646\n",
      "avg viol: 1.7683135025197407, max viol: 1.787876021815464 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2658785283565521, valid regret : -0.2761651873588562 \n",
      "---------------------------------------iteration: 856\n",
      "l1 decision: 0.0907747894525528\n",
      "l1 weight: 0.1502848118543625\n",
      "avg viol: 1.7684498706937302, max viol: 1.7866969557944685 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28342345356941223, valid regret : -0.261112242937088 \n",
      "---------------------------------------iteration: 857\n",
      "l1 decision: 0.08501206338405609\n",
      "l1 weight: 0.14972925186157227\n",
      "avg viol: 1.70344846857246, max viol: 1.7263991883955896 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2539251744747162, valid regret : -0.2716960608959198 \n",
      "---------------------------------------iteration: 858\n",
      "l1 decision: 0.08841973543167114\n",
      "l1 weight: 0.15117929875850677\n",
      "avg viol: 1.7633282336874254, max viol: 1.7825373221421614 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28371912240982056, valid regret : -0.27884984016418457 \n",
      "---------------------------------------iteration: 859\n",
      "l1 decision: 0.08942216634750366\n",
      "l1 weight: 0.15025021135807037\n",
      "avg viol: 1.7769618520478252, max viol: 1.7977534404490143 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2908700704574585, valid regret : -0.2844128906726837 \n",
      "---------------------------------------iteration: 860\n",
      "l1 decision: 0.0895143672823906\n",
      "l1 weight: 0.14951501786708832\n",
      "avg viol: 1.7710788066103123, max viol: 1.795357669936493 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27790454030036926, valid regret : -0.26993420720100403 \n",
      "---------------------------------------iteration: 861\n",
      "l1 decision: 0.08796613663434982\n",
      "l1 weight: 0.14963136613368988\n",
      "avg viol: 1.758297743719304, max viol: 1.7804408301599324 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26822754740715027, valid regret : -0.27043822407722473 \n",
      "---------------------------------------iteration: 862\n",
      "l1 decision: 0.09062986075878143\n",
      "l1 weight: 0.15103287994861603\n",
      "avg viol: 1.7536336632765597, max viol: 1.7772076225373894 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2751217782497406, valid regret : -0.25570639967918396 \n",
      "---------------------------------------iteration: 863\n",
      "l1 decision: 0.08430711925029755\n",
      "l1 weight: 0.15003138780593872\n",
      "avg viol: 1.6919308819645085, max viol: 1.709519723430276 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25408104062080383, valid regret : -0.26812276244163513 \n",
      "---------------------------------------iteration: 864\n",
      "l1 decision: 0.08820491284132004\n",
      "l1 weight: 0.15089485049247742\n",
      "avg viol: 1.7538435313099763, max viol: 1.7803117072908208 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26902103424072266, valid regret : -0.2757125198841095 \n",
      "---------------------------------------iteration: 865\n",
      "l1 decision: 0.08842425793409348\n",
      "l1 weight: 0.1506580412387848\n",
      "avg viol: 1.7671247825070169, max viol: 1.7881717179552652 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28189006447792053, valid regret : -0.2824464738368988 \n",
      "---------------------------------------iteration: 866\n",
      "l1 decision: 0.09040272235870361\n",
      "l1 weight: 0.153221994638443\n",
      "avg viol: 1.7713209129299503, max viol: 1.7913588505471125 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27891600131988525, valid regret : -0.2658350169658661 \n",
      "---------------------------------------iteration: 867\n",
      "l1 decision: 0.08790738135576248\n",
      "l1 weight: 0.15344548225402832\n",
      "avg viol: 1.7503086681384594, max viol: 1.7695345170795918 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2588431239128113, valid regret : -0.27180200815200806 \n",
      "---------------------------------------iteration: 868\n",
      "l1 decision: 0.08841624110937119\n",
      "l1 weight: 0.15185429155826569\n",
      "avg viol: 1.7523706753284205, max viol: 1.7774457186460495 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2782552242279053, valid regret : -0.2742895185947418 \n",
      "---------------------------------------iteration: 869\n",
      "l1 decision: 0.08908462524414062\n",
      "l1 weight: 0.15080499649047852\n",
      "avg viol: 1.7483766541315708, max viol: 1.7654511788859963 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2683582007884979, valid regret : -0.26633599400520325 \n",
      "---------------------------------------iteration: 870\n",
      "l1 decision: 0.08859871327877045\n",
      "l1 weight: 0.15156365931034088\n",
      "avg viol: 1.7472243955655722, max viol: 1.7693359901895747 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27695903182029724, valid regret : -0.26820316910743713 \n",
      "---------------------------------------iteration: 871\n",
      "l1 decision: 0.08800043910741806\n",
      "l1 weight: 0.14980283379554749\n",
      "avg viol: 1.742636114610359, max viol: 1.7640067371539772 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27830883860588074, valid regret : -0.2811225652694702 \n",
      "---------------------------------------iteration: 872\n",
      "l1 decision: 0.08889419585466385\n",
      "l1 weight: 0.1498422622680664\n",
      "avg viol: 1.761524048175197, max viol: 1.7875883858650923 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2744641602039337, valid regret : -0.26685744524002075 \n",
      "---------------------------------------iteration: 873\n",
      "l1 decision: 0.08768830448389053\n",
      "l1 weight: 0.14983361959457397\n",
      "avg viol: 1.7496950820868369, max viol: 1.7702700425870717 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26300692558288574, valid regret : -0.27710726857185364 \n",
      "---------------------------------------iteration: 874\n",
      "l1 decision: 0.08902902156114578\n",
      "l1 weight: 0.15083923935890198\n",
      "avg viol: 1.7676747632503975, max viol: 1.7901698895730078 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28108012676239014, valid regret : -0.2788541913032532 \n",
      "---------------------------------------iteration: 875\n",
      "l1 decision: 0.0888814926147461\n",
      "l1 weight: 0.15019699931144714\n",
      "avg viol: 1.757632025287021, max viol: 1.7788816366810352 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2769375145435333, valid regret : -0.26991507411003113 \n",
      "---------------------------------------iteration: 876\n",
      "l1 decision: 0.08944710344076157\n",
      "l1 weight: 0.15125510096549988\n",
      "avg viol: 1.7586609557073098, max viol: 1.7806341745890677 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2706429362297058, valid regret : -0.2603631019592285 \n",
      "---------------------------------------iteration: 877\n",
      "l1 decision: 0.08586229383945465\n",
      "l1 weight: 0.15021711587905884\n",
      "avg viol: 1.7199378998909378, max viol: 1.7411993442801759 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.264077752828598, valid regret : -0.28211355209350586 \n",
      "---------------------------------------iteration: 878\n",
      "l1 decision: 0.08875834196805954\n",
      "l1 weight: 0.15278415381908417\n",
      "avg viol: 1.7684501037605513, max viol: 1.790330297430046 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2779553532600403, valid regret : -0.27532288432121277 \n",
      "---------------------------------------iteration: 879\n",
      "l1 decision: 0.08940573036670685\n",
      "l1 weight: 0.15334588289260864\n",
      "avg viol: 1.7711909409640065, max viol: 1.798079602769576 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26488375663757324, valid regret : -0.28032293915748596 \n",
      "---------------------------------------iteration: 880\n",
      "l1 decision: 0.08934803307056427\n",
      "l1 weight: 0.15063253045082092\n",
      "avg viol: 1.776978736150195, max viol: 1.7961058841319755 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2875073552131653, valid regret : -0.28439921140670776 \n",
      "---------------------------------------iteration: 881\n",
      "l1 decision: 0.08884956687688828\n",
      "l1 weight: 0.15017648041248322\n",
      "avg viol: 1.768787465688947, max viol: 1.7927635530941188 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27679604291915894, valid regret : -0.2721973955631256 \n",
      "---------------------------------------iteration: 882\n",
      "l1 decision: 0.08996785432100296\n",
      "l1 weight: 0.1511760801076889\n",
      "avg viol: 1.7638492919423152, max viol: 1.7834900398738682 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2823043465614319, valid regret : -0.25997549295425415 \n",
      "---------------------------------------iteration: 883\n",
      "l1 decision: 0.08518297225236893\n",
      "l1 weight: 0.1494651883840561\n",
      "avg viol: 1.7079139292996843, max viol: 1.7399386413162574 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2664738595485687, valid regret : -0.2819989025592804 \n",
      "---------------------------------------iteration: 884\n",
      "l1 decision: 0.08935414999723434\n",
      "l1 weight: 0.1496174931526184\n",
      "avg viol: 1.7665121470671148, max viol: 1.7914960961788893 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.274852454662323, valid regret : -0.2743088901042938 \n",
      "---------------------------------------iteration: 885\n",
      "l1 decision: 0.08854485303163528\n",
      "l1 weight: 0.14952510595321655\n",
      "avg viol: 1.7690534434462097, max viol: 1.7923851266968995 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2715758681297302, valid regret : -0.27955323457717896 \n",
      "---------------------------------------iteration: 886\n",
      "l1 decision: 0.0897405669093132\n",
      "l1 weight: 0.1507704108953476\n",
      "avg viol: 1.7529268209205475, max viol: 1.7961605170276016 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2747615575790405, valid regret : -0.2730572521686554 \n",
      "---------------------------------------iteration: 887\n",
      "l1 decision: 0.08681479096412659\n",
      "l1 weight: 0.1507638394832611\n",
      "avg viol: 1.7387515084294136, max viol: 1.764298197813332 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27169695496559143, valid regret : -0.2726413607597351 \n",
      "---------------------------------------iteration: 888\n",
      "l1 decision: 0.0903533548116684\n",
      "l1 weight: 0.14986780285835266\n",
      "avg viol: 1.7720932399947196, max viol: 1.7932064366759732 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27350831031799316, valid regret : -0.2746042311191559 \n",
      "---------------------------------------iteration: 889\n",
      "l1 decision: 0.08745207637548447\n",
      "l1 weight: 0.15087740123271942\n",
      "avg viol: 1.7498201295663602, max viol: 1.77581378351897 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27803152799606323, valid regret : -0.28167834877967834 \n",
      "---------------------------------------iteration: 890\n",
      "l1 decision: 0.09016866236925125\n",
      "l1 weight: 0.15321961045265198\n",
      "avg viol: 1.770019165377016, max viol: 1.7905316940741614 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2772969603538513, valid regret : -0.266389399766922 \n",
      "---------------------------------------iteration: 891\n",
      "l1 decision: 0.08721023797988892\n",
      "l1 weight: 0.1522231101989746\n",
      "avg viol: 1.7444048389059026, max viol: 1.767945267725736 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25718215107917786, valid regret : -0.27669620513916016 \n",
      "---------------------------------------iteration: 892\n",
      "l1 decision: 0.08861491829156876\n",
      "l1 weight: 0.15050077438354492\n",
      "avg viol: 1.762544461733778, max viol: 1.7900404492393136 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2808080315589905, valid regret : -0.2755739688873291 \n",
      "---------------------------------------iteration: 893\n",
      "l1 decision: 0.08892562985420227\n",
      "l1 weight: 0.14990977942943573\n",
      "avg viol: 1.754274163453374, max viol: 1.7688859634799883 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27077972888946533, valid regret : -0.26865893602371216 \n",
      "---------------------------------------iteration: 894\n",
      "l1 decision: 0.08901116997003555\n",
      "l1 weight: 0.15138669312000275\n",
      "avg viol: 1.7537813923502108, max viol: 1.7765260768355802 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2794482409954071, valid regret : -0.2737465500831604 \n",
      "---------------------------------------iteration: 895\n",
      "l1 decision: 0.0882595106959343\n",
      "l1 weight: 0.1497916430234909\n",
      "avg viol: 1.760915370224393, max viol: 1.7791769666364416 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2857799530029297, valid regret : -0.2804441452026367 \n",
      "---------------------------------------iteration: 896\n",
      "l1 decision: 0.08999762684106827\n",
      "l1 weight: 0.14868134260177612\n",
      "avg viol: 1.7603119310585316, max viol: 1.7818723793607205 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.274049311876297, valid regret : -0.263019323348999 \n",
      "---------------------------------------iteration: 897\n",
      "l1 decision: 0.08706080913543701\n",
      "l1 weight: 0.14871858060359955\n",
      "avg viol: 1.7386963087518235, max viol: 1.7582948610652238 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2598640024662018, valid regret : -0.27481913566589355 \n",
      "---------------------------------------iteration: 898\n",
      "l1 decision: 0.08851119875907898\n",
      "l1 weight: 0.15013937652111053\n",
      "avg viol: 1.7478533534123561, max viol: 1.7817847506375983 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2744903564453125, valid regret : -0.27704712748527527 \n",
      "---------------------------------------iteration: 899\n",
      "l1 decision: 0.0873224288225174\n",
      "l1 weight: 0.1524408608675003\n",
      "avg viol: 1.7363047747989184, max viol: 1.784778430359438 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26978087425231934, valid regret : -0.2735602557659149 \n",
      "---------------------------------------iteration: 900\n",
      "l1 decision: 0.08971817791461945\n",
      "l1 weight: 0.14909107983112335\n",
      "avg viol: 1.77077184880618, max viol: 1.793234494049102 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27483147382736206, valid regret : -0.26952922344207764 \n",
      "---------------------------------------iteration: 901\n",
      "l1 decision: 0.08739323168992996\n",
      "l1 weight: 0.1510147750377655\n",
      "avg viol: 1.7457835465320386, max viol: 1.7641936782747507 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2734706997871399, valid regret : -0.2797718644142151 \n",
      "---------------------------------------iteration: 902\n",
      "l1 decision: 0.08919554948806763\n",
      "l1 weight: 0.15308700501918793\n",
      "avg viol: 1.761669911511708, max viol: 1.7855795049108565 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2749078571796417, valid regret : -0.2489531934261322 \n",
      "---------------------------------------iteration: 903\n",
      "l1 decision: 0.0881652906537056\n",
      "l1 weight: 0.15408356487751007\n",
      "avg viol: 1.7395954125921707, max viol: 1.7681519030593336 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25481417775154114, valid regret : -0.26839491724967957 \n",
      "---------------------------------------iteration: 904\n",
      "l1 decision: 0.08819945156574249\n",
      "l1 weight: 0.15292976796627045\n",
      "avg viol: 1.7591229705075966, max viol: 1.797995936125517 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.281238853931427, valid regret : -0.27482834458351135 \n",
      "---------------------------------------iteration: 905\n",
      "l1 decision: 0.08926235139369965\n",
      "l1 weight: 0.1511041671037674\n",
      "avg viol: 1.7734903826831214, max viol: 1.8000211118487641 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.278051495552063, valid regret : -0.2637692391872406 \n",
      "---------------------------------------iteration: 906\n",
      "l1 decision: 0.08838720619678497\n",
      "l1 weight: 0.15299491584300995\n",
      "avg viol: 1.7542693190622958, max viol: 1.7988790944218636 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2790282964706421, valid regret : -0.26969653367996216 \n",
      "---------------------------------------iteration: 907\n",
      "l1 decision: 0.08659136295318604\n",
      "l1 weight: 0.15176551043987274\n",
      "avg viol: 1.7311710458056768, max viol: 1.7713437359780073 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2736234962940216, valid regret : -0.2806294560432434 \n",
      "---------------------------------------iteration: 908\n",
      "l1 decision: 0.08971040695905685\n",
      "l1 weight: 0.14874045550823212\n",
      "avg viol: 1.7583271513239014, max viol: 1.7949243653565645 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27026063203811646, valid regret : -0.2620857357978821 \n",
      "---------------------------------------iteration: 909\n",
      "l1 decision: 0.08654147386550903\n",
      "l1 weight: 0.15001927316188812\n",
      "avg viol: 1.7326007463259157, max viol: 1.7621889014262706 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25921204686164856, valid regret : -0.2752648890018463 \n",
      "---------------------------------------iteration: 910\n",
      "l1 decision: 0.08826952427625656\n",
      "l1 weight: 0.15227191150188446\n",
      "avg viol: 1.7474716801848262, max viol: 1.7923410241492093 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2730499505996704, valid regret : -0.2763475477695465 \n",
      "---------------------------------------iteration: 911\n",
      "l1 decision: 0.0875229611992836\n",
      "l1 weight: 0.1523991972208023\n",
      "avg viol: 1.748086924549425, max viol: 1.7828231013845652 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2733447849750519, valid regret : -0.2693249583244324 \n",
      "---------------------------------------iteration: 912\n",
      "l1 decision: 0.08919471502304077\n",
      "l1 weight: 0.1498388797044754\n",
      "avg viol: 1.763445776089793, max viol: 1.7913894951343536 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2713223397731781, valid regret : -0.2702438533306122 \n",
      "---------------------------------------iteration: 913\n",
      "l1 decision: 0.08762036263942719\n",
      "l1 weight: 0.15230360627174377\n",
      "avg viol: 1.7474870662856847, max viol: 1.7755273511866108 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2738308608531952, valid regret : -0.28232842683792114 \n",
      "---------------------------------------iteration: 914\n",
      "l1 decision: 0.08877257257699966\n",
      "l1 weight: 0.15402299165725708\n",
      "avg viol: 1.7629227229219395, max viol: 1.7931672324193642 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27496597170829773, valid regret : -0.2703728675842285 \n",
      "---------------------------------------iteration: 915\n",
      "l1 decision: 0.08840266615152359\n",
      "l1 weight: 0.15379129350185394\n",
      "avg viol: 1.759609921120573, max viol: 1.789237756980583 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26183319091796875, valid regret : -0.274916410446167 \n",
      "---------------------------------------iteration: 916\n",
      "l1 decision: 0.08901660144329071\n",
      "l1 weight: 0.15238116681575775\n",
      "avg viol: 1.7588935167976887, max viol: 1.7870639865286648 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2814335227012634, valid regret : -0.26989859342575073 \n",
      "---------------------------------------iteration: 917\n",
      "l1 decision: 0.08702513575553894\n",
      "l1 weight: 0.1505497395992279\n",
      "avg viol: 1.7380024384974968, max viol: 1.757608110550791 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2645189166069031, valid regret : -0.27153265476226807 \n",
      "---------------------------------------iteration: 918\n",
      "l1 decision: 0.08837110549211502\n",
      "l1 weight: 0.15126298367977142\n",
      "avg viol: 1.760246221005218, max viol: 1.7874855590052903 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28125205636024475, valid regret : -0.27599453926086426 \n",
      "---------------------------------------iteration: 919\n",
      "l1 decision: 0.08878905326128006\n",
      "l1 weight: 0.1510985791683197\n",
      "avg viol: 1.7602286550366626, max viol: 1.7898312170000281 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28441011905670166, valid regret : -0.2822697162628174 \n",
      "---------------------------------------iteration: 920\n",
      "l1 decision: 0.08916798233985901\n",
      "l1 weight: 0.1486402451992035\n",
      "avg viol: 1.759804512936971, max viol: 1.7860370132839307 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2745872735977173, valid regret : -0.26373031735420227 \n",
      "---------------------------------------iteration: 921\n",
      "l1 decision: 0.08786913752555847\n",
      "l1 weight: 0.15010784566402435\n",
      "avg viol: 1.7349231381400023, max viol: 1.7670557801611722 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25734013319015503, valid regret : -0.26765307784080505 \n",
      "---------------------------------------iteration: 922\n",
      "l1 decision: 0.08772890269756317\n",
      "l1 weight: 0.1522320806980133\n",
      "avg viol: 1.7317419494478963, max viol: 1.7600957795511931 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27079829573631287, valid regret : -0.27674010396003723 \n",
      "---------------------------------------iteration: 923\n",
      "l1 decision: 0.08800498396158218\n",
      "l1 weight: 0.15145744383335114\n",
      "avg viol: 1.7445957363129128, max viol: 1.7780533258337528 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27162429690361023, valid regret : -0.2732899785041809 \n",
      "---------------------------------------iteration: 924\n",
      "l1 decision: 0.08903048932552338\n",
      "l1 weight: 0.1492217779159546\n",
      "avg viol: 1.7700853865256068, max viol: 1.7927268558414653 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2752250134944916, valid regret : -0.27717125415802 \n",
      "---------------------------------------iteration: 925\n",
      "l1 decision: 0.08862510323524475\n",
      "l1 weight: 0.15188798308372498\n",
      "avg viol: 1.7688993307072087, max viol: 1.7907314179465175 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28164875507354736, valid regret : -0.2827795147895813 \n",
      "---------------------------------------iteration: 926\n",
      "l1 decision: 0.09006651490926743\n",
      "l1 weight: 0.15274792909622192\n",
      "avg viol: 1.775262050515157, max viol: 1.7952110529877245 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2789894640445709, valid regret : -0.26609939336776733 \n",
      "---------------------------------------iteration: 927\n",
      "l1 decision: 0.08720558881759644\n",
      "l1 weight: 0.1530333161354065\n",
      "avg viol: 1.7435369464725954, max viol: 1.7640291082207114 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2581828832626343, valid regret : -0.2800179123878479 \n",
      "---------------------------------------iteration: 928\n",
      "l1 decision: 0.0897187814116478\n",
      "l1 weight: 0.1517665982246399\n",
      "avg viol: 1.7774745562952012, max viol: 1.8016473609022796 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28676536679267883, valid regret : -0.28314539790153503 \n",
      "---------------------------------------iteration: 929\n",
      "l1 decision: 0.08853001892566681\n",
      "l1 weight: 0.1506299376487732\n",
      "avg viol: 1.7672569691323587, max viol: 1.7935192417935468 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27755823731422424, valid regret : -0.27237868309020996 \n",
      "---------------------------------------iteration: 930\n",
      "l1 decision: 0.0905502513051033\n",
      "l1 weight: 0.15106773376464844\n",
      "avg viol: 1.7675050483405357, max viol: 1.7931092448998243 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28211984038352966, valid regret : -0.2606186270713806 \n",
      "---------------------------------------iteration: 931\n",
      "l1 decision: 0.08501037955284119\n",
      "l1 weight: 0.1494520902633667\n",
      "avg viol: 1.7043881074007368, max viol: 1.7373823794769123 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26633796095848083, valid regret : -0.28216809034347534 \n",
      "---------------------------------------iteration: 932\n",
      "l1 decision: 0.08872024714946747\n",
      "l1 weight: 0.14898711442947388\n",
      "avg viol: 1.7654249928804346, max viol: 1.7892745060380548 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27522704005241394, valid regret : -0.2742176353931427 \n",
      "---------------------------------------iteration: 933\n",
      "l1 decision: 0.08891407400369644\n",
      "l1 weight: 0.149649977684021\n",
      "avg viol: 1.7721330946330272, max viol: 1.799584863241762 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2709081470966339, valid regret : -0.27778729796409607 \n",
      "---------------------------------------iteration: 934\n",
      "l1 decision: 0.08900953829288483\n",
      "l1 weight: 0.15095479786396027\n",
      "avg viol: 1.76139584457851, max viol: 1.7917671678587794 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27813780307769775, valid regret : -0.2797580063343048 \n",
      "---------------------------------------iteration: 935\n",
      "l1 decision: 0.0886181965470314\n",
      "l1 weight: 0.15188632905483246\n",
      "avg viol: 1.762675649529556, max viol: 1.7843402967555448 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27920711040496826, valid regret : -0.26862651109695435 \n",
      "---------------------------------------iteration: 936\n",
      "l1 decision: 0.08960531651973724\n",
      "l1 weight: 0.14882931113243103\n",
      "avg viol: 1.7610849680926186, max viol: 1.786477773450315 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2711416184902191, valid regret : -0.26327574253082275 \n",
      "---------------------------------------iteration: 937\n",
      "l1 decision: 0.08679870516061783\n",
      "l1 weight: 0.15114133059978485\n",
      "avg viol: 1.7338940605608513, max viol: 1.7548909111646935 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2685084044933319, valid regret : -0.2797503173351288 \n",
      "---------------------------------------iteration: 938\n",
      "l1 decision: 0.08905182778835297\n",
      "l1 weight: 0.1534375548362732\n",
      "avg viol: 1.7638724156550598, max viol: 1.7866945285350084 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2748268246650696, valid regret : -0.27226799726486206 \n",
      "---------------------------------------iteration: 939\n",
      "l1 decision: 0.08902060240507126\n",
      "l1 weight: 0.15316887199878693\n",
      "avg viol: 1.7725772885313562, max viol: 1.7971628692466766 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2661081552505493, valid regret : -0.2799040973186493 \n",
      "---------------------------------------iteration: 940\n",
      "l1 decision: 0.08906260877847672\n",
      "l1 weight: 0.15218381583690643\n",
      "avg viol: 1.7737409439487966, max viol: 1.801996128866449 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.286854088306427, valid regret : -0.2834472954273224 \n",
      "---------------------------------------iteration: 941\n",
      "l1 decision: 0.08870657533407211\n",
      "l1 weight: 0.15004122257232666\n",
      "avg viol: 1.771255160903529, max viol: 1.7950746612623334 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27885565161705017, valid regret : -0.26529252529144287 \n",
      "---------------------------------------iteration: 942\n",
      "l1 decision: 0.08998002111911774\n",
      "l1 weight: 0.15177354216575623\n",
      "avg viol: 1.7482781905389857, max viol: 1.7770547501277179 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2763238251209259, valid regret : -0.2585159242153168 \n",
      "---------------------------------------iteration: 943\n",
      "l1 decision: 0.08540569990873337\n",
      "l1 weight: 0.14993610978126526\n",
      "avg viol: 1.7113977407175116, max viol: 1.7373004832770675 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2664664387702942, valid regret : -0.2774800956249237 \n",
      "---------------------------------------iteration: 944\n",
      "l1 decision: 0.08888567984104156\n",
      "l1 weight: 0.14941328763961792\n",
      "avg viol: 1.7568098265433219, max viol: 1.779527511447668 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2713392376899719, valid regret : -0.27312901616096497 \n",
      "---------------------------------------iteration: 945\n",
      "l1 decision: 0.08863970637321472\n",
      "l1 weight: 0.1491968035697937\n",
      "avg viol: 1.7698542386453482, max viol: 1.792859244684223 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2700841724872589, valid regret : -0.28037282824516296 \n",
      "---------------------------------------iteration: 946\n",
      "l1 decision: 0.08984499424695969\n",
      "l1 weight: 0.14925386011600494\n",
      "avg viol: 1.7783688972727396, max viol: 1.8008064306341112 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28326451778411865, valid regret : -0.28387534618377686 \n",
      "---------------------------------------iteration: 947\n",
      "l1 decision: 0.08841602504253387\n",
      "l1 weight: 0.1504460722208023\n",
      "avg viol: 1.7667176255559025, max viol: 1.7931694348808378 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28180474042892456, valid regret : -0.2692444622516632 \n",
      "---------------------------------------iteration: 948\n",
      "l1 decision: 0.0908292755484581\n",
      "l1 weight: 0.14862807095050812\n",
      "avg viol: 1.7679763231839751, max viol: 1.787904956145212 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27282026410102844, valid regret : -0.2605450749397278 \n",
      "---------------------------------------iteration: 949\n",
      "l1 decision: 0.08577286452054977\n",
      "l1 weight: 0.15112783014774323\n",
      "avg viol: 1.7190325016557473, max viol: 1.735773173160851 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.264517605304718, valid regret : -0.278777152299881 \n",
      "---------------------------------------iteration: 950\n",
      "l1 decision: 0.08917491883039474\n",
      "l1 weight: 0.15261191129684448\n",
      "avg viol: 1.759760740454658, max viol: 1.7806259816279635 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27325764298439026, valid regret : -0.27190151810646057 \n",
      "---------------------------------------iteration: 951\n",
      "l1 decision: 0.08834072202444077\n",
      "l1 weight: 0.1520630121231079\n",
      "avg viol: 1.7648819143431864, max viol: 1.7886895854608156 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26547518372535706, valid regret : -0.28028804063796997 \n",
      "---------------------------------------iteration: 952\n",
      "l1 decision: 0.09024274349212646\n",
      "l1 weight: 0.15106569230556488\n",
      "avg viol: 1.7786736251408002, max viol: 1.8000881087500602 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28750529885292053, valid regret : -0.28343021869659424 \n",
      "---------------------------------------iteration: 953\n",
      "l1 decision: 0.08859976381063461\n",
      "l1 weight: 0.14973588287830353\n",
      "avg viol: 1.7700279930065153, max viol: 1.7938582254573703 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27827757596969604, valid regret : -0.2689100503921509 \n",
      "---------------------------------------iteration: 954\n",
      "l1 decision: 0.09032931178808212\n",
      "l1 weight: 0.15071295201778412\n",
      "avg viol: 1.7642237016942817, max viol: 1.7868610450532287 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28210338950157166, valid regret : -0.26437145471572876 \n",
      "---------------------------------------iteration: 955\n",
      "l1 decision: 0.08640113472938538\n",
      "l1 weight: 0.14874295890331268\n",
      "avg viol: 1.7328447194438195, max viol: 1.7539442859124392 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27378660440444946, valid regret : -0.2792676091194153 \n",
      "---------------------------------------iteration: 956\n",
      "l1 decision: 0.0890723392367363\n",
      "l1 weight: 0.14901217818260193\n",
      "avg viol: 1.7559646563563729, max viol: 1.7868006058270112 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2715994417667389, valid regret : -0.2734314203262329 \n",
      "---------------------------------------iteration: 957\n",
      "l1 decision: 0.08892332017421722\n",
      "l1 weight: 0.14966349303722382\n",
      "avg viol: 1.7716004625652386, max viol: 1.7988762290333398 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27042973041534424, valid regret : -0.27990877628326416 \n",
      "---------------------------------------iteration: 958\n",
      "l1 decision: 0.08913113176822662\n",
      "l1 weight: 0.15094764530658722\n",
      "avg viol: 1.7708830161276274, max viol: 1.7978931629331782 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28203704953193665, valid regret : -0.2834921181201935 \n",
      "---------------------------------------iteration: 959\n",
      "l1 decision: 0.08909031003713608\n",
      "l1 weight: 0.15137925744056702\n",
      "avg viol: 1.7713808772154152, max viol: 1.7941865983884782 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2823428511619568, valid regret : -0.2687895894050598 \n",
      "---------------------------------------iteration: 960\n",
      "l1 decision: 0.089604951441288\n",
      "l1 weight: 0.14900541305541992\n",
      "avg viol: 1.7609711399284425, max viol: 1.7837838812265545 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2719907760620117, valid regret : -0.2625432312488556 \n",
      "---------------------------------------iteration: 961\n",
      "l1 decision: 0.08652874082326889\n",
      "l1 weight: 0.15135928988456726\n",
      "avg viol: 1.725194577195798, max viol: 1.7493750229477882 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2652522325515747, valid regret : -0.28134793043136597 \n",
      "---------------------------------------iteration: 962\n",
      "l1 decision: 0.0881541520357132\n",
      "l1 weight: 0.15316852927207947\n",
      "avg viol: 1.7598031842222555, max viol: 1.790079538943246 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27474966645240784, valid regret : -0.2758125364780426 \n",
      "---------------------------------------iteration: 963\n",
      "l1 decision: 0.08977474272251129\n",
      "l1 weight: 0.15307947993278503\n",
      "avg viol: 1.7785632752199854, max viol: 1.7983635176206008 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26766717433929443, valid regret : -0.2782253324985504 \n",
      "---------------------------------------iteration: 964\n",
      "l1 decision: 0.0891265869140625\n",
      "l1 weight: 0.1506624072790146\n",
      "avg viol: 1.7697667562536663, max viol: 1.7935848475899547 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.285763680934906, valid regret : -0.27731841802597046 \n",
      "---------------------------------------iteration: 965\n",
      "l1 decision: 0.0886225476861\n",
      "l1 weight: 0.15116220712661743\n",
      "avg viol: 1.7516194515675307, max viol: 1.7782999137416482 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2699241042137146, valid regret : -0.264506459236145 \n",
      "---------------------------------------iteration: 966\n",
      "l1 decision: 0.08815060555934906\n",
      "l1 weight: 0.1519978642463684\n",
      "avg viol: 1.7367496055428637, max viol: 1.7573289645370096 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2743132412433624, valid regret : -0.27117976546287537 \n",
      "---------------------------------------iteration: 967\n",
      "l1 decision: 0.08774561434984207\n",
      "l1 weight: 0.15014766156673431\n",
      "avg viol: 1.7475274124142015, max viol: 1.770537334959954 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2784857153892517, valid regret : -0.28176334500312805 \n",
      "---------------------------------------iteration: 968\n",
      "l1 decision: 0.08870768547058105\n",
      "l1 weight: 0.14977124333381653\n",
      "avg viol: 1.759603862693184, max viol: 1.795862200902775 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2741057574748993, valid regret : -0.2726115882396698 \n",
      "---------------------------------------iteration: 969\n",
      "l1 decision: 0.0882972925901413\n",
      "l1 weight: 0.1494462937116623\n",
      "avg viol: 1.7634253920969787, max viol: 1.786101615987718 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2689981758594513, valid regret : -0.2799753248691559 \n",
      "---------------------------------------iteration: 970\n",
      "l1 decision: 0.08992332220077515\n",
      "l1 weight: 0.1506858766078949\n",
      "avg viol: 1.7709082128613955, max viol: 1.7983903717249632 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28157326579093933, valid regret : -0.2794785499572754 \n",
      "---------------------------------------iteration: 971\n",
      "l1 decision: 0.08769839257001877\n",
      "l1 weight: 0.15169306099414825\n",
      "avg viol: 1.7527251594711561, max viol: 1.778301850776188 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27735140919685364, valid regret : -0.27503302693367004 \n",
      "---------------------------------------iteration: 972\n",
      "l1 decision: 0.09012673795223236\n",
      "l1 weight: 0.14912666380405426\n",
      "avg viol: 1.7771345673577161, max viol: 1.800326528493315 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27639368176460266, valid regret : -0.2748297154903412 \n",
      "---------------------------------------iteration: 973\n",
      "l1 decision: 0.08758936822414398\n",
      "l1 weight: 0.15116797387599945\n",
      "avg viol: 1.751804355098866, max viol: 1.780097991693765 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27710816264152527, valid regret : -0.2829912006855011 \n",
      "---------------------------------------iteration: 974\n",
      "l1 decision: 0.08954999595880508\n",
      "l1 weight: 0.1541212499141693\n",
      "avg viol: 1.768869187310338, max viol: 1.7991708328481764 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2768389880657196, valid regret : -0.26775476336479187 \n",
      "---------------------------------------iteration: 975\n",
      "l1 decision: 0.0876031294465065\n",
      "l1 weight: 0.15261328220367432\n",
      "avg viol: 1.7504791611508699, max viol: 1.7772109780926257 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25925615429878235, valid regret : -0.2745395600795746 \n",
      "---------------------------------------iteration: 976\n",
      "l1 decision: 0.089642733335495\n",
      "l1 weight: 0.1511608064174652\n",
      "avg viol: 1.7621236300974852, max viol: 1.7854404551908374 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28153958916664124, valid regret : -0.2684330940246582 \n",
      "---------------------------------------iteration: 977\n",
      "l1 decision: 0.08682417124509811\n",
      "l1 weight: 0.15040475130081177\n",
      "avg viol: 1.7333397872693603, max viol: 1.7568009628448635 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2629169821739197, valid regret : -0.2730278968811035 \n",
      "---------------------------------------iteration: 978\n",
      "l1 decision: 0.08893181383609772\n",
      "l1 weight: 0.15079520642757416\n",
      "avg viol: 1.7676085641724057, max viol: 1.7909704245394096 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28255438804626465, valid regret : -0.280215859413147 \n",
      "---------------------------------------iteration: 979\n",
      "l1 decision: 0.08865189552307129\n",
      "l1 weight: 0.1500219851732254\n",
      "avg viol: 1.7691306762615204, max viol: 1.7952759407344274 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2870938181877136, valid regret : -0.28541654348373413 \n",
      "---------------------------------------iteration: 980\n",
      "l1 decision: 0.09040798246860504\n",
      "l1 weight: 0.14755316078662872\n",
      "avg viol: 1.7813515796815045, max viol: 1.7996766068972647 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2793867588043213, valid regret : -0.2648523449897766 \n",
      "---------------------------------------iteration: 981\n",
      "l1 decision: 0.08706404268741608\n",
      "l1 weight: 0.14830872416496277\n",
      "avg viol: 1.742195128252497, max viol: 1.7643652842380106 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26139992475509644, valid regret : -0.276661217212677 \n",
      "---------------------------------------iteration: 982\n",
      "l1 decision: 0.0895100086927414\n",
      "l1 weight: 0.15022101998329163\n",
      "avg viol: 1.769135195557028, max viol: 1.7961935241473839 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2803674042224884, valid regret : -0.28290805220603943 \n",
      "---------------------------------------iteration: 983\n",
      "l1 decision: 0.08834206312894821\n",
      "l1 weight: 0.15047980844974518\n",
      "avg viol: 1.7651757179519518, max viol: 1.7921222472796217 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28106391429901123, valid regret : -0.27150383591651917 \n",
      "---------------------------------------iteration: 984\n",
      "l1 decision: 0.09073735773563385\n",
      "l1 weight: 0.14868104457855225\n",
      "avg viol: 1.770099299021531, max viol: 1.7911383612081409 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27339571714401245, valid regret : -0.2652854323387146 \n",
      "---------------------------------------iteration: 985\n",
      "l1 decision: 0.08630136400461197\n",
      "l1 weight: 0.15135742723941803\n",
      "avg viol: 1.7293333731702296, max viol: 1.7550250878557563 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.268581360578537, valid regret : -0.2816992998123169 \n",
      "---------------------------------------iteration: 986\n",
      "l1 decision: 0.08959058672189713\n",
      "l1 weight: 0.15211297571659088\n",
      "avg viol: 1.773871062094695, max viol: 1.7920222440734506 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27851542830467224, valid regret : -0.2768462896347046 \n",
      "---------------------------------------iteration: 987\n",
      "l1 decision: 0.0893058180809021\n",
      "l1 weight: 0.15229757130146027\n",
      "avg viol: 1.7816925991235621, max viol: 1.8004762401105836 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2691276967525482, valid regret : -0.28090229630470276 \n",
      "---------------------------------------iteration: 988\n",
      "l1 decision: 0.08925696462392807\n",
      "l1 weight: 0.15155930817127228\n",
      "avg viol: 1.7728233525846735, max viol: 1.8001691844547167 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2865416407585144, valid regret : -0.28132516145706177 \n",
      "---------------------------------------iteration: 989\n",
      "l1 decision: 0.08867800235748291\n",
      "l1 weight: 0.14980317652225494\n",
      "avg viol: 1.7645662425621413, max viol: 1.7879431312903762 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2755063772201538, valid regret : -0.2673332989215851 \n",
      "---------------------------------------iteration: 990\n",
      "l1 decision: 0.08966047316789627\n",
      "l1 weight: 0.15108263492584229\n",
      "avg viol: 1.7553709040791727, max viol: 1.7740431235870346 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2798222005367279, valid regret : -0.2594415843486786 \n",
      "---------------------------------------iteration: 991\n",
      "l1 decision: 0.08679567277431488\n",
      "l1 weight: 0.14943943917751312\n",
      "avg viol: 1.723589948778972, max viol: 1.7422611949732527 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26896974444389343, valid regret : -0.27878084778785706 \n",
      "---------------------------------------iteration: 992\n",
      "l1 decision: 0.08751087635755539\n",
      "l1 weight: 0.14935815334320068\n",
      "avg viol: 1.7467818953458845, max viol: 1.7760997577861417 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2715955972671509, valid regret : -0.2740885317325592 \n",
      "---------------------------------------iteration: 993\n",
      "l1 decision: 0.09002535045146942\n",
      "l1 weight: 0.148759126663208\n",
      "avg viol: 1.7798074524541152, max viol: 1.798472460708581 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2721906304359436, valid regret : -0.27790117263793945 \n",
      "---------------------------------------iteration: 994\n",
      "l1 decision: 0.0882110670208931\n",
      "l1 weight: 0.15081198513507843\n",
      "avg viol: 1.7622846220160864, max viol: 1.791866006446071 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.281340092420578, valid regret : -0.28343260288238525 \n",
      "---------------------------------------iteration: 995\n",
      "l1 decision: 0.09025391936302185\n",
      "l1 weight: 0.15043731033802032\n",
      "avg viol: 1.7690189693577123, max viol: 1.7985812509432435 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27996015548706055, valid regret : -0.2691861391067505 \n",
      "---------------------------------------iteration: 996\n",
      "l1 decision: 0.08765947818756104\n",
      "l1 weight: 0.1480361968278885\n",
      "avg viol: 1.7537530239659826, max viol: 1.7738956578541547 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.271678626537323, valid regret : -0.2782827913761139 \n",
      "---------------------------------------iteration: 997\n",
      "l1 decision: 0.0897909477353096\n",
      "l1 weight: 0.15156391263008118\n",
      "avg viol: 1.7673429583647522, max viol: 1.797100811265409 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2790208160877228, valid regret : -0.2780880630016327 \n",
      "---------------------------------------iteration: 998\n",
      "l1 decision: 0.08769483119249344\n",
      "l1 weight: 0.15224508941173553\n",
      "avg viol: 1.7548375112598296, max viol: 1.7762993420474231 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2736380398273468, valid regret : -0.27325189113616943 \n",
      "---------------------------------------iteration: 999\n",
      "l1 decision: 0.0902576819062233\n",
      "l1 weight: 0.15242566168308258\n",
      "avg viol: 1.7716773172188551, max viol: 1.7938798337709159 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26475903391838074, valid regret : -0.2747354507446289 \n",
      "---------------------------------------iteration: 1000\n",
      "l1 decision: 0.0872790738940239\n",
      "l1 weight: 0.15107440948486328\n",
      "avg viol: 1.7468618162052008, max viol: 1.7755723572336137 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2785881459712982, valid regret : -0.28312548995018005 \n",
      "---------------------------------------iteration: 1001\n",
      "l1 decision: 0.08985656499862671\n",
      "l1 weight: 0.14930486679077148\n",
      "avg viol: 1.7785226633620914, max viol: 1.7984412994701415 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2792338728904724, valid regret : -0.27287328243255615 \n",
      "---------------------------------------iteration: 1002\n",
      "l1 decision: 0.08838226646184921\n",
      "l1 weight: 0.15044093132019043\n",
      "avg viol: 1.767600411050953, max viol: 1.7931057196110487 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2855006158351898, valid regret : -0.2756870985031128 \n",
      "---------------------------------------iteration: 1003\n",
      "l1 decision: 0.09073229879140854\n",
      "l1 weight: 0.14919398725032806\n",
      "avg viol: 1.7667823573271744, max viol: 1.7864289183635265 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2869257628917694, valid regret : -0.26265448331832886 \n",
      "---------------------------------------iteration: 1004\n",
      "l1 decision: 0.08583435416221619\n",
      "l1 weight: 0.14859385788440704\n",
      "avg viol: 1.714511890062131, max viol: 1.738407914643176 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2558985948562622, valid regret : -0.26834097504615784 \n",
      "---------------------------------------iteration: 1005\n",
      "l1 decision: 0.08790048211812973\n",
      "l1 weight: 0.14882290363311768\n",
      "avg viol: 1.7564005515140888, max viol: 1.7787334956228733 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2678543031215668, valid regret : -0.2779611349105835 \n",
      "---------------------------------------iteration: 1006\n",
      "l1 decision: 0.08920232951641083\n",
      "l1 weight: 0.15141093730926514\n",
      "avg viol: 1.7664479128072708, max viol: 1.7964879861974623 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2795805037021637, valid regret : -0.2840433418750763 \n",
      "---------------------------------------iteration: 1007\n",
      "l1 decision: 0.08924930542707443\n",
      "l1 weight: 0.15121038258075714\n",
      "avg viol: 1.7764454222272617, max viol: 1.7984906767960638 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28399401903152466, valid regret : -0.2725750803947449 \n",
      "---------------------------------------iteration: 1008\n",
      "l1 decision: 0.08943714201450348\n",
      "l1 weight: 0.14843444526195526\n",
      "avg viol: 1.770277780769975, max viol: 1.791302464203909 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27485987544059753, valid regret : -0.2732796370983124 \n",
      "---------------------------------------iteration: 1009\n",
      "l1 decision: 0.08873598277568817\n",
      "l1 weight: 0.1520286202430725\n",
      "avg viol: 1.7501187428086995, max viol: 1.7764238598756492 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27556151151657104, valid regret : -0.266554057598114 \n",
      "---------------------------------------iteration: 1010\n",
      "l1 decision: 0.08673914521932602\n",
      "l1 weight: 0.15249161422252655\n",
      "avg viol: 1.7303084885911084, max viol: 1.749597341986373 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2620948553085327, valid regret : -0.2722981572151184 \n",
      "---------------------------------------iteration: 1011\n",
      "l1 decision: 0.08844935148954391\n",
      "l1 weight: 0.15290462970733643\n",
      "avg viol: 1.7651099158680517, max viol: 1.7920779332052916 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26509132981300354, valid regret : -0.2805350422859192 \n",
      "---------------------------------------iteration: 1012\n",
      "l1 decision: 0.0890340581536293\n",
      "l1 weight: 0.1513066291809082\n",
      "avg viol: 1.7761743633537117, max viol: 1.8011375034693629 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2870101034641266, valid regret : -0.2847568988800049 \n",
      "---------------------------------------iteration: 1013\n",
      "l1 decision: 0.08949916809797287\n",
      "l1 weight: 0.15080057084560394\n",
      "avg viol: 1.7741863760352135, max viol: 1.8017473195213825 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27882733941078186, valid regret : -0.2706889808177948 \n",
      "---------------------------------------iteration: 1014\n",
      "l1 decision: 0.08856761455535889\n",
      "l1 weight: 0.1503138244152069\n",
      "avg viol: 1.7678754176636722, max viol: 1.785603767260909 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2851119637489319, valid regret : -0.2763044834136963 \n",
      "---------------------------------------iteration: 1015\n",
      "l1 decision: 0.09001196175813675\n",
      "l1 weight: 0.15084408223628998\n",
      "avg viol: 1.7551467643957586, max viol: 1.7864300883375108 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2807715833187103, valid regret : -0.2709067761898041 \n",
      "---------------------------------------iteration: 1016\n",
      "l1 decision: 0.08674447983503342\n",
      "l1 weight: 0.14955216646194458\n",
      "avg viol: 1.7322562296403339, max viol: 1.757134438608773 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2635221779346466, valid regret : -0.27188971638679504 \n",
      "---------------------------------------iteration: 1017\n",
      "l1 decision: 0.08868808299303055\n",
      "l1 weight: 0.14860433340072632\n",
      "avg viol: 1.7692197566095273, max viol: 1.7893220661208034 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2699470520019531, valid regret : -0.28043633699417114 \n",
      "---------------------------------------iteration: 1018\n",
      "l1 decision: 0.08907195925712585\n",
      "l1 weight: 0.15125051140785217\n",
      "avg viol: 1.7693056179629638, max viol: 1.7975836168043315 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28197091817855835, valid regret : -0.2798224687576294 \n",
      "---------------------------------------iteration: 1019\n",
      "l1 decision: 0.08907248079776764\n",
      "l1 weight: 0.15191222727298737\n",
      "avg viol: 1.7660422227124217, max viol: 1.8000525432871655 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28102192282676697, valid regret : -0.26261913776397705 \n",
      "---------------------------------------iteration: 1020\n",
      "l1 decision: 0.08788503706455231\n",
      "l1 weight: 0.14817209541797638\n",
      "avg viol: 1.7509781816473697, max viol: 1.7747858143411577 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2684985399246216, valid regret : -0.2742680013179779 \n",
      "---------------------------------------iteration: 1021\n",
      "l1 decision: 0.08854040503501892\n",
      "l1 weight: 0.15252411365509033\n",
      "avg viol: 1.7540319927746895, max viol: 1.7904176480369642 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27602237462997437, valid regret : -0.27497541904449463 \n",
      "---------------------------------------iteration: 1022\n",
      "l1 decision: 0.08716992288827896\n",
      "l1 weight: 0.15270619094371796\n",
      "avg viol: 1.7374998608214083, max viol: 1.7726231479318812 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2667241096496582, valid regret : -0.2744865119457245 \n",
      "---------------------------------------iteration: 1023\n",
      "l1 decision: 0.08890452235937119\n",
      "l1 weight: 0.15352573990821838\n",
      "avg viol: 1.7686526360193966, max viol: 1.7971664960496128 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2647486627101898, valid regret : -0.2792002558708191 \n",
      "---------------------------------------iteration: 1024\n",
      "l1 decision: 0.08824915438890457\n",
      "l1 weight: 0.15134508907794952\n",
      "avg viol: 1.7646801727538877, max viol: 1.790994425304234 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28449293971061707, valid regret : -0.2757759392261505 \n",
      "---------------------------------------iteration: 1025\n",
      "l1 decision: 0.09038663655519485\n",
      "l1 weight: 0.15035800635814667\n",
      "avg viol: 1.7559424944920465, max viol: 1.7815237005706877 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2705172300338745, valid regret : -0.25257986783981323 \n",
      "---------------------------------------iteration: 1026\n",
      "l1 decision: 0.08564130961894989\n",
      "l1 weight: 0.150979146361351\n",
      "avg viol: 1.7149775289645186, max viol: 1.738333186833188 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2641051709651947, valid regret : -0.27592602372169495 \n",
      "---------------------------------------iteration: 1027\n",
      "l1 decision: 0.08864525705575943\n",
      "l1 weight: 0.15007533133029938\n",
      "avg viol: 1.7622298475546996, max viol: 1.7861847500316799 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2850954234600067, valid regret : -0.2849063575267792 \n",
      "---------------------------------------iteration: 1028\n",
      "l1 decision: 0.08847778290510178\n",
      "l1 weight: 0.14868785440921783\n",
      "avg viol: 1.7648307292689787, max viol: 1.799936005845666 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.275429904460907, valid regret : -0.2756992280483246 \n",
      "---------------------------------------iteration: 1029\n",
      "l1 decision: 0.0899309366941452\n",
      "l1 weight: 0.1492137461900711\n",
      "avg viol: 1.7780211615981534, max viol: 1.799951372668147 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2727246582508087, valid regret : -0.2774113118648529 \n",
      "---------------------------------------iteration: 1030\n",
      "l1 decision: 0.08785466849803925\n",
      "l1 weight: 0.14990739524364471\n",
      "avg viol: 1.7570229287181065, max viol: 1.784331037895754 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27992820739746094, valid regret : -0.281125545501709 \n",
      "---------------------------------------iteration: 1031\n",
      "l1 decision: 0.0905422493815422\n",
      "l1 weight: 0.1509784758090973\n",
      "avg viol: 1.7702170754532562, max viol: 1.795256988494657 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28096282482147217, valid regret : -0.2604604661464691 \n",
      "---------------------------------------iteration: 1032\n",
      "l1 decision: 0.08687103539705276\n",
      "l1 weight: 0.14792940020561218\n",
      "avg viol: 1.7390794067538808, max viol: 1.7554861032404006 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2640620172023773, valid regret : -0.2760021686553955 \n",
      "---------------------------------------iteration: 1033\n",
      "l1 decision: 0.08893045037984848\n",
      "l1 weight: 0.15190577507019043\n",
      "avg viol: 1.758833951044362, max viol: 1.7876442421693355 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.277323454618454, valid regret : -0.28207653760910034 \n",
      "---------------------------------------iteration: 1034\n",
      "l1 decision: 0.08803673088550568\n",
      "l1 weight: 0.15288712084293365\n",
      "avg viol: 1.7599032994411754, max viol: 1.7878562742844224 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27602940797805786, valid regret : -0.27455973625183105 \n",
      "---------------------------------------iteration: 1035\n",
      "l1 decision: 0.08992522209882736\n",
      "l1 weight: 0.15327772498130798\n",
      "avg viol: 1.772858651506831, max viol: 1.7986152656376362 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26534363627433777, valid regret : -0.2803058624267578 \n",
      "---------------------------------------iteration: 1036\n",
      "l1 decision: 0.08848980814218521\n",
      "l1 weight: 0.15112978219985962\n",
      "avg viol: 1.7691150417353856, max viol: 1.7972165568498895 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2859569191932678, valid regret : -0.2838018238544464 \n",
      "---------------------------------------iteration: 1037\n",
      "l1 decision: 0.09003399312496185\n",
      "l1 weight: 0.15057094395160675\n",
      "avg viol: 1.7722284468146972, max viol: 1.795883717481047 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2775750458240509, valid regret : -0.2686224579811096 \n",
      "---------------------------------------iteration: 1038\n",
      "l1 decision: 0.08776701986789703\n",
      "l1 weight: 0.1511908322572708\n",
      "avg viol: 1.75604030766699, max viol: 1.7779865572229028 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28069284558296204, valid regret : -0.28029105067253113 \n",
      "---------------------------------------iteration: 1039\n",
      "l1 decision: 0.08967763185501099\n",
      "l1 weight: 0.15046851336956024\n",
      "avg viol: 1.7710176207032056, max viol: 1.797976013389416 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28731536865234375, valid regret : -0.28232917189598083 \n",
      "---------------------------------------iteration: 1040\n",
      "l1 decision: 0.08832454681396484\n",
      "l1 weight: 0.14816690981388092\n",
      "avg viol: 1.7663149155504652, max viol: 1.7902039142791182 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2770308554172516, valid regret : -0.27347731590270996 \n",
      "---------------------------------------iteration: 1041\n",
      "l1 decision: 0.09045886993408203\n",
      "l1 weight: 0.14888714253902435\n",
      "avg viol: 1.7763406929565826, max viol: 1.794384427368641 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2716299295425415, valid regret : -0.27470138669013977 \n",
      "---------------------------------------iteration: 1042\n",
      "l1 decision: 0.0876467153429985\n",
      "l1 weight: 0.14967626333236694\n",
      "avg viol: 1.7539633787481579, max viol: 1.776063796132803 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27899184823036194, valid regret : -0.283930242061615 \n",
      "---------------------------------------iteration: 1043\n",
      "l1 decision: 0.08999191969633102\n",
      "l1 weight: 0.15131790935993195\n",
      "avg viol: 1.7758897348784375, max viol: 1.8000290198251605 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28294381499290466, valid regret : -0.273106187582016 \n",
      "---------------------------------------iteration: 1044\n",
      "l1 decision: 0.08875229954719543\n",
      "l1 weight: 0.14789849519729614\n",
      "avg viol: 1.7727474289142993, max viol: 1.7893219711259007 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27618035674095154, valid regret : -0.27748093008995056 \n",
      "---------------------------------------iteration: 1045\n",
      "l1 decision: 0.08942199498414993\n",
      "l1 weight: 0.1515028029680252\n",
      "avg viol: 1.7615897932846565, max viol: 1.788265698356554 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27864110469818115, valid regret : -0.26480093598365784 \n",
      "---------------------------------------iteration: 1046\n",
      "l1 decision: 0.087079718708992\n",
      "l1 weight: 0.15225403010845184\n",
      "avg viol: 1.7269841627875575, max viol: 1.7464104710379615 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2603980004787445, valid regret : -0.270011305809021 \n",
      "---------------------------------------iteration: 1047\n",
      "l1 decision: 0.08781812340021133\n",
      "l1 weight: 0.1531028300523758\n",
      "avg viol: 1.7543944115320482, max viol: 1.7823342895135283 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26184967160224915, valid regret : -0.2797718644142151 \n",
      "---------------------------------------iteration: 1048\n",
      "l1 decision: 0.08936265856027603\n",
      "l1 weight: 0.15091530978679657\n",
      "avg viol: 1.7746645148766766, max viol: 1.8025645927991718 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2861221730709076, valid regret : -0.2842997610569 \n",
      "---------------------------------------iteration: 1049\n",
      "l1 decision: 0.08929481357336044\n",
      "l1 weight: 0.1505940705537796\n",
      "avg viol: 1.7730201101896819, max viol: 1.7983115093084052 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2785886526107788, valid regret : -0.26996591687202454 \n",
      "---------------------------------------iteration: 1050\n",
      "l1 decision: 0.08841460198163986\n",
      "l1 weight: 0.1503189504146576\n",
      "avg viol: 1.7639441968157188, max viol: 1.7830634982092306 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2831721901893616, valid regret : -0.27705278992652893 \n",
      "---------------------------------------iteration: 1051\n",
      "l1 decision: 0.08947144448757172\n",
      "l1 weight: 0.1501699984073639\n",
      "avg viol: 1.7549333090602885, max viol: 1.7813862711191177 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2819584310054779, valid regret : -0.2653312385082245 \n",
      "---------------------------------------iteration: 1052\n",
      "l1 decision: 0.08650892972946167\n",
      "l1 weight: 0.1486494392156601\n",
      "avg viol: 1.7187646917795063, max viol: 1.743663995526731 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2569332718849182, valid regret : -0.26854580640792847 \n",
      "---------------------------------------iteration: 1053\n",
      "l1 decision: 0.08772074431180954\n",
      "l1 weight: 0.14939454197883606\n",
      "avg viol: 1.7530399545293767, max viol: 1.774938180053141 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2678819000720978, valid regret : -0.27969998121261597 \n",
      "---------------------------------------iteration: 1054\n",
      "l1 decision: 0.0901838168501854\n",
      "l1 weight: 0.1503189504146576\n",
      "avg viol: 1.77904879485548, max viol: 1.7987146188970655 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2836879789829254, valid regret : -0.28432387113571167 \n",
      "---------------------------------------iteration: 1055\n",
      "l1 decision: 0.08858105540275574\n",
      "l1 weight: 0.1514490395784378\n",
      "avg viol: 1.769045542167387, max viol: 1.7995329489931464 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2829930782318115, valid regret : -0.2752326428890228 \n",
      "---------------------------------------iteration: 1056\n",
      "l1 decision: 0.09091275185346603\n",
      "l1 weight: 0.14837513864040375\n",
      "avg viol: 1.7824584168905857, max viol: 1.7989959474653006 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2775631844997406, valid regret : -0.27381518483161926 \n",
      "---------------------------------------iteration: 1057\n",
      "l1 decision: 0.08761254698038101\n",
      "l1 weight: 0.1508771777153015\n",
      "avg viol: 1.752388249093783, max viol: 1.7751031315419823 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2777636647224426, valid regret : -0.2842722237110138 \n",
      "---------------------------------------iteration: 1058\n",
      "l1 decision: 0.0900941863656044\n",
      "l1 weight: 0.15248969197273254\n",
      "avg viol: 1.7763954470213503, max viol: 1.8011091658845544 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2784171402454376, valid regret : -0.27225974202156067 \n",
      "---------------------------------------iteration: 1059\n",
      "l1 decision: 0.08826147764921188\n",
      "l1 weight: 0.1519085317850113\n",
      "avg viol: 1.7647449473291636, max viol: 1.7853041200432926 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26432082056999207, valid regret : -0.27749165892601013 \n",
      "---------------------------------------iteration: 1060\n",
      "l1 decision: 0.08958722651004791\n",
      "l1 weight: 0.1515025794506073\n",
      "avg viol: 1.7734505342773628, max viol: 1.7981635114410892 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28607696294784546, valid regret : -0.2809537947177887 \n",
      "---------------------------------------iteration: 1061\n",
      "l1 decision: 0.08828108757734299\n",
      "l1 weight: 0.15016187727451324\n",
      "avg viol: 1.7642836138912572, max viol: 1.7856535536702722 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27551689743995667, valid regret : -0.27168476581573486 \n",
      "---------------------------------------iteration: 1062\n",
      "l1 decision: 0.0900103896856308\n",
      "l1 weight: 0.1508045643568039\n",
      "avg viol: 1.7642247298313305, max viol: 1.7855883692391217 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2819700241088867, valid regret : -0.26216980814933777 \n",
      "---------------------------------------iteration: 1063\n",
      "l1 decision: 0.08629025518894196\n",
      "l1 weight: 0.14897726476192474\n",
      "avg viol: 1.7285449380567297, max viol: 1.745780204422772 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2717053294181824, valid regret : -0.27790433168411255 \n",
      "---------------------------------------iteration: 1064\n",
      "l1 decision: 0.08907339721918106\n",
      "l1 weight: 0.14880026876926422\n",
      "avg viol: 1.7623095334408572, max viol: 1.782399024348706 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2725692689418793, valid regret : -0.2748962938785553 \n",
      "---------------------------------------iteration: 1065\n",
      "l1 decision: 0.08884549885988235\n",
      "l1 weight: 0.14840401709079742\n",
      "avg viol: 1.7725518026500504, max viol: 1.79553445847705 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2710515558719635, valid regret : -0.28122442960739136 \n",
      "---------------------------------------iteration: 1066\n",
      "l1 decision: 0.08973757177591324\n",
      "l1 weight: 0.14969971776008606\n",
      "avg viol: 1.780896386904642, max viol: 1.8017434626817703 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2853606939315796, valid regret : -0.28311774134635925 \n",
      "---------------------------------------iteration: 1067\n",
      "l1 decision: 0.08881592750549316\n",
      "l1 weight: 0.1509481966495514\n",
      "avg viol: 1.7727123664866666, max viol: 1.794220071635209 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28294551372528076, valid regret : -0.26894503831863403 \n",
      "---------------------------------------iteration: 1068\n",
      "l1 decision: 0.08979948610067368\n",
      "l1 weight: 0.14832018315792084\n",
      "avg viol: 1.7662613626313395, max viol: 1.7846940429881215 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2735150456428528, valid regret : -0.26196980476379395 \n",
      "---------------------------------------iteration: 1069\n",
      "l1 decision: 0.08686575293540955\n",
      "l1 weight: 0.15116754174232483\n",
      "avg viol: 1.729858421999961, max viol: 1.7476567480480298 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26614320278167725, valid regret : -0.2785300314426422 \n",
      "---------------------------------------iteration: 1070\n",
      "l1 decision: 0.08758929371833801\n",
      "l1 weight: 0.15316131711006165\n",
      "avg viol: 1.7513583647896303, max viol: 1.7790754928719252 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27357590198516846, valid regret : -0.2738967835903168 \n",
      "---------------------------------------iteration: 1071\n",
      "l1 decision: 0.08983907848596573\n",
      "l1 weight: 0.1523519903421402\n",
      "avg viol: 1.778586100676912, max viol: 1.8000413092086092 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2661536633968353, valid regret : -0.2796866297721863 \n",
      "---------------------------------------iteration: 1072\n",
      "l1 decision: 0.08822851628065109\n",
      "l1 weight: 0.15064792335033417\n",
      "avg viol: 1.764553682652804, max viol: 1.79672952380497 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28561753034591675, valid regret : -0.2838001549243927 \n",
      "---------------------------------------iteration: 1073\n",
      "l1 decision: 0.0901755765080452\n",
      "l1 weight: 0.15067468583583832\n",
      "avg viol: 1.7714274209283758, max viol: 1.798164654057473 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2758365273475647, valid regret : -0.26886117458343506 \n",
      "---------------------------------------iteration: 1074\n",
      "l1 decision: 0.0879497304558754\n",
      "l1 weight: 0.15005998313426971\n",
      "avg viol: 1.7589315803174395, max viol: 1.779036610852927 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2819646894931793, valid regret : -0.27980294823646545 \n",
      "---------------------------------------iteration: 1075\n",
      "l1 decision: 0.09015610069036484\n",
      "l1 weight: 0.1498253345489502\n",
      "avg viol: 1.7778471120080213, max viol: 1.798833197215572 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28968068957328796, valid regret : -0.27926740050315857 \n",
      "---------------------------------------iteration: 1076\n",
      "l1 decision: 0.0877828374505043\n",
      "l1 weight: 0.1489834487438202\n",
      "avg viol: 1.756343024171656, max viol: 1.7812154749408364 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2730157673358917, valid regret : -0.2741797864437103 \n",
      "---------------------------------------iteration: 1077\n",
      "l1 decision: 0.08991959691047668\n",
      "l1 weight: 0.14930149912834167\n",
      "avg viol: 1.7780214793339837, max viol: 1.801633070455864 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2712332010269165, valid regret : -0.2776744067668915 \n",
      "---------------------------------------iteration: 1078\n",
      "l1 decision: 0.08807791024446487\n",
      "l1 weight: 0.1493975669145584\n",
      "avg viol: 1.7624300124303227, max viol: 1.785569273866713 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28192299604415894, valid regret : -0.28222906589508057 \n",
      "---------------------------------------iteration: 1079\n",
      "l1 decision: 0.08987181633710861\n",
      "l1 weight: 0.15076373517513275\n",
      "avg viol: 1.7696771523950157, max viol: 1.794513194821775 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2807984948158264, valid regret : -0.26903557777404785 \n",
      "---------------------------------------iteration: 1080\n",
      "l1 decision: 0.08800452947616577\n",
      "l1 weight: 0.1477251946926117\n",
      "avg viol: 1.760693621709943, max viol: 1.7803878898266703 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2729928493499756, valid regret : -0.2799966335296631 \n",
      "---------------------------------------iteration: 1081\n",
      "l1 decision: 0.08934193104505539\n",
      "l1 weight: 0.15144382417201996\n",
      "avg viol: 1.7746443147637183, max viol: 1.8009124065283686 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.282762348651886, valid regret : -0.28464475274086 \n",
      "---------------------------------------iteration: 1082\n",
      "l1 decision: 0.088959239423275\n",
      "l1 weight: 0.15213234722614288\n",
      "avg viol: 1.7771363926721824, max viol: 1.797478134794801 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28104162216186523, valid regret : -0.2715935707092285 \n",
      "---------------------------------------iteration: 1083\n",
      "l1 decision: 0.09032798558473587\n",
      "l1 weight: 0.15261273086071014\n",
      "avg viol: 1.7681148276507157, max viol: 1.7897012631874532 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2639980614185333, valid regret : -0.26586607098579407 \n",
      "---------------------------------------iteration: 1084\n",
      "l1 decision: 0.08673569560050964\n",
      "l1 weight: 0.15107037127017975\n",
      "avg viol: 1.735965037360438, max viol: 1.7569892187602818 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2715025842189789, valid regret : -0.2789421081542969 \n",
      "---------------------------------------iteration: 1085\n",
      "l1 decision: 0.08888407051563263\n",
      "l1 weight: 0.1499081254005432\n",
      "avg viol: 1.7641491558996494, max viol: 1.7849711934104562 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27422815561294556, valid regret : -0.27449455857276917 \n",
      "---------------------------------------iteration: 1086\n",
      "l1 decision: 0.08891414105892181\n",
      "l1 weight: 0.15071295201778412\n",
      "avg viol: 1.7763373007329755, max viol: 1.7968212668783963 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2876110076904297, valid regret : -0.27937930822372437 \n",
      "---------------------------------------iteration: 1087\n",
      "l1 decision: 0.09024707227945328\n",
      "l1 weight: 0.14982286095619202\n",
      "avg viol: 1.772953918313724, max viol: 1.7964210549835116 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28842300176620483, valid regret : -0.2781238853931427 \n",
      "---------------------------------------iteration: 1088\n",
      "l1 decision: 0.08748326450586319\n",
      "l1 weight: 0.14800313115119934\n",
      "avg viol: 1.750385770581197, max viol: 1.7754436815157533 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2714916467666626, valid regret : -0.2730536162853241 \n",
      "---------------------------------------iteration: 1089\n",
      "l1 decision: 0.0901573896408081\n",
      "l1 weight: 0.1495211273431778\n",
      "avg viol: 1.771969960479182, max viol: 1.7944646091200411 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27005311846733093, valid regret : -0.27167773246765137 \n",
      "---------------------------------------iteration: 1090\n",
      "l1 decision: 0.08781611174345016\n",
      "l1 weight: 0.14984358847141266\n",
      "avg viol: 1.753304704236798, max viol: 1.7737164702266455 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2759786546230316, valid regret : -0.2830340266227722 \n",
      "---------------------------------------iteration: 1091\n",
      "l1 decision: 0.08910982310771942\n",
      "l1 weight: 0.15101775527000427\n",
      "avg viol: 1.7732812490308425, max viol: 1.7931430785683915 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2827291488647461, valid regret : -0.27106258273124695 \n",
      "---------------------------------------iteration: 1092\n",
      "l1 decision: 0.08873653411865234\n",
      "l1 weight: 0.14793910086154938\n",
      "avg viol: 1.7721482229040704, max viol: 1.790055694640614 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27624091506004333, valid regret : -0.27730292081832886 \n",
      "---------------------------------------iteration: 1093\n",
      "l1 decision: 0.08944915980100632\n",
      "l1 weight: 0.15140867233276367\n",
      "avg viol: 1.7642322476120897, max viol: 1.7906401375075802 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.280525267124176, valid regret : -0.27096179127693176 \n",
      "---------------------------------------iteration: 1094\n",
      "l1 decision: 0.08682631701231003\n",
      "l1 weight: 0.1523316204547882\n",
      "avg viol: 1.7387185063026847, max viol: 1.7594470690237358 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2660507261753082, valid regret : -0.27204644680023193 \n",
      "---------------------------------------iteration: 1095\n",
      "l1 decision: 0.08878520876169205\n",
      "l1 weight: 0.15253938734531403\n",
      "avg viol: 1.769577411026694, max viol: 1.7898349995957687 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.265000581741333, valid regret : -0.27983587980270386 \n",
      "---------------------------------------iteration: 1096\n",
      "l1 decision: 0.08905989676713943\n",
      "l1 weight: 0.15137094259262085\n",
      "avg viol: 1.7709387118547602, max viol: 1.794799210736528 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28555670380592346, valid regret : -0.28500083088874817 \n",
      "---------------------------------------iteration: 1097\n",
      "l1 decision: 0.08965597301721573\n",
      "l1 weight: 0.1497640758752823\n",
      "avg viol: 1.7758376985881477, max viol: 1.798247516155243 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2792262136936188, valid regret : -0.2691316306591034 \n",
      "---------------------------------------iteration: 1098\n",
      "l1 decision: 0.08791345357894897\n",
      "l1 weight: 0.15049879252910614\n",
      "avg viol: 1.7573256625392242, max viol: 1.7753417454659939 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2812581956386566, valid regret : -0.2797500491142273 \n",
      "---------------------------------------iteration: 1099\n",
      "l1 decision: 0.09008762985467911\n",
      "l1 weight: 0.15024730563163757\n",
      "avg viol: 1.7701558664947514, max viol: 1.7933205252047628 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28704410791397095, valid regret : -0.26999273896217346 \n",
      "---------------------------------------iteration: 1100\n",
      "l1 decision: 0.08681083470582962\n",
      "l1 weight: 0.1487073302268982\n",
      "avg viol: 1.7328799262898975, max viol: 1.756222339347005 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2639278471469879, valid regret : -0.27103108167648315 \n",
      "---------------------------------------iteration: 1101\n",
      "l1 decision: 0.08848506957292557\n",
      "l1 weight: 0.14930982887744904\n",
      "avg viol: 1.766838811605703, max viol: 1.792822299990803 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2690018117427826, valid regret : -0.28093767166137695 \n",
      "---------------------------------------iteration: 1102\n",
      "l1 decision: 0.08926493674516678\n",
      "l1 weight: 0.15052439272403717\n",
      "avg viol: 1.7728581453696097, max viol: 1.799867155845277 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2827363908290863, valid regret : -0.28523924946784973 \n",
      "---------------------------------------iteration: 1103\n",
      "l1 decision: 0.08922671526670456\n",
      "l1 weight: 0.1517512947320938\n",
      "avg viol: 1.777311318773136, max viol: 1.8015650956658646 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28473082184791565, valid regret : -0.27523043751716614 \n",
      "---------------------------------------iteration: 1104\n",
      "l1 decision: 0.08920653164386749\n",
      "l1 weight: 0.14813266694545746\n",
      "avg viol: 1.7796332579026422, max viol: 1.8004828629782423 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2788669168949127, valid regret : -0.27919602394104004 \n",
      "---------------------------------------iteration: 1105\n",
      "l1 decision: 0.08974691480398178\n",
      "l1 weight: 0.1517765074968338\n",
      "avg viol: 1.7705814447480952, max viol: 1.794992967392318 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28179752826690674, valid regret : -0.27128541469573975 \n",
      "---------------------------------------iteration: 1106\n",
      "l1 decision: 0.08662063628435135\n",
      "l1 weight: 0.1528349220752716\n",
      "avg viol: 1.7356314707640559, max viol: 1.7593886873219162 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26564261317253113, valid regret : -0.27206113934516907 \n",
      "---------------------------------------iteration: 1107\n",
      "l1 decision: 0.08923457562923431\n",
      "l1 weight: 0.15307603776454926\n",
      "avg viol: 1.7692106231598883, max viol: 1.7942214132053778 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.264003187417984, valid regret : -0.2786364257335663 \n",
      "---------------------------------------iteration: 1108\n",
      "l1 decision: 0.08837868273258209\n",
      "l1 weight: 0.15077035129070282\n",
      "avg viol: 1.7656958419237343, max viol: 1.791635945905 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2844019830226898, valid regret : -0.282405287027359 \n",
      "---------------------------------------iteration: 1109\n",
      "l1 decision: 0.0897289514541626\n",
      "l1 weight: 0.15002520382404327\n",
      "avg viol: 1.7653354927781038, max viol: 1.7937536309473217 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2743658125400543, valid regret : -0.2672308683395386 \n",
      "---------------------------------------iteration: 1110\n",
      "l1 decision: 0.08742427825927734\n",
      "l1 weight: 0.14977428317070007\n",
      "avg viol: 1.7499184739944758, max viol: 1.7722767275990918 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.279026061296463, valid regret : -0.28085586428642273 \n",
      "---------------------------------------iteration: 1111\n",
      "l1 decision: 0.0894652009010315\n",
      "l1 weight: 0.14975544810295105\n",
      "avg viol: 1.7724464074906428, max viol: 1.8002989506348968 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28761816024780273, valid regret : -0.2833661735057831 \n",
      "---------------------------------------iteration: 1112\n",
      "l1 decision: 0.08903130888938904\n",
      "l1 weight: 0.14792655408382416\n",
      "avg viol: 1.7771595933110802, max viol: 1.7968042306602001 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2801152467727661, valid regret : -0.27330222725868225 \n",
      "---------------------------------------iteration: 1113\n",
      "l1 decision: 0.09034904837608337\n",
      "l1 weight: 0.14833377301692963\n",
      "avg viol: 1.7785932240012334, max viol: 1.7960807192139328 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2726745307445526, valid regret : -0.2662637233734131 \n",
      "---------------------------------------iteration: 1114\n",
      "l1 decision: 0.08682454377412796\n",
      "l1 weight: 0.14971469342708588\n",
      "avg viol: 1.7381783072219696, max viol: 1.757655044668354 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2699829936027527, valid regret : -0.28044721484184265 \n",
      "---------------------------------------iteration: 1115\n",
      "l1 decision: 0.08852236717939377\n",
      "l1 weight: 0.1508869230747223\n",
      "avg viol: 1.764077171139652, max viol: 1.7862608586438 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27998068928718567, valid regret : -0.27374979853630066 \n",
      "---------------------------------------iteration: 1116\n",
      "l1 decision: 0.08933404833078384\n",
      "l1 weight: 0.1481647491455078\n",
      "avg viol: 1.7772595490626555, max viol: 1.7942154377233237 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27738896012306213, valid regret : -0.278841108083725 \n",
      "---------------------------------------iteration: 1117\n",
      "l1 decision: 0.08930233865976334\n",
      "l1 weight: 0.15157945454120636\n",
      "avg viol: 1.769616355720209, max viol: 1.7959437486715615 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2824013829231262, valid regret : -0.2755807638168335 \n",
      "---------------------------------------iteration: 1118\n",
      "l1 decision: 0.08759012073278427\n",
      "l1 weight: 0.15181505680084229\n",
      "avg viol: 1.750689393025241, max viol: 1.771581421373412 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27124011516571045, valid regret : -0.27355876564979553 \n",
      "---------------------------------------iteration: 1119\n",
      "l1 decision: 0.0896010473370552\n",
      "l1 weight: 0.15318743884563446\n",
      "avg viol: 1.7746353408624418, max viol: 1.7991622374393046 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2665086090564728, valid regret : -0.27760133147239685 \n",
      "---------------------------------------iteration: 1120\n",
      "l1 decision: 0.08841995894908905\n",
      "l1 weight: 0.1505284160375595\n",
      "avg viol: 1.7664060055516893, max viol: 1.7903498803498223 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2847655117511749, valid regret : -0.2831513583660126 \n",
      "---------------------------------------iteration: 1121\n",
      "l1 decision: 0.09025008231401443\n",
      "l1 weight: 0.15040072798728943\n",
      "avg viol: 1.774654157552868, max viol: 1.7990485555492342 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27771544456481934, valid regret : -0.2659469544887543 \n",
      "---------------------------------------iteration: 1122\n",
      "l1 decision: 0.08736804872751236\n",
      "l1 weight: 0.14986953139305115\n",
      "avg viol: 1.7477174766833194, max viol: 1.7639797059819102 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27761778235435486, valid regret : -0.2801707983016968 \n",
      "---------------------------------------iteration: 1123\n",
      "l1 decision: 0.08971218019723892\n",
      "l1 weight: 0.1493147611618042\n",
      "avg viol: 1.7795797453587874, max viol: 1.7985492072766647 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2902366518974304, valid regret : -0.28382593393325806 \n",
      "---------------------------------------iteration: 1124\n",
      "l1 decision: 0.08901729434728622\n",
      "l1 weight: 0.14828284084796906\n",
      "avg viol: 1.7753645253152355, max viol: 1.7955462376121432 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2788272500038147, valid regret : -0.2725120782852173 \n",
      "---------------------------------------iteration: 1125\n",
      "l1 decision: 0.08990832418203354\n",
      "l1 weight: 0.14894896745681763\n",
      "avg viol: 1.7694203763327097, max viol: 1.7864186693914235 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26999759674072266, valid regret : -0.2642383277416229 \n",
      "---------------------------------------iteration: 1126\n",
      "l1 decision: 0.08644992113113403\n",
      "l1 weight: 0.15041352808475494\n",
      "avg viol: 1.7311094107839744, max viol: 1.7522114687599242 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2675546705722809, valid regret : -0.28154516220092773 \n",
      "---------------------------------------iteration: 1127\n",
      "l1 decision: 0.08839795738458633\n",
      "l1 weight: 0.15042580664157867\n",
      "avg viol: 1.7645660773487908, max viol: 1.7872247382765636 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2810652554035187, valid regret : -0.27688491344451904 \n",
      "---------------------------------------iteration: 1128\n",
      "l1 decision: 0.0898352563381195\n",
      "l1 weight: 0.14809547364711761\n",
      "avg viol: 1.7839830966191947, max viol: 1.801373679190874 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27854904532432556, valid regret : -0.2820216119289398 \n",
      "---------------------------------------iteration: 1129\n",
      "l1 decision: 0.08938972651958466\n",
      "l1 weight: 0.15107697248458862\n",
      "avg viol: 1.7790132796915714, max viol: 1.8008495110552758 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28534528613090515, valid regret : -0.2831360697746277 \n",
      "---------------------------------------iteration: 1130\n",
      "l1 decision: 0.08893996477127075\n",
      "l1 weight: 0.1517520397901535\n",
      "avg viol: 1.7745972191973123, max viol: 1.7921649396885186 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2794016897678375, valid regret : -0.27091217041015625 \n",
      "---------------------------------------iteration: 1131\n",
      "l1 decision: 0.09027765691280365\n",
      "l1 weight: 0.15214452147483826\n",
      "avg viol: 1.7611139920831191, max viol: 1.7798470978159457 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26126766204833984, valid regret : -0.25752875208854675 \n",
      "---------------------------------------iteration: 1132\n",
      "l1 decision: 0.08575475960969925\n",
      "l1 weight: 0.15093806385993958\n",
      "avg viol: 1.7189975732692984, max viol: 1.737081081373617 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26491355895996094, valid regret : -0.279737651348114 \n",
      "---------------------------------------iteration: 1133\n",
      "l1 decision: 0.087994784116745\n",
      "l1 weight: 0.14979982376098633\n",
      "avg viol: 1.757709135944715, max viol: 1.7773028030060232 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27504709362983704, valid regret : -0.2756552994251251 \n",
      "---------------------------------------iteration: 1134\n",
      "l1 decision: 0.08955378085374832\n",
      "l1 weight: 0.1506243795156479\n",
      "avg viol: 1.7811444167218724, max viol: 1.8007980943657458 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2871740460395813, valid regret : -0.2801631689071655 \n",
      "---------------------------------------iteration: 1135\n",
      "l1 decision: 0.08964821696281433\n",
      "l1 weight: 0.14937973022460938\n",
      "avg viol: 1.7770387261558789, max viol: 1.7968698567710817 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28980574011802673, valid regret : -0.2768401801586151 \n",
      "---------------------------------------iteration: 1136\n",
      "l1 decision: 0.08845283091068268\n",
      "l1 weight: 0.14734400808811188\n",
      "avg viol: 1.7533956438204041, max viol: 1.77158399799373 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2708319425582886, valid regret : -0.27385178208351135 \n",
      "---------------------------------------iteration: 1137\n",
      "l1 decision: 0.08974196016788483\n",
      "l1 weight: 0.1491009145975113\n",
      "avg viol: 1.769905570964911, max viol: 1.790769710438326 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26978686451911926, valid regret : -0.2684757113456726 \n",
      "---------------------------------------iteration: 1138\n",
      "l1 decision: 0.08700986951589584\n",
      "l1 weight: 0.14888358116149902\n",
      "avg viol: 1.7393353100394597, max viol: 1.7653222751105204 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2724216878414154, valid regret : -0.2791532576084137 \n",
      "---------------------------------------iteration: 1139\n",
      "l1 decision: 0.09008153527975082\n",
      "l1 weight: 0.1499428153038025\n",
      "avg viol: 1.7664641347143333, max viol: 1.7858910695649683 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2789080739021301, valid regret : -0.26120078563690186 \n",
      "---------------------------------------iteration: 1140\n",
      "l1 decision: 0.08685559779405594\n",
      "l1 weight: 0.14767059683799744\n",
      "avg viol: 1.7361833561013917, max viol: 1.750416754046455 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26379284262657166, valid regret : -0.277361661195755 \n",
      "---------------------------------------iteration: 1141\n",
      "l1 decision: 0.08837589621543884\n",
      "l1 weight: 0.15086613595485687\n",
      "avg viol: 1.7674271322356072, max viol: 1.7908095358870924 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27960634231567383, valid regret : -0.28309953212738037 \n",
      "---------------------------------------iteration: 1142\n",
      "l1 decision: 0.08884274214506149\n",
      "l1 weight: 0.15148192644119263\n",
      "avg viol: 1.774580116227662, max viol: 1.7897841280791909 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2803778052330017, valid regret : -0.2761574983596802 \n",
      "---------------------------------------iteration: 1143\n",
      "l1 decision: 0.09044668823480606\n",
      "l1 weight: 0.15135052800178528\n",
      "avg viol: 1.7848698122712086, max viol: 1.7993796980008483 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26917564868927, valid regret : -0.2708355188369751 \n",
      "---------------------------------------iteration: 1144\n",
      "l1 decision: 0.08752632886171341\n",
      "l1 weight: 0.15032652020454407\n",
      "avg viol: 1.7509658193978248, max viol: 1.7722050625598058 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.278309166431427, valid regret : -0.28322187066078186 \n",
      "---------------------------------------iteration: 1145\n",
      "l1 decision: 0.0895516648888588\n",
      "l1 weight: 0.1495639681816101\n",
      "avg viol: 1.7706734970863909, max viol: 1.7947035373654217 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27768126130104065, valid regret : -0.2719119191169739 \n",
      "---------------------------------------iteration: 1146\n",
      "l1 decision: 0.08852734416723251\n",
      "l1 weight: 0.15005254745483398\n",
      "avg viol: 1.7642027290933766, max viol: 1.7819154558237642 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28269416093826294, valid regret : -0.2786575257778168 \n",
      "---------------------------------------iteration: 1147\n",
      "l1 decision: 0.08973710983991623\n",
      "l1 weight: 0.14859670400619507\n",
      "avg viol: 1.7766666088509373, max viol: 1.792852520593442 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29034551978111267, valid regret : -0.2724091410636902 \n",
      "---------------------------------------iteration: 1148\n",
      "l1 decision: 0.08843347430229187\n",
      "l1 weight: 0.14699481427669525\n",
      "avg viol: 1.7473891964560608, max viol: 1.7614294606028125 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26813939213752747, valid regret : -0.27263060212135315 \n",
      "---------------------------------------iteration: 1149\n",
      "l1 decision: 0.0887487381696701\n",
      "l1 weight: 0.14889314770698547\n",
      "avg viol: 1.7642776248157315, max viol: 1.7832528750877827 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26949694752693176, valid regret : -0.2784050703048706 \n",
      "---------------------------------------iteration: 1150\n",
      "l1 decision: 0.08894985169172287\n",
      "l1 weight: 0.14864103496074677\n",
      "avg viol: 1.773489926725706, max viol: 1.7929306152509525 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28395888209342957, valid regret : -0.28453925251960754 \n",
      "---------------------------------------iteration: 1151\n",
      "l1 decision: 0.08983055502176285\n",
      "l1 weight: 0.14999271929264069\n",
      "avg viol: 1.780308494209894, max viol: 1.7988171465694904 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28537794947624207, valid regret : -0.2696657180786133 \n",
      "---------------------------------------iteration: 1152\n",
      "l1 decision: 0.08805833011865616\n",
      "l1 weight: 0.14761561155319214\n",
      "avg viol: 1.7588391931686784, max viol: 1.7772715473547578 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2719632089138031, valid regret : -0.27965331077575684 \n",
      "---------------------------------------iteration: 1153\n",
      "l1 decision: 0.09023451060056686\n",
      "l1 weight: 0.15061645209789276\n",
      "avg viol: 1.7814861499640393, max viol: 1.8019446555990726 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2849177420139313, valid regret : -0.2791232168674469 \n",
      "---------------------------------------iteration: 1154\n",
      "l1 decision: 0.08799233287572861\n",
      "l1 weight: 0.15105265378952026\n",
      "avg viol: 1.7590737538348185, max viol: 1.775420413352549 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27709513902664185, valid regret : -0.2729059159755707 \n",
      "---------------------------------------iteration: 1155\n",
      "l1 decision: 0.09053978323936462\n",
      "l1 weight: 0.15166905522346497\n",
      "avg viol: 1.775829400474322, max viol: 1.7929813780356199 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.265651136636734, valid regret : -0.2622884511947632 \n",
      "---------------------------------------iteration: 1156\n",
      "l1 decision: 0.08635295927524567\n",
      "l1 weight: 0.15071281790733337\n",
      "avg viol: 1.7281740686501144, max viol: 1.7464945256942883 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27102383971214294, valid regret : -0.2813636064529419 \n",
      "---------------------------------------iteration: 1157\n",
      "l1 decision: 0.08977214246988297\n",
      "l1 weight: 0.1489323228597641\n",
      "avg viol: 1.7729893303959399, max viol: 1.793599059805274 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27632206678390503, valid regret : -0.27295756340026855 \n",
      "---------------------------------------iteration: 1158\n",
      "l1 decision: 0.08829452842473984\n",
      "l1 weight: 0.15017621219158173\n",
      "avg viol: 1.764979817062267, max viol: 1.784837254555896 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2847937047481537, valid regret : -0.28063714504241943 \n",
      "---------------------------------------iteration: 1159\n",
      "l1 decision: 0.09024538099765778\n",
      "l1 weight: 0.1490418016910553\n",
      "avg viol: 1.7813426280661953, max viol: 1.7980259526520967 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29154112935066223, valid regret : -0.2756274342536926 \n",
      "---------------------------------------iteration: 1160\n",
      "l1 decision: 0.08724226802587509\n",
      "l1 weight: 0.14706458151340485\n",
      "avg viol: 1.7438271982467268, max viol: 1.768739772378467 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26796141266822815, valid regret : -0.2736557126045227 \n",
      "---------------------------------------iteration: 1161\n",
      "l1 decision: 0.08896395564079285\n",
      "l1 weight: 0.14853201806545258\n",
      "avg viol: 1.7721088460058672, max viol: 1.7936903743539006 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2710074782371521, valid regret : -0.2811847925186157 \n",
      "---------------------------------------iteration: 1162\n",
      "l1 decision: 0.08940141648054123\n",
      "l1 weight: 0.14882929623126984\n",
      "avg viol: 1.7769214206858306, max viol: 1.7976772743277252 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.284349262714386, valid regret : -0.28421998023986816 \n",
      "---------------------------------------iteration: 1163\n",
      "l1 decision: 0.08980000764131546\n",
      "l1 weight: 0.14998145401477814\n",
      "avg viol: 1.776860504958313, max viol: 1.79429638129659 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2842641770839691, valid regret : -0.262487530708313 \n",
      "---------------------------------------iteration: 1164\n",
      "l1 decision: 0.08762887865304947\n",
      "l1 weight: 0.14812558889389038\n",
      "avg viol: 1.7414486421528272, max viol: 1.7570156403817236 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26391878724098206, valid regret : -0.2777586877346039 \n",
      "---------------------------------------iteration: 1165\n",
      "l1 decision: 0.08829745650291443\n",
      "l1 weight: 0.15093585848808289\n",
      "avg viol: 1.7639149551528317, max viol: 1.7858453067019582 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28185251355171204, valid regret : -0.28595083951950073 \n",
      "---------------------------------------iteration: 1166\n",
      "l1 decision: 0.08985137939453125\n",
      "l1 weight: 0.15127824246883392\n",
      "avg viol: 1.7864715928125223, max viol: 1.8007864359533414 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2829914391040802, valid regret : -0.27586764097213745 \n",
      "---------------------------------------iteration: 1167\n",
      "l1 decision: 0.08881875872612\n",
      "l1 weight: 0.15203812718391418\n",
      "avg viol: 1.7746882025859667, max viol: 1.7929106317460537 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2677217423915863, valid regret : -0.28049901127815247 \n",
      "---------------------------------------iteration: 1168\n",
      "l1 decision: 0.08977560698986053\n",
      "l1 weight: 0.15170404314994812\n",
      "avg viol: 1.773830920738983, max viol: 1.7997159259393811 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28562331199645996, valid regret : -0.28085359930992126 \n",
      "---------------------------------------iteration: 1169\n",
      "l1 decision: 0.0880902111530304\n",
      "l1 weight: 0.14908479154109955\n",
      "avg viol: 1.760217436841922, max viol: 1.7832576062064618 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2748735547065735, valid regret : -0.27471303939819336 \n",
      "---------------------------------------iteration: 1170\n",
      "l1 decision: 0.09012176841497421\n",
      "l1 weight: 0.15025624632835388\n",
      "avg viol: 1.7794946103321854, max viol: 1.7987661832012236 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2869878113269806, valid regret : -0.2762953042984009 \n",
      "---------------------------------------iteration: 1171\n",
      "l1 decision: 0.0880875363945961\n",
      "l1 weight: 0.14848414063453674\n",
      "avg viol: 1.7606054970395053, max viol: 1.7803472522646189 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2861596941947937, valid regret : -0.28297340869903564 \n",
      "---------------------------------------iteration: 1172\n",
      "l1 decision: 0.09071342647075653\n",
      "l1 weight: 0.14723989367485046\n",
      "avg viol: 1.776359811227303, max viol: 1.7932401022408158 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2773746848106384, valid regret : -0.26446834206581116 \n",
      "---------------------------------------iteration: 1173\n",
      "l1 decision: 0.08716823160648346\n",
      "l1 weight: 0.14859023690223694\n",
      "avg viol: 1.7445282414543908, max viol: 1.7634753342717886 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.262649804353714, valid regret : -0.2766835689544678 \n",
      "---------------------------------------iteration: 1174\n",
      "l1 decision: 0.09003102779388428\n",
      "l1 weight: 0.14850065112113953\n",
      "avg viol: 1.7723852331732632, max viol: 1.7900770360138267 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2814829647541046, valid regret : -0.2748861312866211 \n",
      "---------------------------------------iteration: 1175\n",
      "l1 decision: 0.08763156831264496\n",
      "l1 weight: 0.14946995675563812\n",
      "avg viol: 1.7511276438483037, max viol: 1.7669430549722165 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27511462569236755, valid regret : -0.27173522114753723 \n",
      "---------------------------------------iteration: 1176\n",
      "l1 decision: 0.08916696161031723\n",
      "l1 weight: 0.1474054902791977\n",
      "avg viol: 1.7732852865580935, max viol: 1.7898611202836037 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27426037192344666, valid regret : -0.2720366418361664 \n",
      "---------------------------------------iteration: 1177\n",
      "l1 decision: 0.08776931464672089\n",
      "l1 weight: 0.1504449099302292\n",
      "avg viol: 1.7535517912707292, max viol: 1.772462846362032 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2756150960922241, valid regret : -0.281424880027771 \n",
      "---------------------------------------iteration: 1178\n",
      "l1 decision: 0.08934716880321503\n",
      "l1 weight: 0.1512686014175415\n",
      "avg viol: 1.7751076067547547, max viol: 1.7904818158131093 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27858689427375793, valid regret : -0.26791515946388245 \n",
      "---------------------------------------iteration: 1179\n",
      "l1 decision: 0.08770813047885895\n",
      "l1 weight: 0.15147267282009125\n",
      "avg viol: 1.7518458237079904, max viol: 1.77301071153488 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2590266168117523, valid regret : -0.2789658010005951 \n",
      "---------------------------------------iteration: 1180\n",
      "l1 decision: 0.08890049904584885\n",
      "l1 weight: 0.15038122236728668\n",
      "avg viol: 1.7725838557363023, max viol: 1.7923595358151942 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28633570671081543, valid regret : -0.2839304208755493 \n",
      "---------------------------------------iteration: 1181\n",
      "l1 decision: 0.08915706723928452\n",
      "l1 weight: 0.14926894009113312\n",
      "avg viol: 1.7746067387939002, max viol: 1.7945876147132367 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27920517325401306, valid regret : -0.27467450499534607 \n",
      "---------------------------------------iteration: 1182\n",
      "l1 decision: 0.08931078016757965\n",
      "l1 weight: 0.15010923147201538\n",
      "avg viol: 1.768452624756028, max viol: 1.790703495265916 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28465715050697327, valid regret : -0.2689927816390991 \n",
      "---------------------------------------iteration: 1183\n",
      "l1 decision: 0.08820965886116028\n",
      "l1 weight: 0.14832589030265808\n",
      "avg viol: 1.7497006978769787, max viol: 1.7631529837381095 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28014153242111206, valid regret : -0.2803693115711212 \n",
      "---------------------------------------iteration: 1184\n",
      "l1 decision: 0.08838839828968048\n",
      "l1 weight: 0.1478678435087204\n",
      "avg viol: 1.7567361522780265, max viol: 1.7790416070492938 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27276110649108887, valid regret : -0.2701847553253174 \n",
      "---------------------------------------iteration: 1185\n",
      "l1 decision: 0.08924595266580582\n",
      "l1 weight: 0.1479855179786682\n",
      "avg viol: 1.7626237458846299, max viol: 1.7806470796931535 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.266610711812973, valid regret : -0.2746208608150482 \n",
      "---------------------------------------iteration: 1186\n",
      "l1 decision: 0.08822028338909149\n",
      "l1 weight: 0.15024210512638092\n",
      "avg viol: 1.7537055528084238, max viol: 1.7772503521991894 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2785274386405945, valid regret : -0.27621668577194214 \n",
      "---------------------------------------iteration: 1187\n",
      "l1 decision: 0.08864104002714157\n",
      "l1 weight: 0.1498994380235672\n",
      "avg viol: 1.7576773161668098, max viol: 1.7758635813370347 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27607762813568115, valid regret : -0.2689201831817627 \n",
      "---------------------------------------iteration: 1188\n",
      "l1 decision: 0.08856624364852905\n",
      "l1 weight: 0.14796999096870422\n",
      "avg viol: 1.7555138816579712, max viol: 1.7712762777227908 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2709718644618988, valid regret : -0.27189165353775024 \n",
      "---------------------------------------iteration: 1189\n",
      "l1 decision: 0.08814829587936401\n",
      "l1 weight: 0.15044349431991577\n",
      "avg viol: 1.7550865675460228, max viol: 1.7764946385286748 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2750077545642853, valid regret : -0.28041234612464905 \n",
      "---------------------------------------iteration: 1190\n",
      "l1 decision: 0.08858798444271088\n",
      "l1 weight: 0.1513601541519165\n",
      "avg viol: 1.7626253165787784, max viol: 1.7811144966399297 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27651551365852356, valid regret : -0.270630806684494 \n",
      "---------------------------------------iteration: 1191\n",
      "l1 decision: 0.08854488283395767\n",
      "l1 weight: 0.15180279314517975\n",
      "avg viol: 1.7650716757585905, max viol: 1.7856911874841899 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26324427127838135, valid regret : -0.27767062187194824 \n",
      "---------------------------------------iteration: 1192\n",
      "l1 decision: 0.08826438337564468\n",
      "l1 weight: 0.15050914883613586\n",
      "avg viol: 1.7593795535293066, max viol: 1.786412354093045 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2825905680656433, valid regret : -0.2826785147190094 \n",
      "---------------------------------------iteration: 1193\n",
      "l1 decision: 0.08911971002817154\n",
      "l1 weight: 0.14867374300956726\n",
      "avg viol: 1.774848774833481, max viol: 1.7943784522358328 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2790505886077881, valid regret : -0.27507153153419495 \n",
      "---------------------------------------iteration: 1194\n",
      "l1 decision: 0.08961895853281021\n",
      "l1 weight: 0.1505800038576126\n",
      "avg viol: 1.7765449075750075, max viol: 1.795474766753614 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2868126928806305, valid regret : -0.2749389111995697 \n",
      "---------------------------------------iteration: 1195\n",
      "l1 decision: 0.08804912120103836\n",
      "l1 weight: 0.14830221235752106\n",
      "avg viol: 1.7592982759954976, max viol: 1.781078154566785 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2868949770927429, valid regret : -0.28035348653793335 \n",
      "---------------------------------------iteration: 1196\n",
      "l1 decision: 0.09130439162254333\n",
      "l1 weight: 0.14823678135871887\n",
      "avg viol: 1.7648170984943863, max viol: 1.7851389175048098 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2733803689479828, valid regret : -0.25688496232032776 \n",
      "---------------------------------------iteration: 1197\n",
      "l1 decision: 0.08543556928634644\n",
      "l1 weight: 0.1485210359096527\n",
      "avg viol: 1.7106948956480483, max viol: 1.7413103964645416 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2512481212615967, valid regret : -0.27655860781669617 \n",
      "---------------------------------------iteration: 1198\n",
      "l1 decision: 0.08815769106149673\n",
      "l1 weight: 0.14994937181472778\n",
      "avg viol: 1.7606245254725217, max viol: 1.7868632085155696 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27963411808013916, valid regret : -0.28344419598579407 \n",
      "---------------------------------------iteration: 1199\n",
      "l1 decision: 0.08966095745563507\n",
      "l1 weight: 0.14926831424236298\n",
      "avg viol: 1.783871871012161, max viol: 1.7993582251947373 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28562015295028687, valid regret : -0.2755502760410309 \n",
      "---------------------------------------iteration: 1200\n",
      "l1 decision: 0.08976210653781891\n",
      "l1 weight: 0.1476890742778778\n",
      "avg viol: 1.7747420023888116, max viol: 1.7952855159528553 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2765718400478363, valid regret : -0.27328938245773315 \n",
      "---------------------------------------iteration: 1201\n",
      "l1 decision: 0.08820638060569763\n",
      "l1 weight: 0.1507897675037384\n",
      "avg viol: 1.756632710393169, max viol: 1.7758176198694855 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27726128697395325, valid regret : -0.2824023365974426 \n",
      "---------------------------------------iteration: 1202\n",
      "l1 decision: 0.08951243758201599\n",
      "l1 weight: 0.1516868770122528\n",
      "avg viol: 1.7797007502592168, max viol: 1.7954186638817191 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28035447001457214, valid regret : -0.2757152318954468 \n",
      "---------------------------------------iteration: 1203\n",
      "l1 decision: 0.08924590796232224\n",
      "l1 weight: 0.15129204094409943\n",
      "avg viol: 1.7787134507039446, max viol: 1.79551796297892 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26769182085990906, valid regret : -0.27656832337379456 \n",
      "---------------------------------------iteration: 1204\n",
      "l1 decision: 0.08997047692537308\n",
      "l1 weight: 0.1496468335390091\n",
      "avg viol: 1.7662676552520133, max viol: 1.7870201347395778 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2839266359806061, valid regret : -0.2703554034233093 \n",
      "---------------------------------------iteration: 1205\n",
      "l1 decision: 0.08724845200777054\n",
      "l1 weight: 0.14894628524780273\n",
      "avg viol: 1.742562223211862, max viol: 1.758436807896942 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26630720496177673, valid regret : -0.27200934290885925 \n",
      "---------------------------------------iteration: 1206\n",
      "l1 decision: 0.08883976936340332\n",
      "l1 weight: 0.15018701553344727\n",
      "avg viol: 1.7674248493649065, max viol: 1.7870587054640055 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2830445468425751, valid regret : -0.2800489366054535 \n",
      "---------------------------------------iteration: 1207\n",
      "l1 decision: 0.08934716880321503\n",
      "l1 weight: 0.14856046438217163\n",
      "avg viol: 1.7799903230249037, max viol: 1.800826903199777 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29078564047813416, valid regret : -0.28602683544158936 \n",
      "---------------------------------------iteration: 1208\n",
      "l1 decision: 0.08981534838676453\n",
      "l1 weight: 0.14746947586536407\n",
      "avg viol: 1.7820823263784404, max viol: 1.8013839956838638 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28065353631973267, valid regret : -0.2750818133354187 \n",
      "---------------------------------------iteration: 1209\n",
      "l1 decision: 0.08894605189561844\n",
      "l1 weight: 0.1478014588356018\n",
      "avg viol: 1.7768018307787132, max viol: 1.7942717464175075 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27325788140296936, valid regret : -0.2783351540565491 \n",
      "---------------------------------------iteration: 1210\n",
      "l1 decision: 0.08988095819950104\n",
      "l1 weight: 0.1497066169977188\n",
      "avg viol: 1.7686583123926538, max viol: 1.7935028078500181 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2819330096244812, valid regret : -0.2752878665924072 \n",
      "---------------------------------------iteration: 1211\n",
      "l1 decision: 0.08756881952285767\n",
      "l1 weight: 0.14963500201702118\n",
      "avg viol: 1.7511620758438948, max viol: 1.7697317483834922 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2754169702529907, valid regret : -0.2761356234550476 \n",
      "---------------------------------------iteration: 1212\n",
      "l1 decision: 0.09002301096916199\n",
      "l1 weight: 0.14768551290035248\n",
      "avg viol: 1.782779803899466, max viol: 1.8004572172649205 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2782171070575714, valid regret : -0.28031474351882935 \n",
      "---------------------------------------iteration: 1213\n",
      "l1 decision: 0.08870834112167358\n",
      "l1 weight: 0.15070712566375732\n",
      "avg viol: 1.7730335333558105, max viol: 1.7970674036478158 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2840845584869385, valid regret : -0.2829176187515259 \n",
      "---------------------------------------iteration: 1214\n",
      "l1 decision: 0.09064152091741562\n",
      "l1 weight: 0.15117210149765015\n",
      "avg viol: 1.7825882983475458, max viol: 1.7953949936199933 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28201231360435486, valid regret : -0.2683345675468445 \n",
      "---------------------------------------iteration: 1215\n",
      "l1 decision: 0.08781958371400833\n",
      "l1 weight: 0.15139932930469513\n",
      "avg viol: 1.7564568963006604, max viol: 1.7724243991542608 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2607637047767639, valid regret : -0.28019094467163086 \n",
      "---------------------------------------iteration: 1216\n",
      "l1 decision: 0.08914084732532501\n",
      "l1 weight: 0.15050895512104034\n",
      "avg viol: 1.7738518383383053, max viol: 1.7993429023772478 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28595831990242004, valid regret : -0.2858874797821045 \n",
      "---------------------------------------iteration: 1217\n",
      "l1 decision: 0.08952365815639496\n",
      "l1 weight: 0.1488192081451416\n",
      "avg viol: 1.7813005552179675, max viol: 1.8018735887599178 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28106310963630676, valid regret : -0.27267125248908997 \n",
      "---------------------------------------iteration: 1218\n",
      "l1 decision: 0.08980931341648102\n",
      "l1 weight: 0.15035822987556458\n",
      "avg viol: 1.7713070010708178, max viol: 1.789123646565713 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28527167439460754, valid regret : -0.26455622911453247 \n",
      "---------------------------------------iteration: 1219\n",
      "l1 decision: 0.08718747645616531\n",
      "l1 weight: 0.14808468520641327\n",
      "avg viol: 1.7340468437894014, max viol: 1.751114551909268 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2738575041294098, valid regret : -0.28211501240730286 \n",
      "---------------------------------------iteration: 1220\n",
      "l1 decision: 0.0882735624909401\n",
      "l1 weight: 0.14795523881912231\n",
      "avg viol: 1.7623676849441836, max viol: 1.7837867410853505 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2753713130950928, valid regret : -0.27613189816474915 \n",
      "---------------------------------------iteration: 1221\n",
      "l1 decision: 0.08963443338871002\n",
      "l1 weight: 0.1482096165418625\n",
      "avg viol: 1.7749155307952968, max viol: 1.7997753138188273 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2705244719982147, valid regret : -0.2814415395259857 \n",
      "---------------------------------------iteration: 1222\n",
      "l1 decision: 0.08953574299812317\n",
      "l1 weight: 0.14813129603862762\n",
      "avg viol: 1.78238982302777, max viol: 1.797409477410838 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28685200214385986, valid regret : -0.28238552808761597 \n",
      "---------------------------------------iteration: 1223\n",
      "l1 decision: 0.08912132680416107\n",
      "l1 weight: 0.14997608959674835\n",
      "avg viol: 1.7684611614458845, max viol: 1.7924298481084406 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2809904217720032, valid regret : -0.2693079710006714 \n",
      "---------------------------------------iteration: 1224\n",
      "l1 decision: 0.08892682194709778\n",
      "l1 weight: 0.14855080842971802\n",
      "avg viol: 1.7574808360124008, max viol: 1.7784422244876623 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27146464586257935, valid regret : -0.2692926526069641 \n",
      "---------------------------------------iteration: 1225\n",
      "l1 decision: 0.08752477169036865\n",
      "l1 weight: 0.15034081041812897\n",
      "avg viol: 1.74384969050996, max viol: 1.7650022347224876 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2727222740650177, valid regret : -0.28476956486701965 \n",
      "---------------------------------------iteration: 1226\n",
      "l1 decision: 0.08935357630252838\n",
      "l1 weight: 0.1516866832971573\n",
      "avg viol: 1.7812962775217602, max viol: 1.7976923089008778 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28195691108703613, valid regret : -0.2757759392261505 \n",
      "---------------------------------------iteration: 1227\n",
      "l1 decision: 0.08914270997047424\n",
      "l1 weight: 0.15209193527698517\n",
      "avg viol: 1.7798801829083823, max viol: 1.7991204647696577 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26891589164733887, valid regret : -0.2794943153858185 \n",
      "---------------------------------------iteration: 1228\n",
      "l1 decision: 0.08993159234523773\n",
      "l1 weight: 0.1507881134748459\n",
      "avg viol: 1.7739758274343331, max viol: 1.797069405671209 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.286245733499527, valid regret : -0.2737773656845093 \n",
      "---------------------------------------iteration: 1229\n",
      "l1 decision: 0.08722246438264847\n",
      "l1 weight: 0.14821866154670715\n",
      "avg viol: 1.7452069698856212, max viol: 1.7631952507654205 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26825693249702454, valid regret : -0.27266982197761536 \n",
      "---------------------------------------iteration: 1230\n",
      "l1 decision: 0.09004548192024231\n",
      "l1 weight: 0.14963175356388092\n",
      "avg viol: 1.776145202020416, max viol: 1.7934893922647461 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28560593724250793, valid regret : -0.27301090955734253 \n",
      "---------------------------------------iteration: 1231\n",
      "l1 decision: 0.08805612474679947\n",
      "l1 weight: 0.14771603047847748\n",
      "avg viol: 1.7587506689538714, max viol: 1.7742126686498523 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28469496965408325, valid regret : -0.27688243985176086 \n",
      "---------------------------------------iteration: 1232\n",
      "l1 decision: 0.08934873342514038\n",
      "l1 weight: 0.1476966142654419\n",
      "avg viol: 1.758737810254097, max viol: 1.7773085297085345 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27169033885002136, valid regret : -0.2623714506626129 \n",
      "---------------------------------------iteration: 1233\n",
      "l1 decision: 0.08670841157436371\n",
      "l1 weight: 0.14799807965755463\n",
      "avg viol: 1.7362877278856468, max viol: 1.755148099618964 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2596677541732788, valid regret : -0.2788187265396118 \n",
      "---------------------------------------iteration: 1234\n",
      "l1 decision: 0.08964122831821442\n",
      "l1 weight: 0.14781761169433594\n",
      "avg viol: 1.780478900837479, max viol: 1.7934298852924258 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28455373644828796, valid regret : -0.2861495614051819 \n",
      "---------------------------------------iteration: 1235\n",
      "l1 decision: 0.08888174593448639\n",
      "l1 weight: 0.14929133653640747\n",
      "avg viol: 1.7770639020571617, max viol: 1.8002224643714726 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2843833863735199, valid regret : -0.2766278386116028 \n",
      "---------------------------------------iteration: 1236\n",
      "l1 decision: 0.08997876197099686\n",
      "l1 weight: 0.14758974313735962\n",
      "avg viol: 1.7856657746924611, max viol: 1.8023990759975277 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27983224391937256, valid regret : -0.2791648507118225 \n",
      "---------------------------------------iteration: 1237\n",
      "l1 decision: 0.08856318145990372\n",
      "l1 weight: 0.15006622672080994\n",
      "avg viol: 1.7701733519922163, max viol: 1.7918217751430348 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28401610255241394, valid regret : -0.28061777353286743 \n",
      "---------------------------------------iteration: 1238\n",
      "l1 decision: 0.09051394462585449\n",
      "l1 weight: 0.15172135829925537\n",
      "avg viol: 1.7639830996614183, max viol: 1.7885419512167573 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27521613240242004, valid regret : -0.26186642050743103 \n",
      "---------------------------------------iteration: 1239\n",
      "l1 decision: 0.08779219537973404\n",
      "l1 weight: 0.15133164823055267\n",
      "avg viol: 1.7436734289256857, max viol: 1.7548301834613085 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25521421432495117, valid regret : -0.2780592143535614 \n",
      "---------------------------------------iteration: 1240\n",
      "l1 decision: 0.08878832310438156\n",
      "l1 weight: 0.15047411620616913\n",
      "avg viol: 1.7697788957000011, max viol: 1.7891282070195302 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28517478704452515, valid regret : -0.28595682978630066 \n",
      "---------------------------------------iteration: 1241\n",
      "l1 decision: 0.08984363824129105\n",
      "l1 weight: 0.1485704481601715\n",
      "avg viol: 1.7834510327255884, max viol: 1.802960409084335 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28112220764160156, valid regret : -0.2772323787212372 \n",
      "---------------------------------------iteration: 1242\n",
      "l1 decision: 0.08957209438085556\n",
      "l1 weight: 0.15018759667873383\n",
      "avg viol: 1.7786772865086096, max viol: 1.7994353881804273 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28818178176879883, valid regret : -0.27328112721443176 \n",
      "---------------------------------------iteration: 1243\n",
      "l1 decision: 0.08885025233030319\n",
      "l1 weight: 0.14785227179527283\n",
      "avg viol: 1.7624397460010368, max viol: 1.7753976930398494 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28548046946525574, valid regret : -0.2748396098613739 \n",
      "---------------------------------------iteration: 1244\n",
      "l1 decision: 0.08911065757274628\n",
      "l1 weight: 0.1476774513721466\n",
      "avg viol: 1.746042495695292, max viol: 1.759369421750307 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26981258392333984, valid regret : -0.26356247067451477 \n",
      "---------------------------------------iteration: 1245\n",
      "l1 decision: 0.08707622438669205\n",
      "l1 weight: 0.14775925874710083\n",
      "avg viol: 1.7369388071692082, max viol: 1.757672863546759 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2590000033378601, valid regret : -0.28097009658813477 \n",
      "---------------------------------------iteration: 1246\n",
      "l1 decision: 0.08893167227506638\n",
      "l1 weight: 0.14852198958396912\n",
      "avg viol: 1.7747153043970867, max viol: 1.7948905826197006 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28412604331970215, valid regret : -0.2870149314403534 \n",
      "---------------------------------------iteration: 1247\n",
      "l1 decision: 0.08963492512702942\n",
      "l1 weight: 0.14983154833316803\n",
      "avg viol: 1.7857805904323323, max viol: 1.8043468607356772 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28643086552619934, valid regret : -0.2783556878566742 \n",
      "---------------------------------------iteration: 1248\n",
      "l1 decision: 0.08963806927204132\n",
      "l1 weight: 0.14821933209896088\n",
      "avg viol: 1.7851071074366518, max viol: 1.8038627600762993 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28003251552581787, valid regret : -0.28265079855918884 \n",
      "---------------------------------------iteration: 1249\n",
      "l1 decision: 0.08926017582416534\n",
      "l1 weight: 0.1510152965784073\n",
      "avg viol: 1.779044344738395, max viol: 1.8047311804257333 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2842470109462738, valid regret : -0.28447645902633667 \n",
      "---------------------------------------iteration: 1250\n",
      "l1 decision: 0.08907101303339005\n",
      "l1 weight: 0.15158753097057343\n",
      "avg viol: 1.7780188327182804, max viol: 1.7969103253562935 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28130894899368286, valid regret : -0.2714848518371582 \n",
      "---------------------------------------iteration: 1251\n",
      "l1 decision: 0.09077852219343185\n",
      "l1 weight: 0.15165770053863525\n",
      "avg viol: 1.7692769629496616, max viol: 1.7863975706277415 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2633049190044403, valid regret : -0.2601303458213806 \n",
      "---------------------------------------iteration: 1252\n",
      "l1 decision: 0.08609157055616379\n",
      "l1 weight: 0.14904211461544037\n",
      "avg viol: 1.7251713375357212, max viol: 1.7442647106945515 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26867061853408813, valid regret : -0.279474675655365 \n",
      "---------------------------------------iteration: 1253\n",
      "l1 decision: 0.08919677883386612\n",
      "l1 weight: 0.14925271272659302\n",
      "avg viol: 1.76713883193559, max viol: 1.7844086124096066 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27581679821014404, valid regret : -0.2744758427143097 \n",
      "---------------------------------------iteration: 1254\n",
      "l1 decision: 0.08863130956888199\n",
      "l1 weight: 0.1499616801738739\n",
      "avg viol: 1.771529048917073, max viol: 1.7927483527746517 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28663578629493713, valid regret : -0.27847686409950256 \n",
      "---------------------------------------iteration: 1255\n",
      "l1 decision: 0.09107417613267899\n",
      "l1 weight: 0.14843545854091644\n",
      "avg viol: 1.778107363503659, max viol: 1.7933265781030059 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29000428318977356, valid regret : -0.27264395356178284 \n",
      "---------------------------------------iteration: 1256\n",
      "l1 decision: 0.08756860345602036\n",
      "l1 weight: 0.1472158133983612\n",
      "avg viol: 1.7504630216391524, max viol: 1.7645329560618848 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26951849460601807, valid regret : -0.2705638110637665 \n",
      "---------------------------------------iteration: 1257\n",
      "l1 decision: 0.08959390223026276\n",
      "l1 weight: 0.14822125434875488\n",
      "avg viol: 1.7672516443219501, max viol: 1.786210100632161 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26818111538887024, valid regret : -0.27667537331581116 \n",
      "---------------------------------------iteration: 1258\n",
      "l1 decision: 0.08799769729375839\n",
      "l1 weight: 0.14807426929473877\n",
      "avg viol: 1.7598519781552022, max viol: 1.7800721456296742 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2810737192630768, valid regret : -0.28343665599823 \n",
      "---------------------------------------iteration: 1259\n",
      "l1 decision: 0.08992776274681091\n",
      "l1 weight: 0.15006159245967865\n",
      "avg viol: 1.7749656173563562, max viol: 1.795463738963008 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28293314576148987, valid regret : -0.2758149206638336 \n",
      "---------------------------------------iteration: 1260\n",
      "l1 decision: 0.08898324519395828\n",
      "l1 weight: 0.14748643338680267\n",
      "avg viol: 1.7772836652044497, max viol: 1.7930038194463123 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27818864583969116, valid regret : -0.27888694405555725 \n",
      "---------------------------------------iteration: 1261\n",
      "l1 decision: 0.08931490033864975\n",
      "l1 weight: 0.15059150755405426\n",
      "avg viol: 1.7653105828736444, max viol: 1.7915097940713167 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28070753812789917, valid regret : -0.26939040422439575 \n",
      "---------------------------------------iteration: 1262\n",
      "l1 decision: 0.0879441350698471\n",
      "l1 weight: 0.15081268548965454\n",
      "avg viol: 1.7424345108133275, max viol: 1.7556504986714572 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26645800471305847, valid regret : -0.270851731300354 \n",
      "---------------------------------------iteration: 1263\n",
      "l1 decision: 0.0880788266658783\n",
      "l1 weight: 0.15201789140701294\n",
      "avg viol: 1.7594399662857176, max viol: 1.777209531981498 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2628559172153473, valid regret : -0.27966704964637756 \n",
      "---------------------------------------iteration: 1264\n",
      "l1 decision: 0.08973056823015213\n",
      "l1 weight: 0.14962930977344513\n",
      "avg viol: 1.7817300271196654, max viol: 1.7991521587828174 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2879876494407654, valid regret : -0.28576645255088806 \n",
      "---------------------------------------iteration: 1265\n",
      "l1 decision: 0.08964991569519043\n",
      "l1 weight: 0.14912185072898865\n",
      "avg viol: 1.780573067116202, max viol: 1.7975792433135211 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2813255190849304, valid regret : -0.27403897047042847 \n",
      "---------------------------------------iteration: 1266\n",
      "l1 decision: 0.08897402137517929\n",
      "l1 weight: 0.14975689351558685\n",
      "avg viol: 1.7740357837465854, max viol: 1.7890190369216725 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2869073152542114, valid regret : -0.27770933508872986 \n",
      "---------------------------------------iteration: 1267\n",
      "l1 decision: 0.0901980921626091\n",
      "l1 weight: 0.14889243245124817\n",
      "avg viol: 1.7696833525260445, max viol: 1.7870803236728534 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28849828243255615, valid regret : -0.2674475610256195 \n",
      "---------------------------------------iteration: 1268\n",
      "l1 decision: 0.08692088723182678\n",
      "l1 weight: 0.1474602371454239\n",
      "avg viol: 1.731666139808949, max viol: 1.7502726106904447 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26233741641044617, valid regret : -0.27071717381477356 \n",
      "---------------------------------------iteration: 1269\n",
      "l1 decision: 0.08777707815170288\n",
      "l1 weight: 0.14834044873714447\n",
      "avg viol: 1.753782490895319, max viol: 1.7762686773203313 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.267970472574234, valid regret : -0.28043675422668457 \n",
      "---------------------------------------iteration: 1270\n",
      "l1 decision: 0.0896599292755127\n",
      "l1 weight: 0.14889556169509888\n",
      "avg viol: 1.7807691639581753, max viol: 1.7993124529602937 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28511378169059753, valid regret : -0.2856873869895935 \n",
      "---------------------------------------iteration: 1271\n",
      "l1 decision: 0.08871746063232422\n",
      "l1 weight: 0.14996793866157532\n",
      "avg viol: 1.7731391750577314, max viol: 1.7965740157524124 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2845346927642822, valid regret : -0.2766226828098297 \n",
      "---------------------------------------iteration: 1272\n",
      "l1 decision: 0.0907566249370575\n",
      "l1 weight: 0.1478491574525833\n",
      "avg viol: 1.7848882412316742, max viol: 1.8003565254621208 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27848488092422485, valid regret : -0.2761186361312866 \n",
      "---------------------------------------iteration: 1273\n",
      "l1 decision: 0.08815376460552216\n",
      "l1 weight: 0.14969998598098755\n",
      "avg viol: 1.7621214719500857, max viol: 1.7805933016352355 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28155556321144104, valid regret : -0.2844022810459137 \n",
      "---------------------------------------iteration: 1274\n",
      "l1 decision: 0.09033045172691345\n",
      "l1 weight: 0.1519130915403366\n",
      "avg viol: 1.7771358586847783, max viol: 1.797155014704913 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2796526551246643, valid regret : -0.2684895396232605 \n",
      "---------------------------------------iteration: 1275\n",
      "l1 decision: 0.08786486834287643\n",
      "l1 weight: 0.15182222425937653\n",
      "avg viol: 1.7567763311759337, max viol: 1.7741300463676453 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26133501529693604, valid regret : -0.27906784415245056 \n",
      "---------------------------------------iteration: 1276\n",
      "l1 decision: 0.08981699496507645\n",
      "l1 weight: 0.14974211156368256\n",
      "avg viol: 1.7754104505351278, max viol: 1.7965837512165308 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.286444753408432, valid regret : -0.28329646587371826 \n",
      "---------------------------------------iteration: 1277\n",
      "l1 decision: 0.088810496032238\n",
      "l1 weight: 0.1482575535774231\n",
      "avg viol: 1.773302355541964, max viol: 1.7902040020562708 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2792779207229614, valid regret : -0.2732284367084503 \n",
      "---------------------------------------iteration: 1278\n",
      "l1 decision: 0.0899595320224762\n",
      "l1 weight: 0.14989013969898224\n",
      "avg viol: 1.7738755306671374, max viol: 1.7897866978310049 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.285232812166214, valid regret : -0.2668069899082184 \n",
      "---------------------------------------iteration: 1279\n",
      "l1 decision: 0.08702106028795242\n",
      "l1 weight: 0.14831408858299255\n",
      "avg viol: 1.742927722823806, max viol: 1.757714114501141 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2775958180427551, valid regret : -0.2834627628326416 \n",
      "---------------------------------------iteration: 1280\n",
      "l1 decision: 0.0898158997297287\n",
      "l1 weight: 0.1473456472158432\n",
      "avg viol: 1.7777126353618222, max viol: 1.793654619017616 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2782849669456482, valid regret : -0.27403998374938965 \n",
      "---------------------------------------iteration: 1281\n",
      "l1 decision: 0.08890878409147263\n",
      "l1 weight: 0.14801736176013947\n",
      "avg viol: 1.768883837744943, max viol: 1.7909276764839888 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26953113079071045, valid regret : -0.2765779495239258 \n",
      "---------------------------------------iteration: 1282\n",
      "l1 decision: 0.08962740004062653\n",
      "l1 weight: 0.14844174683094025\n",
      "avg viol: 1.7700541216740384, max viol: 1.7860054969787598 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2821241617202759, valid regret : -0.2670595645904541 \n",
      "---------------------------------------iteration: 1283\n",
      "l1 decision: 0.08730895817279816\n",
      "l1 weight: 0.1489909440279007\n",
      "avg viol: 1.7340627004246927, max viol: 1.7464897818863392 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2668614685535431, valid regret : -0.2724185585975647 \n",
      "---------------------------------------iteration: 1284\n",
      "l1 decision: 0.08825667202472687\n",
      "l1 weight: 0.14768588542938232\n",
      "avg viol: 1.7642590016113173, max viol: 1.7868408318609 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2750062048435211, valid regret : -0.2797638177871704 \n",
      "---------------------------------------iteration: 1285\n",
      "l1 decision: 0.08972939848899841\n",
      "l1 weight: 0.15026356279850006\n",
      "avg viol: 1.7823628972808, max viol: 1.8014166370267048 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2848721146583557, valid regret : -0.28555771708488464 \n",
      "---------------------------------------iteration: 1286\n",
      "l1 decision: 0.08893507719039917\n",
      "l1 weight: 0.15131109952926636\n",
      "avg viol: 1.7780221095234992, max viol: 1.7990980132017285 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28259575366973877, valid regret : -0.2741772532463074 \n",
      "---------------------------------------iteration: 1287\n",
      "l1 decision: 0.09083467721939087\n",
      "l1 weight: 0.1519426703453064\n",
      "avg viol: 1.777664817388868, max viol: 1.7927794348215684 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2662559151649475, valid regret : -0.27153074741363525 \n",
      "---------------------------------------iteration: 1288\n",
      "l1 decision: 0.08746558427810669\n",
      "l1 weight: 0.15004552900791168\n",
      "avg viol: 1.7500751580193172, max viol: 1.7692034388892353 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27864351868629456, valid regret : -0.2851431369781494 \n",
      "---------------------------------------iteration: 1289\n",
      "l1 decision: 0.09028191864490509\n",
      "l1 weight: 0.148565873503685\n",
      "avg viol: 1.7837512040091679, max viol: 1.7998630973743275 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28064870834350586, valid regret : -0.27565184235572815 \n",
      "---------------------------------------iteration: 1290\n",
      "l1 decision: 0.08876346796751022\n",
      "l1 weight: 0.1494569033384323\n",
      "avg viol: 1.7747514923466952, max viol: 1.7961237800773233 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2873513698577881, valid regret : -0.27851662039756775 \n",
      "---------------------------------------iteration: 1291\n",
      "l1 decision: 0.09025587886571884\n",
      "l1 weight: 0.14875103533267975\n",
      "avg viol: 1.7725399782881142, max viol: 1.792338946601376 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2887178361415863, valid regret : -0.27562519907951355 \n",
      "---------------------------------------iteration: 1292\n",
      "l1 decision: 0.0872839018702507\n",
      "l1 weight: 0.14693373441696167\n",
      "avg viol: 1.747536063453881, max viol: 1.7679000903153792 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27002155780792236, valid regret : -0.2755182385444641 \n",
      "---------------------------------------iteration: 1293\n",
      "l1 decision: 0.08965721726417542\n",
      "l1 weight: 0.14794118702411652\n",
      "avg viol: 1.781709897244582, max viol: 1.799070607405156 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.273666650056839, valid regret : -0.2813875079154968 \n",
      "---------------------------------------iteration: 1294\n",
      "l1 decision: 0.08908099681138992\n",
      "l1 weight: 0.14784114062786102\n",
      "avg viol: 1.7776747022413475, max viol: 1.8016244252212346 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28499606251716614, valid regret : -0.28545424342155457 \n",
      "---------------------------------------iteration: 1295\n",
      "l1 decision: 0.09014468640089035\n",
      "l1 weight: 0.14993973076343536\n",
      "avg viol: 1.7802237377048005, max viol: 1.7983351764269173 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28503668308258057, valid regret : -0.2685106098651886 \n",
      "---------------------------------------iteration: 1296\n",
      "l1 decision: 0.08822983503341675\n",
      "l1 weight: 0.14737853407859802\n",
      "avg viol: 1.7555271465948317, max viol: 1.7697208877652884 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27022284269332886, valid regret : -0.2779475450515747 \n",
      "---------------------------------------iteration: 1297\n",
      "l1 decision: 0.08900273591279984\n",
      "l1 weight: 0.15027189254760742\n",
      "avg viol: 1.770606602379703, max viol: 1.7875423328951001 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2825111448764801, valid regret : -0.2765255868434906 \n",
      "---------------------------------------iteration: 1298\n",
      "l1 decision: 0.08891421556472778\n",
      "l1 weight: 0.15102802217006683\n",
      "avg viol: 1.7580082987761125, max viol: 1.7724447951186448 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2729005217552185, valid regret : -0.2756706178188324 \n",
      "---------------------------------------iteration: 1299\n",
      "l1 decision: 0.08943666517734528\n",
      "l1 weight: 0.15135343372821808\n",
      "avg viol: 1.7788859161752044, max viol: 1.7948421774199232 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2683160901069641, valid regret : -0.27690160274505615 \n",
      "---------------------------------------iteration: 1300\n",
      "l1 decision: 0.08816687017679214\n",
      "l1 weight: 0.14966440200805664\n",
      "avg viol: 1.7615318501917137, max viol: 1.7879311236320063 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28324511647224426, valid regret : -0.2850712239742279 \n",
      "---------------------------------------iteration: 1301\n",
      "l1 decision: 0.09083806723356247\n",
      "l1 weight: 0.14863088726997375\n",
      "avg viol: 1.782394150791224, max viol: 1.7968422276899219 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28034141659736633, valid regret : -0.27303728461265564 \n",
      "---------------------------------------iteration: 1302\n",
      "l1 decision: 0.08845208585262299\n",
      "l1 weight: 0.1495273858308792\n",
      "avg viol: 1.7674324587627779, max viol: 1.7863969024037942 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28523609042167664, valid regret : -0.2805902063846588 \n",
      "---------------------------------------iteration: 1303\n",
      "l1 decision: 0.09068457782268524\n",
      "l1 weight: 0.14839479327201843\n",
      "avg viol: 1.780519930430455, max viol: 1.7939214353682473 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29134780168533325, valid regret : -0.2752816081047058 \n",
      "---------------------------------------iteration: 1304\n",
      "l1 decision: 0.08739025890827179\n",
      "l1 weight: 0.14709748327732086\n",
      "avg viol: 1.7465718971769093, max viol: 1.7653116512810811 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2693904638290405, valid regret : -0.27540796995162964 \n",
      "---------------------------------------iteration: 1305\n",
      "l1 decision: 0.08955631405115128\n",
      "l1 weight: 0.1476535201072693\n",
      "avg viol: 1.7796844267495908, max viol: 1.7966016484424472 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27235090732574463, valid regret : -0.2824106812477112 \n",
      "---------------------------------------iteration: 1306\n",
      "l1 decision: 0.0892753005027771\n",
      "l1 weight: 0.14781324565410614\n",
      "avg viol: 1.780451154597613, max viol: 1.7976190449553542 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2867702841758728, valid regret : -0.2825399339199066 \n",
      "---------------------------------------iteration: 1307\n",
      "l1 decision: 0.09045516699552536\n",
      "l1 weight: 0.14943289756774902\n",
      "avg viol: 1.7727875579416286, max viol: 1.7917418266879395 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2825663387775421, valid regret : -0.26393046975135803 \n",
      "---------------------------------------iteration: 1308\n",
      "l1 decision: 0.08718223869800568\n",
      "l1 weight: 0.14721238613128662\n",
      "avg viol: 1.744039035414462, max viol: 1.7582181046018377 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26594483852386475, valid regret : -0.2788366973400116 \n",
      "---------------------------------------iteration: 1309\n",
      "l1 decision: 0.08911773562431335\n",
      "l1 weight: 0.1504085659980774\n",
      "avg viol: 1.7748902957880637, max viol: 1.7928600856103003 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2835010290145874, valid regret : -0.2862134575843811 \n",
      "---------------------------------------iteration: 1310\n",
      "l1 decision: 0.0897480845451355\n",
      "l1 weight: 0.15082304179668427\n",
      "avg viol: 1.7861332598192894, max viol: 1.7989492790657096 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28353336453437805, valid regret : -0.2766972780227661 \n",
      "---------------------------------------iteration: 1311\n",
      "l1 decision: 0.09018833190202713\n",
      "l1 weight: 0.15186823904514313\n",
      "avg viol: 1.779694678883534, max viol: 1.7964460568036884 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.268500417470932, valid regret : -0.27400293946266174 \n",
      "---------------------------------------iteration: 1312\n",
      "l1 decision: 0.08775104582309723\n",
      "l1 weight: 0.14954455196857452\n",
      "avg viol: 1.7550164737505838, max viol: 1.773260613437742 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2817176580429077, valid regret : -0.2859421968460083 \n",
      "---------------------------------------iteration: 1313\n",
      "l1 decision: 0.09054604172706604\n",
      "l1 weight: 0.1484776884317398\n",
      "avg viol: 1.7870471094071398, max viol: 1.8024229852017015 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2817792594432831, valid regret : -0.2741054594516754 \n",
      "---------------------------------------iteration: 1314\n",
      "l1 decision: 0.08840443193912506\n",
      "l1 weight: 0.14947135746479034\n",
      "avg viol: 1.7681942831602646, max viol: 1.7876032339408994 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28520333766937256, valid regret : -0.2788168787956238 \n",
      "---------------------------------------iteration: 1315\n",
      "l1 decision: 0.09055295586585999\n",
      "l1 weight: 0.14803150296211243\n",
      "avg viol: 1.7796995377889835, max viol: 1.794014579616487 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29120171070098877, valid regret : -0.2778935432434082 \n",
      "---------------------------------------iteration: 1316\n",
      "l1 decision: 0.08784904330968857\n",
      "l1 weight: 0.14659592509269714\n",
      "avg viol: 1.7582203088951065, max viol: 1.773375007789582 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2737024426460266, valid regret : -0.2769920229911804 \n",
      "---------------------------------------iteration: 1317\n",
      "l1 decision: 0.09000912308692932\n",
      "l1 weight: 0.1475435048341751\n",
      "avg viol: 1.7846127726673149, max viol: 1.7996147288940847 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2739836573600769, valid regret : -0.2812495529651642 \n",
      "---------------------------------------iteration: 1318\n",
      "l1 decision: 0.08883459120988846\n",
      "l1 weight: 0.1480093151330948\n",
      "avg viol: 1.773219585411498, max viol: 1.8002193432766944 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28400981426239014, valid regret : -0.2843887209892273 \n",
      "---------------------------------------iteration: 1319\n",
      "l1 decision: 0.0900811180472374\n",
      "l1 weight: 0.14952027797698975\n",
      "avg viol: 1.775795424557873, max viol: 1.7995725084329024 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2836439311504364, valid regret : -0.26865142583847046 \n",
      "---------------------------------------iteration: 1320\n",
      "l1 decision: 0.08799345046281815\n",
      "l1 weight: 0.14732478559017181\n",
      "avg viol: 1.7563686964777299, max viol: 1.7717900681309402 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27090755105018616, valid regret : -0.28068551421165466 \n",
      "---------------------------------------iteration: 1321\n",
      "l1 decision: 0.08935033529996872\n",
      "l1 weight: 0.15058942139148712\n",
      "avg viol: 1.7801734591880813, max viol: 1.800562478019856 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2852296829223633, valid regret : -0.285925030708313 \n",
      "---------------------------------------iteration: 1322\n",
      "l1 decision: 0.08936886489391327\n",
      "l1 weight: 0.15135407447814941\n",
      "avg viol: 1.7814913219623123, max viol: 1.7977169705554843 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2822037637233734, valid regret : -0.27378207445144653 \n",
      "---------------------------------------iteration: 1323\n",
      "l1 decision: 0.08992442488670349\n",
      "l1 weight: 0.15130667388439178\n",
      "avg viol: 1.774755859852885, max viol: 1.7911903533386067 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2669660151004791, valid regret : -0.26672786474227905 \n",
      "---------------------------------------iteration: 1324\n",
      "l1 decision: 0.08699151873588562\n",
      "l1 weight: 0.14995424449443817\n",
      "avg viol: 1.7381325535429641, max viol: 1.75539292616304 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2735016942024231, valid regret : -0.2845103144645691 \n",
      "---------------------------------------iteration: 1325\n",
      "l1 decision: 0.08901369571685791\n",
      "l1 weight: 0.1487284153699875\n",
      "avg viol: 1.7770263751702078, max viol: 1.7955296136206016 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2802168130874634, valid regret : -0.2766568660736084 \n",
      "---------------------------------------iteration: 1326\n",
      "l1 decision: 0.08917863667011261\n",
      "l1 weight: 0.14991110563278198\n",
      "avg viol: 1.7799240074762748, max viol: 1.799700342467986 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28806325793266296, valid regret : -0.2808176279067993 \n",
      "---------------------------------------iteration: 1327\n",
      "l1 decision: 0.09059251099824905\n",
      "l1 weight: 0.14856332540512085\n",
      "avg viol: 1.7833253184403293, max viol: 1.797823202330619 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29285717010498047, valid regret : -0.27373459935188293 \n",
      "---------------------------------------iteration: 1328\n",
      "l1 decision: 0.08717349916696548\n",
      "l1 weight: 0.1475072056055069\n",
      "avg viol: 1.7457193850993644, max viol: 1.7612550024641678 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2689458727836609, valid regret : -0.2752530574798584 \n",
      "---------------------------------------iteration: 1329\n",
      "l1 decision: 0.08998212963342667\n",
      "l1 weight: 0.14815199375152588\n",
      "avg viol: 1.7799554736883147, max viol: 1.7984369540354237 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2723914384841919, valid regret : -0.28088411688804626 \n",
      "---------------------------------------iteration: 1330\n",
      "l1 decision: 0.08876694738864899\n",
      "l1 weight: 0.1481027603149414\n",
      "avg viol: 1.773030768001845, max viol: 1.7965896347304806 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.284892201423645, valid regret : -0.28389254212379456 \n",
      "---------------------------------------iteration: 1331\n",
      "l1 decision: 0.09086904674768448\n",
      "l1 weight: 0.14952558279037476\n",
      "avg viol: 1.7787399742915295, max viol: 1.7972209326690063 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28361934423446655, valid regret : -0.2690412998199463 \n",
      "---------------------------------------iteration: 1332\n",
      "l1 decision: 0.08782513439655304\n",
      "l1 weight: 0.14816813170909882\n",
      "avg viol: 1.755736306795734, max viol: 1.7744287942769006 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2707410156726837, valid regret : -0.2810826301574707 \n",
      "---------------------------------------iteration: 1333\n",
      "l1 decision: 0.08968130499124527\n",
      "l1 weight: 0.14992043375968933\n",
      "avg viol: 1.7805009311111644, max viol: 1.8032497732201591 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2843853831291199, valid regret : -0.2854275405406952 \n",
      "---------------------------------------iteration: 1334\n",
      "l1 decision: 0.08925870805978775\n",
      "l1 weight: 0.1510394960641861\n",
      "avg viol: 1.7809610558822715, max viol: 1.7992543682339601 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28279414772987366, valid regret : -0.27512672543525696 \n",
      "---------------------------------------iteration: 1335\n",
      "l1 decision: 0.09008636325597763\n",
      "l1 weight: 0.15193471312522888\n",
      "avg viol: 1.7791104464267846, max viol: 1.7943804732058197 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26796725392341614, valid regret : -0.27341940999031067 \n",
      "---------------------------------------iteration: 1336\n",
      "l1 decision: 0.0878467708826065\n",
      "l1 weight: 0.14900389313697815\n",
      "avg viol: 1.755908721438609, max viol: 1.7731571585172787 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2808298170566559, valid regret : -0.2856023907661438 \n",
      "---------------------------------------iteration: 1337\n",
      "l1 decision: 0.09007202088832855\n",
      "l1 weight: 0.14888547360897064\n",
      "avg viol: 1.7835742360859876, max viol: 1.802272140281275 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2812732756137848, valid regret : -0.27326664328575134 \n",
      "---------------------------------------iteration: 1338\n",
      "l1 decision: 0.08843517303466797\n",
      "l1 weight: 0.14954932034015656\n",
      "avg viol: 1.7682573290588335, max viol: 1.7887169455643743 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2844288647174835, valid regret : -0.2799459993839264 \n",
      "---------------------------------------iteration: 1339\n",
      "l1 decision: 0.0904323011636734\n",
      "l1 weight: 0.1487046480178833\n",
      "avg viol: 1.7815928755444475, max viol: 1.7992407698184252 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2915114164352417, valid regret : -0.27671709656715393 \n",
      "---------------------------------------iteration: 1340\n",
      "l1 decision: 0.08774963021278381\n",
      "l1 weight: 0.14673182368278503\n",
      "avg viol: 1.7551521551172482, max viol: 1.7724661458050832 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27185747027397156, valid regret : -0.274555504322052 \n",
      "---------------------------------------iteration: 1341\n",
      "l1 decision: 0.08966943621635437\n",
      "l1 weight: 0.1475110948085785\n",
      "avg viol: 1.7766296782688005, max viol: 1.7947243395028636 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27159225940704346, valid regret : -0.27472400665283203 \n",
      "---------------------------------------iteration: 1342\n",
      "l1 decision: 0.08828692883253098\n",
      "l1 weight: 0.14819729328155518\n",
      "avg viol: 1.7634510213637258, max viol: 1.780262518208474 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2806388735771179, valid regret : -0.27904486656188965 \n",
      "---------------------------------------iteration: 1343\n",
      "l1 decision: 0.08890422433614731\n",
      "l1 weight: 0.1494242250919342\n",
      "avg viol: 1.75920142303803, max viol: 1.781928414478898 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2770352363586426, valid regret : -0.26200589537620544 \n",
      "---------------------------------------iteration: 1344\n",
      "l1 decision: 0.08699511736631393\n",
      "l1 weight: 0.14843936264514923\n",
      "avg viol: 1.7401411949191243, max viol: 1.7570810235338286 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2645331919193268, valid regret : -0.2783118188381195 \n",
      "---------------------------------------iteration: 1345\n",
      "l1 decision: 0.08927714824676514\n",
      "l1 weight: 0.14952224493026733\n",
      "avg viol: 1.7769532425055514, max viol: 1.791685519972816 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2838629484176636, valid regret : -0.28401950001716614 \n",
      "---------------------------------------iteration: 1346\n",
      "l1 decision: 0.08867143094539642\n",
      "l1 weight: 0.15086035430431366\n",
      "avg viol: 1.7735692776548058, max viol: 1.7937510586925782 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2808893024921417, valid regret : -0.27643901109695435 \n",
      "---------------------------------------iteration: 1347\n",
      "l1 decision: 0.0901431143283844\n",
      "l1 weight: 0.1513710469007492\n",
      "avg viol: 1.7828283747663953, max viol: 1.7978738753590733 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2695038914680481, valid regret : -0.2739364504814148 \n",
      "---------------------------------------iteration: 1348\n",
      "l1 decision: 0.08765609562397003\n",
      "l1 weight: 0.1496446281671524\n",
      "avg viol: 1.753240188100608, max viol: 1.7782734023639932 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2809264361858368, valid regret : -0.28597959876060486 \n",
      "---------------------------------------iteration: 1349\n",
      "l1 decision: 0.08987028896808624\n",
      "l1 weight: 0.14865534007549286\n",
      "avg viol: 1.7825301358976866, max viol: 1.800430657924153 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2805592119693756, valid regret : -0.27331042289733887 \n",
      "---------------------------------------iteration: 1350\n",
      "l1 decision: 0.08851476013660431\n",
      "l1 weight: 0.14909401535987854\n",
      "avg viol: 1.7696921125543303, max viol: 1.78632482199464 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28614336252212524, valid regret : -0.27930906414985657 \n",
      "---------------------------------------iteration: 1351\n",
      "l1 decision: 0.09050118178129196\n",
      "l1 weight: 0.14854538440704346\n",
      "avg viol: 1.7761391071270918, max viol: 1.7926870675291866 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2901970446109772, valid regret : -0.27640897035598755 \n",
      "---------------------------------------iteration: 1352\n",
      "l1 decision: 0.08761992305517197\n",
      "l1 weight: 0.1469678282737732\n",
      "avg viol: 1.7531367878313175, max viol: 1.7713192538358271 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27176979184150696, valid regret : -0.27561816573143005 \n",
      "---------------------------------------iteration: 1353\n",
      "l1 decision: 0.08942151814699173\n",
      "l1 weight: 0.14794224500656128\n",
      "avg viol: 1.7798596812185132, max viol: 1.798479744233191 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2730155289173126, valid regret : -0.28151705861091614 \n",
      "---------------------------------------iteration: 1354\n",
      "l1 decision: 0.08956193923950195\n",
      "l1 weight: 0.14837294816970825\n",
      "avg viol: 1.7843990977761677, max viol: 1.7992317634634674 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2872560918331146, valid regret : -0.2824079692363739 \n",
      "---------------------------------------iteration: 1355\n",
      "l1 decision: 0.08980448544025421\n",
      "l1 weight: 0.14971135556697845\n",
      "avg viol: 1.7693643895711284, max viol: 1.7920916622970253 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28187426924705505, valid regret : -0.2630782425403595 \n",
      "---------------------------------------iteration: 1356\n",
      "l1 decision: 0.08749733120203018\n",
      "l1 weight: 0.14840908348560333\n",
      "avg viol: 1.741863660016097, max viol: 1.758643442299217 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26445332169532776, valid regret : -0.276326060295105 \n",
      "---------------------------------------iteration: 1357\n",
      "l1 decision: 0.0881127119064331\n",
      "l1 weight: 0.150247260928154\n",
      "avg viol: 1.7603128848580674, max viol: 1.782209299504757 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28079286217689514, valid regret : -0.28538814187049866 \n",
      "---------------------------------------iteration: 1358\n",
      "l1 decision: 0.09024558216333389\n",
      "l1 weight: 0.15089532732963562\n",
      "avg viol: 1.788154492811882, max viol: 1.8017048275796697 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28304028511047363, valid regret : -0.27733519673347473 \n",
      "---------------------------------------iteration: 1359\n",
      "l1 decision: 0.08891257643699646\n",
      "l1 weight: 0.1522175520658493\n",
      "avg viol: 1.7760792286510332, max viol: 1.8016689578071237 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26865991950035095, valid regret : -0.28218013048171997 \n",
      "---------------------------------------iteration: 1360\n",
      "l1 decision: 0.08996997028589249\n",
      "l1 weight: 0.14948776364326477\n",
      "avg viol: 1.7854811085396796, max viol: 1.8037507352419198 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28931015729904175, valid regret : -0.2838716506958008 \n",
      "---------------------------------------iteration: 1361\n",
      "l1 decision: 0.08880120515823364\n",
      "l1 weight: 0.14871704578399658\n",
      "avg viol: 1.7743724726454821, max viol: 1.7936299815773964 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2792491018772125, valid regret : -0.2728351354598999 \n",
      "---------------------------------------iteration: 1362\n",
      "l1 decision: 0.09026877582073212\n",
      "l1 weight: 0.15003158152103424\n",
      "avg viol: 1.7701942846144083, max viol: 1.7893001060001552 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2842694818973541, valid regret : -0.26533377170562744 \n",
      "---------------------------------------iteration: 1363\n",
      "l1 decision: 0.08659610897302628\n",
      "l1 weight: 0.1482042670249939\n",
      "avg viol: 1.734193315199227, max viol: 1.758084823610261 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.275551438331604, valid regret : -0.2807787358760834 \n",
      "---------------------------------------iteration: 1364\n",
      "l1 decision: 0.0897369384765625\n",
      "l1 weight: 0.14669202268123627\n",
      "avg viol: 1.7714450990915065, max viol: 1.7876353496685624 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27618563175201416, valid regret : -0.2721802592277527 \n",
      "---------------------------------------iteration: 1365\n",
      "l1 decision: 0.08838222920894623\n",
      "l1 weight: 0.1471891850233078\n",
      "avg viol: 1.767263017563382, max viol: 1.7829894172027707 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27076542377471924, valid regret : -0.27987322211265564 \n",
      "---------------------------------------iteration: 1366\n",
      "l1 decision: 0.09039027988910675\n",
      "l1 weight: 0.14839738607406616\n",
      "avg viol: 1.782018618870643, max viol: 1.7968350700102746 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28561222553253174, valid regret : -0.2853931188583374 \n",
      "---------------------------------------iteration: 1367\n",
      "l1 decision: 0.08895713090896606\n",
      "l1 weight: 0.14893604815006256\n",
      "avg viol: 1.7773080871413913, max viol: 1.7993062230525538 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.284920871257782, valid regret : -0.27570873498916626 \n",
      "---------------------------------------iteration: 1368\n",
      "l1 decision: 0.0898829773068428\n",
      "l1 weight: 0.14847306907176971\n",
      "avg viol: 1.778064037945005, max viol: 1.7968439578544348 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2774304747581482, valid regret : -0.27310970425605774 \n",
      "---------------------------------------iteration: 1369\n",
      "l1 decision: 0.08773544430732727\n",
      "l1 weight: 0.14938032627105713\n",
      "avg viol: 1.7554918807337527, max viol: 1.7738009103341028 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27856484055519104, valid regret : -0.28586921095848083 \n",
      "---------------------------------------iteration: 1370\n",
      "l1 decision: 0.08989495784044266\n",
      "l1 weight: 0.15109257400035858\n",
      "avg viol: 1.7845566870027687, max viol: 1.8022065405966714 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2822530269622803, valid regret : -0.2767060697078705 \n",
      "---------------------------------------iteration: 1371\n",
      "l1 decision: 0.08900731056928635\n",
      "l1 weight: 0.1520674079656601\n",
      "avg viol: 1.7779579681016913, max viol: 1.7993335700593889 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26849693059921265, valid regret : -0.28115737438201904 \n",
      "---------------------------------------iteration: 1372\n",
      "l1 decision: 0.08986924588680267\n",
      "l1 weight: 0.1493164598941803\n",
      "avg viol: 1.7817835281544832, max viol: 1.8036900693550706 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28848952054977417, valid regret : -0.2820393443107605 \n",
      "---------------------------------------iteration: 1373\n",
      "l1 decision: 0.08866143971681595\n",
      "l1 weight: 0.14828024804592133\n",
      "avg viol: 1.7697802105220035, max viol: 1.7854992781067267 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2776787579059601, valid regret : -0.27528610825538635 \n",
      "---------------------------------------iteration: 1374\n",
      "l1 decision: 0.08982367068529129\n",
      "l1 weight: 0.14989817142486572\n",
      "avg viol: 1.776021937612677, max viol: 1.798592519480735 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28650131821632385, valid regret : -0.27559220790863037 \n",
      "---------------------------------------iteration: 1375\n",
      "l1 decision: 0.0880618616938591\n",
      "l1 weight: 0.14804084599018097\n",
      "avg viol: 1.7607892043178435, max viol: 1.7798081596847624 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2867034077644348, valid regret : -0.286239892244339 \n",
      "---------------------------------------iteration: 1376\n",
      "l1 decision: 0.09019434452056885\n",
      "l1 weight: 0.147606760263443\n",
      "avg viol: 1.7835968135367148, max viol: 1.8020149013027549 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28065118193626404, valid regret : -0.2745937407016754 \n",
      "---------------------------------------iteration: 1377\n",
      "l1 decision: 0.08842665702104568\n",
      "l1 weight: 0.14820298552513123\n",
      "avg viol: 1.7685621374746552, max viol: 1.7934288322576322 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2710232436656952, valid regret : -0.28016892075538635 \n",
      "---------------------------------------iteration: 1378\n",
      "l1 decision: 0.09008777886629105\n",
      "l1 weight: 0.1487930417060852\n",
      "avg viol: 1.7774530154751846, max viol: 1.7977726182434708 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28359946608543396, valid regret : -0.2769908905029297 \n",
      "---------------------------------------iteration: 1379\n",
      "l1 decision: 0.08795507997274399\n",
      "l1 weight: 0.14889900386333466\n",
      "avg viol: 1.7588289669167716, max viol: 1.7754750333260745 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2781837284564972, valid regret : -0.2728891372680664 \n",
      "---------------------------------------iteration: 1380\n",
      "l1 decision: 0.09002348780632019\n",
      "l1 weight: 0.14816561341285706\n",
      "avg viol: 1.7731249067466706, max viol: 1.792484458303079 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27466362714767456, valid regret : -0.27371418476104736 \n",
      "---------------------------------------iteration: 1381\n",
      "l1 decision: 0.0875171646475792\n",
      "l1 weight: 0.1492236703634262\n",
      "avg viol: 1.7520481664163525, max viol: 1.7711588947568089 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.277603417634964, valid regret : -0.28255245089530945 \n",
      "---------------------------------------iteration: 1382\n",
      "l1 decision: 0.08970369398593903\n",
      "l1 weight: 0.15122711658477783\n",
      "avg viol: 1.77863872175687, max viol: 1.7915587145835161 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27977386116981506, valid regret : -0.2676924765110016 \n",
      "---------------------------------------iteration: 1383\n",
      "l1 decision: 0.08805323392152786\n",
      "l1 weight: 0.15133142471313477\n",
      "avg viol: 1.7591344684723298, max viol: 1.7739401017315686 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26080894470214844, valid regret : -0.2778586149215698 \n",
      "---------------------------------------iteration: 1384\n",
      "l1 decision: 0.0890166386961937\n",
      "l1 weight: 0.14931979775428772\n",
      "avg viol: 1.7746342483989428, max viol: 1.7940027699805796 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28575050830841064, valid regret : -0.28210678696632385 \n",
      "---------------------------------------iteration: 1385\n",
      "l1 decision: 0.0890105664730072\n",
      "l1 weight: 0.14846809208393097\n",
      "avg viol: 1.7751509813462325, max viol: 1.7943387809209526 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27851516008377075, valid regret : -0.2740142047405243 \n",
      "---------------------------------------iteration: 1386\n",
      "l1 decision: 0.08956830203533173\n",
      "l1 weight: 0.14964641630649567\n",
      "avg viol: 1.77374276624294, max viol: 1.7920749492477626 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28617727756500244, valid regret : -0.26886481046676636 \n",
      "---------------------------------------iteration: 1387\n",
      "l1 decision: 0.08742016553878784\n",
      "l1 weight: 0.1482592523097992\n",
      "avg viol: 1.7471122597745852, max viol: 1.7639950448647141 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27967238426208496, valid regret : -0.2824573814868927 \n",
      "---------------------------------------iteration: 1388\n",
      "l1 decision: 0.08886008709669113\n",
      "l1 weight: 0.14790089428424835\n",
      "avg viol: 1.7672310399846174, max viol: 1.7944249025313184 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27630797028541565, valid regret : -0.2756820023059845 \n",
      "---------------------------------------iteration: 1389\n",
      "l1 decision: 0.08860324323177338\n",
      "l1 weight: 0.14812831580638885\n",
      "avg viol: 1.7712566229585354, max viol: 1.7966960887424648 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27127009630203247, valid regret : -0.28065791726112366 \n",
      "---------------------------------------iteration: 1390\n",
      "l1 decision: 0.0903368666768074\n",
      "l1 weight: 0.14865180850028992\n",
      "avg viol: 1.7801120869832812, max viol: 1.79936036397703 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28483498096466064, valid regret : -0.28245049715042114 \n",
      "---------------------------------------iteration: 1391\n",
      "l1 decision: 0.08862032741308212\n",
      "l1 weight: 0.14882998168468475\n",
      "avg viol: 1.7672818559389998, max viol: 1.7845264356583357 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28181275725364685, valid regret : -0.27414649724960327 \n",
      "---------------------------------------iteration: 1392\n",
      "l1 decision: 0.08961288630962372\n",
      "l1 weight: 0.14814968407154083\n",
      "avg viol: 1.7713544060947606, max viol: 1.790065755834803 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27603644132614136, valid regret : -0.2746223211288452 \n",
      "---------------------------------------iteration: 1393\n",
      "l1 decision: 0.08792106807231903\n",
      "l1 weight: 0.1495957374572754\n",
      "avg viol: 1.7576497476384976, max viol: 1.7781110503710806 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27937522530555725, valid regret : -0.2864137887954712 \n",
      "---------------------------------------iteration: 1394\n",
      "l1 decision: 0.08992213010787964\n",
      "l1 weight: 0.1514103263616562\n",
      "avg viol: 1.7857107068726328, max viol: 1.8022343883058056 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2827164828777313, valid regret : -0.2775071859359741 \n",
      "---------------------------------------iteration: 1395\n",
      "l1 decision: 0.08933155983686447\n",
      "l1 weight: 0.1516551971435547\n",
      "avg viol: 1.7833395506686065, max viol: 1.799418632290326 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2697695791721344, valid regret : -0.28122347593307495 \n",
      "---------------------------------------iteration: 1396\n",
      "l1 decision: 0.09011442959308624\n",
      "l1 weight: 0.14879295229911804\n",
      "avg viol: 1.7840850617701653, max viol: 1.800211219349876 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28913503885269165, valid regret : -0.27861982583999634 \n",
      "---------------------------------------iteration: 1397\n",
      "l1 decision: 0.08804761618375778\n",
      "l1 weight: 0.1482803374528885\n",
      "avg viol: 1.7609247785748448, max viol: 1.775697352946736 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27468541264533997, valid regret : -0.27442431449890137 \n",
      "---------------------------------------iteration: 1398\n",
      "l1 decision: 0.09010712802410126\n",
      "l1 weight: 0.14976733922958374\n",
      "avg viol: 1.7758778955071466, max viol: 1.7955507535953075 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28530293703079224, valid regret : -0.27513906359672546 \n",
      "---------------------------------------iteration: 1399\n",
      "l1 decision: 0.08801107108592987\n",
      "l1 weight: 0.14838726818561554\n",
      "avg viol: 1.7604151663876837, max viol: 1.7771964753046632 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28574806451797485, valid regret : -0.281438946723938 \n",
      "---------------------------------------iteration: 1400\n",
      "l1 decision: 0.0897054374217987\n",
      "l1 weight: 0.1468108892440796\n",
      "avg viol: 1.7707951222371776, max viol: 1.7870346244890243 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2758302390575409, valid regret : -0.26448097825050354 \n",
      "---------------------------------------iteration: 1401\n",
      "l1 decision: 0.08730233460664749\n",
      "l1 weight: 0.1473282128572464\n",
      "avg viol: 1.7480354914540657, max viol: 1.7626240467652678 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26261162757873535, valid regret : -0.2792889177799225 \n",
      "---------------------------------------iteration: 1402\n",
      "l1 decision: 0.08927493542432785\n",
      "l1 weight: 0.14841105043888092\n",
      "avg viol: 1.7770725280570332, max viol: 1.7957307184115052 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28416335582733154, valid regret : -0.2855614125728607 \n",
      "---------------------------------------iteration: 1403\n",
      "l1 decision: 0.08855710178613663\n",
      "l1 weight: 0.14904311299324036\n",
      "avg viol: 1.7716263003968016, max viol: 1.7982848020619713 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28353455662727356, valid regret : -0.27664458751678467 \n",
      "---------------------------------------iteration: 1404\n",
      "l1 decision: 0.08980964124202728\n",
      "l1 weight: 0.14815157651901245\n",
      "avg viol: 1.778115767966956, max viol: 1.7992044135462493 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27738213539123535, valid regret : -0.27517902851104736 \n",
      "---------------------------------------iteration: 1405\n",
      "l1 decision: 0.08761576563119888\n",
      "l1 weight: 0.15034903585910797\n",
      "avg viol: 1.7529748515505343, max viol: 1.777368548209779 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27860671281814575, valid regret : -0.2867421507835388 \n",
      "---------------------------------------iteration: 1406\n",
      "l1 decision: 0.08994844555854797\n",
      "l1 weight: 0.15132972598075867\n",
      "avg viol: 1.7868150329543278, max viol: 1.802893379703164 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2830530107021332, valid regret : -0.27736687660217285 \n",
      "---------------------------------------iteration: 1407\n",
      "l1 decision: 0.08911018818616867\n",
      "l1 weight: 0.15182487666606903\n",
      "avg viol: 1.77948489213617, max viol: 1.8003651409526356 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26887357234954834, valid regret : -0.2820187509059906 \n",
      "---------------------------------------iteration: 1408\n",
      "l1 decision: 0.08967092633247375\n",
      "l1 weight: 0.1493646502494812\n",
      "avg viol: 1.7808503813293646, max viol: 1.8011848701862618 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2895773649215698, valid regret : -0.28425121307373047 \n",
      "---------------------------------------iteration: 1409\n",
      "l1 decision: 0.08925512433052063\n",
      "l1 weight: 0.14843793213367462\n",
      "avg viol: 1.7774853758215614, max viol: 1.790785514516756 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28028130531311035, valid regret : -0.2702321708202362 \n",
      "---------------------------------------iteration: 1410\n",
      "l1 decision: 0.08959575742483139\n",
      "l1 weight: 0.14993765950202942\n",
      "avg viol: 1.7606438282260206, max viol: 1.776845199521631 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2823536694049835, valid regret : -0.26757556200027466 \n",
      "---------------------------------------iteration: 1411\n",
      "l1 decision: 0.08742319792509079\n",
      "l1 weight: 0.14818863570690155\n",
      "avg viol: 1.7433750703959958, max viol: 1.758729872526601 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27767157554626465, valid regret : -0.2848183512687683 \n",
      "---------------------------------------iteration: 1412\n",
      "l1 decision: 0.08896899223327637\n",
      "l1 weight: 0.14671792089939117\n",
      "avg viol: 1.7743719454173332, max viol: 1.7927819748874754 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2787289023399353, valid regret : -0.2782033085823059 \n",
      "---------------------------------------iteration: 1413\n",
      "l1 decision: 0.08936403691768646\n",
      "l1 weight: 0.14885097742080688\n",
      "avg viol: 1.7800120798734498, max viol: 1.8036269134609029 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2733776569366455, valid regret : -0.2823595702648163 \n",
      "---------------------------------------iteration: 1414\n",
      "l1 decision: 0.08948341012001038\n",
      "l1 weight: 0.14891231060028076\n",
      "avg viol: 1.7798734513410455, max viol: 1.8021665813867003 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2857828140258789, valid regret : -0.2837693691253662 \n",
      "---------------------------------------iteration: 1415\n",
      "l1 decision: 0.08915147185325623\n",
      "l1 weight: 0.14894375205039978\n",
      "avg viol: 1.7772674320789519, max viol: 1.7918805715162307 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2844471335411072, valid regret : -0.27453500032424927 \n",
      "---------------------------------------iteration: 1416\n",
      "l1 decision: 0.08972899615764618\n",
      "l1 weight: 0.1481986939907074\n",
      "avg viol: 1.7726827262120788, max viol: 1.791564776445739 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27619364857673645, valid regret : -0.2699851095676422 \n",
      "---------------------------------------iteration: 1417\n",
      "l1 decision: 0.08724737912416458\n",
      "l1 weight: 0.1501370072364807\n",
      "avg viol: 1.7462019509542734, max viol: 1.7648111013695598 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2751240134239197, valid regret : -0.28603994846343994 \n",
      "---------------------------------------iteration: 1418\n",
      "l1 decision: 0.08976364135742188\n",
      "l1 weight: 0.15123960375785828\n",
      "avg viol: 1.787626626084093, max viol: 1.803367143147625 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28329288959503174, valid regret : -0.27842193841934204 \n",
      "---------------------------------------iteration: 1419\n",
      "l1 decision: 0.08953386545181274\n",
      "l1 weight: 0.15144279599189758\n",
      "avg viol: 1.7850062018247264, max viol: 1.8050432595191523 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2701340913772583, valid regret : -0.281000554561615 \n",
      "---------------------------------------iteration: 1420\n",
      "l1 decision: 0.08995147794485092\n",
      "l1 weight: 0.1492164134979248\n",
      "avg viol: 1.7820582276867936, max viol: 1.8003167961724102 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2894481122493744, valid regret : -0.2788349390029907 \n",
      "---------------------------------------iteration: 1421\n",
      "l1 decision: 0.08794455975294113\n",
      "l1 weight: 0.14822401106357574\n",
      "avg viol: 1.7583953924675007, max viol: 1.7759070979664102 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2743940055370331, valid regret : -0.2746344804763794 \n",
      "---------------------------------------iteration: 1422\n",
      "l1 decision: 0.09014516323804855\n",
      "l1 weight: 0.14951342344284058\n",
      "avg viol: 1.7741399963735602, max viol: 1.7930139341624454 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2843353748321533, valid regret : -0.2733883857727051 \n",
      "---------------------------------------iteration: 1423\n",
      "l1 decision: 0.0876065194606781\n",
      "l1 weight: 0.1478431671857834\n",
      "avg viol: 1.7534352313593262, max viol: 1.7705503234174103 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28420713543891907, valid regret : -0.284260630607605 \n",
      "---------------------------------------iteration: 1424\n",
      "l1 decision: 0.08963675796985626\n",
      "l1 weight: 0.14736159145832062\n",
      "avg viol: 1.776805953901494, max viol: 1.794814559398219 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2777353525161743, valid regret : -0.27453503012657166 \n",
      "---------------------------------------iteration: 1425\n",
      "l1 decision: 0.08849038928747177\n",
      "l1 weight: 0.14740224182605743\n",
      "avg viol: 1.7694514340405294, max viol: 1.7874146106187254 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27095043659210205, valid regret : -0.2814685106277466 \n",
      "---------------------------------------iteration: 1426\n",
      "l1 decision: 0.08945956081151962\n",
      "l1 weight: 0.1487015187740326\n",
      "avg viol: 1.7779660378955304, max viol: 1.7995510215405375 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28405314683914185, valid regret : -0.28529489040374756 \n",
      "---------------------------------------iteration: 1427\n",
      "l1 decision: 0.08887387812137604\n",
      "l1 weight: 0.14867322146892548\n",
      "avg viol: 1.7765508420704281, max viol: 1.7969227988505736 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28445807099342346, valid regret : -0.27466872334480286 \n",
      "---------------------------------------iteration: 1428\n",
      "l1 decision: 0.09037717431783676\n",
      "l1 weight: 0.1475025862455368\n",
      "avg viol: 1.7789071529591456, max viol: 1.7954605983104557 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2771044075489044, valid regret : -0.27069976925849915 \n",
      "---------------------------------------iteration: 1429\n",
      "l1 decision: 0.08751221746206284\n",
      "l1 weight: 0.14956797659397125\n",
      "avg viol: 1.7518627673079026, max viol: 1.769049401045777 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2769671678543091, valid regret : -0.28586074709892273 \n",
      "---------------------------------------iteration: 1430\n",
      "l1 decision: 0.08950207382440567\n",
      "l1 weight: 0.15120065212249756\n",
      "avg viol: 1.7804485441092401, max viol: 1.802530668093823 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2812417447566986, valid regret : -0.27783942222595215 \n",
      "---------------------------------------iteration: 1431\n",
      "l1 decision: 0.08965061604976654\n",
      "l1 weight: 0.15154610574245453\n",
      "avg viol: 1.786088233459377, max viol: 1.803792581311427 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27061110734939575, valid regret : -0.28158795833587646 \n",
      "---------------------------------------iteration: 1432\n",
      "l1 decision: 0.08962502330541611\n",
      "l1 weight: 0.1494799256324768\n",
      "avg viol: 1.781314686553669, max viol: 1.7996779552195221 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2891558110713959, valid regret : -0.28250592947006226 \n",
      "---------------------------------------iteration: 1433\n",
      "l1 decision: 0.08866706490516663\n",
      "l1 weight: 0.14819929003715515\n",
      "avg viol: 1.7716506542993011, max viol: 1.7867189040407538 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2784615755081177, valid regret : -0.2737491726875305 \n",
      "---------------------------------------iteration: 1434\n",
      "l1 decision: 0.09017679840326309\n",
      "l1 weight: 0.1495228111743927\n",
      "avg viol: 1.7755476630164777, max viol: 1.792098558973521 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2868807017803192, valid regret : -0.26974546909332275 \n",
      "---------------------------------------iteration: 1435\n",
      "l1 decision: 0.08727432042360306\n",
      "l1 weight: 0.14829358458518982\n",
      "avg viol: 1.7453177566197702, max viol: 1.7647810250055045 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2794720530509949, valid regret : -0.2842887341976166 \n",
      "---------------------------------------iteration: 1436\n",
      "l1 decision: 0.08917907625436783\n",
      "l1 weight: 0.14734916388988495\n",
      "avg viol: 1.7779695469734724, max viol: 1.7944059534929693 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2794019877910614, valid regret : -0.2761368751525879 \n",
      "---------------------------------------iteration: 1437\n",
      "l1 decision: 0.08940703421831131\n",
      "l1 weight: 0.14743950963020325\n",
      "avg viol: 1.781717437101579, max viol: 1.8011914519011043 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27380645275115967, valid regret : -0.28183960914611816 \n",
      "---------------------------------------iteration: 1438\n",
      "l1 decision: 0.08985461294651031\n",
      "l1 weight: 0.14843960106372833\n",
      "avg viol: 1.7790001098369248, max viol: 1.7982196104712784 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28522789478302, valid regret : -0.2761099338531494 \n",
      "---------------------------------------iteration: 1439\n",
      "l1 decision: 0.08844645321369171\n",
      "l1 weight: 0.14867345988750458\n",
      "avg viol: 1.7562296283023897, max viol: 1.7710157386027277 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2762073278427124, valid regret : -0.2751185894012451 \n",
      "---------------------------------------iteration: 1440\n",
      "l1 decision: 0.08918444812297821\n",
      "l1 weight: 0.14812541007995605\n",
      "avg viol: 1.7784229412279091, max viol: 1.7947349169990048 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27766793966293335, valid regret : -0.2805020809173584 \n",
      "---------------------------------------iteration: 1441\n",
      "l1 decision: 0.08916959911584854\n",
      "l1 weight: 0.14926046133041382\n",
      "avg viol: 1.781448478452512, max viol: 1.796524461125955 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2861621379852295, valid regret : -0.2825784385204315 \n",
      "---------------------------------------iteration: 1442\n",
      "l1 decision: 0.09043072164058685\n",
      "l1 weight: 0.15112975239753723\n",
      "avg viol: 1.7707417414785596, max viol: 1.7903005338739604 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2779220938682556, valid regret : -0.2605079710483551 \n",
      "---------------------------------------iteration: 1443\n",
      "l1 decision: 0.08694149553775787\n",
      "l1 weight: 0.15078365802764893\n",
      "avg viol: 1.7401325884496328, max viol: 1.7551944428123534 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.25420117378234863, valid regret : -0.2780698239803314 \n",
      "---------------------------------------iteration: 1444\n",
      "l1 decision: 0.08925887942314148\n",
      "l1 weight: 0.14862920343875885\n",
      "avg viol: 1.771003223216394, max viol: 1.7902130717411637 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2842700183391571, valid regret : -0.28587090969085693 \n",
      "---------------------------------------iteration: 1445\n",
      "l1 decision: 0.08952423185110092\n",
      "l1 weight: 0.14818890392780304\n",
      "avg viol: 1.7851017572124328, max viol: 1.7992872439790517 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28252291679382324, valid regret : -0.2765710949897766 \n",
      "---------------------------------------iteration: 1446\n",
      "l1 decision: 0.09005375951528549\n",
      "l1 weight: 0.149617001414299\n",
      "avg viol: 1.7805962067062502, max viol: 1.8008957784622908 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2872850000858307, valid regret : -0.27639061212539673 \n",
      "---------------------------------------iteration: 1447\n",
      "l1 decision: 0.08819735050201416\n",
      "l1 weight: 0.14764618873596191\n",
      "avg viol: 1.762730847800849, max viol: 1.7834295842330903 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2877594232559204, valid regret : -0.283931702375412 \n",
      "---------------------------------------iteration: 1448\n",
      "l1 decision: 0.09060998260974884\n",
      "l1 weight: 0.14699120819568634\n",
      "avg viol: 1.7807601892796812, max viol: 1.7934782623779029 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27987387776374817, valid regret : -0.2699962854385376 \n",
      "---------------------------------------iteration: 1449\n",
      "l1 decision: 0.08775319159030914\n",
      "l1 weight: 0.14761722087860107\n",
      "avg viol: 1.7555043184629175, max viol: 1.7769575114361942 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2679939568042755, valid regret : -0.2810448706150055 \n",
      "---------------------------------------iteration: 1450\n",
      "l1 decision: 0.08999123424291611\n",
      "l1 weight: 0.1478414535522461\n",
      "avg viol: 1.7868543803971262, max viol: 1.7995188522618264 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28685152530670166, valid regret : -0.2852581739425659 \n",
      "---------------------------------------iteration: 1451\n",
      "l1 decision: 0.08901229500770569\n",
      "l1 weight: 0.14845947921276093\n",
      "avg viol: 1.779246671416331, max viol: 1.79513254086487 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2859022617340088, valid regret : -0.27307361364364624 \n",
      "---------------------------------------iteration: 1452\n",
      "l1 decision: 0.0902281105518341\n",
      "l1 weight: 0.14742279052734375\n",
      "avg viol: 1.7726905611879191, max viol: 1.790115146432072 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2749594449996948, valid regret : -0.26780426502227783 \n",
      "---------------------------------------iteration: 1453\n",
      "l1 decision: 0.08696765452623367\n",
      "l1 weight: 0.14910300076007843\n",
      "avg viol: 1.7427830962982263, max viol: 1.7603859183145687 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2722286581993103, valid regret : -0.28420063853263855 \n",
      "---------------------------------------iteration: 1454\n",
      "l1 decision: 0.08943278342485428\n",
      "l1 weight: 0.15084916353225708\n",
      "avg viol: 1.7797076924837893, max viol: 1.7932928943773732 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28126630187034607, valid regret : -0.27583834528923035 \n",
      "---------------------------------------iteration: 1455\n",
      "l1 decision: 0.08941737562417984\n",
      "l1 weight: 0.15157797932624817\n",
      "avg viol: 1.7822729202894334, max viol: 1.7983374596806243 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2692859172821045, valid regret : -0.28105631470680237 \n",
      "---------------------------------------iteration: 1456\n",
      "l1 decision: 0.08975276350975037\n",
      "l1 weight: 0.1495712846517563\n",
      "avg viol: 1.78040259974543, max viol: 1.7991677436511964 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2891528010368347, valid regret : -0.2839372754096985 \n",
      "---------------------------------------iteration: 1457\n",
      "l1 decision: 0.08880680054426193\n",
      "l1 weight: 0.14846475422382355\n",
      "avg viol: 1.7734118952142308, max viol: 1.7917812447994947 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2787114381790161, valid regret : -0.27460938692092896 \n",
      "---------------------------------------iteration: 1458\n",
      "l1 decision: 0.08992928266525269\n",
      "l1 weight: 0.15024398267269135\n",
      "avg viol: 1.7754520490358119, max viol: 1.7931246899534017 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28636521100997925, valid regret : -0.27546870708465576 \n",
      "---------------------------------------iteration: 1459\n",
      "l1 decision: 0.08792667835950851\n",
      "l1 weight: 0.14749298989772797\n",
      "avg viol: 1.7583953672868666, max viol: 1.7762180030113086 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28776586055755615, valid regret : -0.28582438826560974 \n",
      "---------------------------------------iteration: 1460\n",
      "l1 decision: 0.09062188863754272\n",
      "l1 weight: 0.1470058411359787\n",
      "avg viol: 1.7876518039160874, max viol: 1.8021393166854978 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2817089557647705, valid regret : -0.27451008558273315 \n",
      "---------------------------------------iteration: 1461\n",
      "l1 decision: 0.08870510756969452\n",
      "l1 weight: 0.1480201631784439\n",
      "avg viol: 1.7734332398633705, max viol: 1.7929521843325347 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2727695107460022, valid regret : -0.28043675422668457 \n",
      "---------------------------------------iteration: 1462\n",
      "l1 decision: 0.09014962613582611\n",
      "l1 weight: 0.14846263825893402\n",
      "avg viol: 1.7747651296085678, max viol: 1.7951011892873794 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2827707827091217, valid regret : -0.2757549285888672 \n",
      "---------------------------------------iteration: 1463\n",
      "l1 decision: 0.08756345510482788\n",
      "l1 weight: 0.14941824972629547\n",
      "avg viol: 1.752001997719053, max viol: 1.7684712156187743 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.275077760219574, valid regret : -0.27639439702033997 \n",
      "---------------------------------------iteration: 1464\n",
      "l1 decision: 0.08928538113832474\n",
      "l1 weight: 0.14808733761310577\n",
      "avg viol: 1.7789092406327836, max viol: 1.7957618047948927 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27762076258659363, valid regret : -0.2801612615585327 \n",
      "---------------------------------------iteration: 1465\n",
      "l1 decision: 0.0892275795340538\n",
      "l1 weight: 0.15026381611824036\n",
      "avg viol: 1.7812439204599468, max viol: 1.7980358367349254 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2858738601207733, valid regret : -0.28558602929115295 \n",
      "---------------------------------------iteration: 1466\n",
      "l1 decision: 0.09050700068473816\n",
      "l1 weight: 0.1507805436849594\n",
      "avg viol: 1.779977397210896, max viol: 1.7971357729984447 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2813517451286316, valid regret : -0.2690211832523346 \n",
      "---------------------------------------iteration: 1467\n",
      "l1 decision: 0.08779363334178925\n",
      "l1 weight: 0.15117232501506805\n",
      "avg viol: 1.7565351860655938, max viol: 1.7747715400764719 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26122626662254333, valid regret : -0.2820793390274048 \n",
      "---------------------------------------iteration: 1468\n",
      "l1 decision: 0.08974960446357727\n",
      "l1 weight: 0.14905866980552673\n",
      "avg viol: 1.783560514728888, max viol: 1.8030915799317881 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2889983355998993, valid regret : -0.287410169839859 \n",
      "---------------------------------------iteration: 1469\n",
      "l1 decision: 0.08962452411651611\n",
      "l1 weight: 0.1483839452266693\n",
      "avg viol: 1.7875343925969718, max viol: 1.803343829815276 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2838245928287506, valid regret : -0.27674391865730286 \n",
      "---------------------------------------iteration: 1470\n",
      "l1 decision: 0.09032773971557617\n",
      "l1 weight: 0.149600550532341\n",
      "avg viol: 1.7819919838424538, max viol: 1.7964823632501066 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2885622978210449, valid regret : -0.27191758155822754 \n",
      "---------------------------------------iteration: 1471\n",
      "l1 decision: 0.08772505819797516\n",
      "l1 weight: 0.14773212373256683\n",
      "avg viol: 1.7529575726785698, max viol: 1.7694502496160567 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.283051073551178, valid regret : -0.28599944710731506 \n",
      "---------------------------------------iteration: 1472\n",
      "l1 decision: 0.08991815149784088\n",
      "l1 weight: 0.14726926386356354\n",
      "avg viol: 1.7833366240991746, max viol: 1.7993251695297658 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28050458431243896, valid regret : -0.2782629728317261 \n",
      "---------------------------------------iteration: 1473\n",
      "l1 decision: 0.0891747921705246\n",
      "l1 weight: 0.14779019355773926\n",
      "avg viol: 1.7819425511186637, max viol: 1.8007540189719293 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27521952986717224, valid regret : -0.2805338203907013 \n",
      "---------------------------------------iteration: 1474\n",
      "l1 decision: 0.09032517671585083\n",
      "l1 weight: 0.14934664964675903\n",
      "avg viol: 1.780621020188555, max viol: 1.8002521444577724 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2855175733566284, valid regret : -0.27811986207962036 \n",
      "---------------------------------------iteration: 1475\n",
      "l1 decision: 0.08795549720525742\n",
      "l1 weight: 0.14877770841121674\n",
      "avg viol: 1.7588968754245433, max viol: 1.7740620489930734 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27805978059768677, valid regret : -0.2782919406890869 \n",
      "---------------------------------------iteration: 1476\n",
      "l1 decision: 0.09014282375574112\n",
      "l1 weight: 0.14751243591308594\n",
      "avg viol: 1.7876780642714585, max viol: 1.803217799635604 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27951163053512573, valid regret : -0.28020039200782776 \n",
      "---------------------------------------iteration: 1477\n",
      "l1 decision: 0.08879320323467255\n",
      "l1 weight: 0.14986614882946014\n",
      "avg viol: 1.7745046976028243, max viol: 1.7978028698125854 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2851727604866028, valid regret : -0.2852858304977417 \n",
      "---------------------------------------iteration: 1478\n",
      "l1 decision: 0.09056407958269119\n",
      "l1 weight: 0.15134726464748383\n",
      "avg viol: 1.7820572160213488, max viol: 1.7977434259373695 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2814147472381592, valid regret : -0.27017009258270264 \n",
      "---------------------------------------iteration: 1479\n",
      "l1 decision: 0.08803220838308334\n",
      "l1 weight: 0.15137016773223877\n",
      "avg viol: 1.7598954984132433, max viol: 1.7756196955451742 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2619583010673523, valid regret : -0.28186503052711487 \n",
      "---------------------------------------iteration: 1480\n",
      "l1 decision: 0.0896478146314621\n",
      "l1 weight: 0.14954006671905518\n",
      "avg viol: 1.7831033807480707, max viol: 1.8006402134196833 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28908050060272217, valid regret : -0.28713318705558777 \n",
      "---------------------------------------iteration: 1481\n",
      "l1 decision: 0.08953216671943665\n",
      "l1 weight: 0.14812587201595306\n",
      "avg viol: 1.7834347572274418, max viol: 1.8000105149694718 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28187867999076843, valid regret : -0.27794602513313293 \n",
      "---------------------------------------iteration: 1482\n",
      "l1 decision: 0.09019993245601654\n",
      "l1 weight: 0.1495397388935089\n",
      "avg viol: 1.7864826632570476, max viol: 1.802264962811023 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28999337553977966, valid regret : -0.2750377357006073 \n",
      "---------------------------------------iteration: 1483\n",
      "l1 decision: 0.08828247338533401\n",
      "l1 weight: 0.14746098220348358\n",
      "avg viol: 1.7656872114894213, max viol: 1.7796999113634229 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.288003534078598, valid regret : -0.2850053012371063 \n",
      "---------------------------------------iteration: 1484\n",
      "l1 decision: 0.09042949229478836\n",
      "l1 weight: 0.14735940098762512\n",
      "avg viol: 1.7812729376659262, max viol: 1.7977431123144925 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2797304689884186, valid regret : -0.2730627655982971 \n",
      "---------------------------------------iteration: 1485\n",
      "l1 decision: 0.0879775732755661\n",
      "l1 weight: 0.14826801419258118\n",
      "avg viol: 1.7597770492674316, max viol: 1.7825342705473304 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2691318690776825, valid regret : -0.2809300124645233 \n",
      "---------------------------------------iteration: 1486\n",
      "l1 decision: 0.08997756242752075\n",
      "l1 weight: 0.14821498095989227\n",
      "avg viol: 1.7844796512112953, max viol: 1.8011246314272285 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2875221073627472, valid regret : -0.28352198004722595 \n",
      "---------------------------------------iteration: 1487\n",
      "l1 decision: 0.08892793953418732\n",
      "l1 weight: 0.14840248227119446\n",
      "avg viol: 1.7747466698964127, max viol: 1.7888129747007042 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28400513529777527, valid regret : -0.27571266889572144 \n",
      "---------------------------------------iteration: 1488\n",
      "l1 decision: 0.08942069858312607\n",
      "l1 weight: 0.14811082184314728\n",
      "avg viol: 1.774420542618027, max viol: 1.7922117202542722 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27662575244903564, valid regret : -0.2755439579486847 \n",
      "---------------------------------------iteration: 1489\n",
      "l1 decision: 0.08813345432281494\n",
      "l1 weight: 0.14995890855789185\n",
      "avg viol: 1.762342805127846, max viol: 1.7813145354157314 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2810521125793457, valid regret : -0.2863621413707733 \n",
      "---------------------------------------iteration: 1490\n",
      "l1 decision: 0.09005061537027359\n",
      "l1 weight: 0.15098193287849426\n",
      "avg viol: 1.787188516355818, max viol: 1.8021745830774307 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2832266092300415, valid regret : -0.2752525806427002 \n",
      "---------------------------------------iteration: 1491\n",
      "l1 decision: 0.0888529121875763\n",
      "l1 weight: 0.15093190968036652\n",
      "avg viol: 1.7758943840523715, max viol: 1.7901133397826925 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26717409491539, valid regret : -0.2802463173866272 \n",
      "---------------------------------------iteration: 1492\n",
      "l1 decision: 0.09025226533412933\n",
      "l1 weight: 0.14907023310661316\n",
      "avg viol: 1.779228854692774, max viol: 1.7988943562377244 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2874208390712738, valid regret : -0.27472975850105286 \n",
      "---------------------------------------iteration: 1493\n",
      "l1 decision: 0.08789139986038208\n",
      "l1 weight: 0.1482921689748764\n",
      "avg viol: 1.7548078922735295, max viol: 1.7702210198622197 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2700805068016052, valid regret : -0.2743273973464966 \n",
      "---------------------------------------iteration: 1494\n",
      "l1 decision: 0.0894208699464798\n",
      "l1 weight: 0.14931721985340118\n",
      "avg viol: 1.775705203615944, max viol: 1.7952291262336075 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28539109230041504, valid regret : -0.2783612310886383 \n",
      "---------------------------------------iteration: 1495\n",
      "l1 decision: 0.0889834389090538\n",
      "l1 weight: 0.14743399620056152\n",
      "avg viol: 1.7763733824167867, max viol: 1.789823376107961 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29096245765686035, valid regret : -0.2855447828769684 \n",
      "---------------------------------------iteration: 1496\n",
      "l1 decision: 0.08999299257993698\n",
      "l1 weight: 0.14691162109375\n",
      "avg viol: 1.783572873477824, max viol: 1.799769718083553 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2799593508243561, valid regret : -0.2700965106487274 \n",
      "---------------------------------------iteration: 1497\n",
      "l1 decision: 0.08779390156269073\n",
      "l1 weight: 0.1488838642835617\n",
      "avg viol: 1.755128669742262, max viol: 1.775286418152973 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2663334012031555, valid regret : -0.27906882762908936 \n",
      "---------------------------------------iteration: 1498\n",
      "l1 decision: 0.0903177261352539\n",
      "l1 weight: 0.1480439305305481\n",
      "avg viol: 1.7778090477769728, max viol: 1.7938351090997458 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.283704936504364, valid regret : -0.27446675300598145 \n",
      "---------------------------------------iteration: 1499\n",
      "l1 decision: 0.08748230338096619\n",
      "l1 weight: 0.14802969992160797\n",
      "avg viol: 1.7502481705456738, max viol: 1.7644132572459057 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2746600806713104, valid regret : -0.2772281765937805 \n",
      "---------------------------------------iteration: 1500\n",
      "l1 decision: 0.089133121073246\n",
      "l1 weight: 0.1481650024652481\n",
      "avg viol: 1.7799824606676702, max viol: 1.8014612910337746 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27813997864723206, valid regret : -0.2798219621181488 \n",
      "---------------------------------------iteration: 1501\n",
      "l1 decision: 0.08936309814453125\n",
      "l1 weight: 0.14937938749790192\n",
      "avg viol: 1.785350681608452, max viol: 1.8018415072583593 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2880685329437256, valid regret : -0.28680115938186646 \n",
      "---------------------------------------iteration: 1502\n",
      "l1 decision: 0.09026695787906647\n",
      "l1 weight: 0.1503484696149826\n",
      "avg viol: 1.788817469587084, max viol: 1.8001456626225263 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2846033573150635, valid regret : -0.2717882990837097 \n",
      "---------------------------------------iteration: 1503\n",
      "l1 decision: 0.08844330161809921\n",
      "l1 weight: 0.15140801668167114\n",
      "avg viol: 1.7650409885880072, max viol: 1.7808102620765567 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2643522322177887, valid regret : -0.27888357639312744 \n",
      "---------------------------------------iteration: 1504\n",
      "l1 decision: 0.08933144807815552\n",
      "l1 weight: 0.14887800812721252\n",
      "avg viol: 1.7764526993042091, max viol: 1.7972169526619837 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2872268855571747, valid regret : -0.28414270281791687 \n",
      "---------------------------------------iteration: 1505\n",
      "l1 decision: 0.0890335664153099\n",
      "l1 weight: 0.14801593124866486\n",
      "avg viol: 1.7766113630445033, max viol: 1.7920084010111168 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27948495745658875, valid regret : -0.27495309710502625 \n",
      "---------------------------------------iteration: 1506\n",
      "l1 decision: 0.09015104174613953\n",
      "l1 weight: 0.14979785680770874\n",
      "avg viol: 1.7743693872296717, max viol: 1.7891195081174374 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2859813868999481, valid regret : -0.2655375599861145 \n",
      "---------------------------------------iteration: 1507\n",
      "l1 decision: 0.08720220625400543\n",
      "l1 weight: 0.1475924402475357\n",
      "avg viol: 1.7432281545817387, max viol: 1.760342326015234 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2776866555213928, valid regret : -0.28219741582870483 \n",
      "---------------------------------------iteration: 1508\n",
      "l1 decision: 0.08871489763259888\n",
      "l1 weight: 0.14735174179077148\n",
      "avg viol: 1.7700906826130813, max viol: 1.785656109917909 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2770264148712158, valid regret : -0.2776552438735962 \n",
      "---------------------------------------iteration: 1509\n",
      "l1 decision: 0.08982069045305252\n",
      "l1 weight: 0.14776098728179932\n",
      "avg viol: 1.784140811670659, max viol: 1.8011694757733494 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27451619505882263, valid regret : -0.27974459528923035 \n",
      "---------------------------------------iteration: 1510\n",
      "l1 decision: 0.08994246274232864\n",
      "l1 weight: 0.14826539158821106\n",
      "avg viol: 1.783964798245579, max viol: 1.7959999272134155 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2878141701221466, valid regret : -0.2733399569988251 \n",
      "---------------------------------------iteration: 1511\n",
      "l1 decision: 0.08898518234491348\n",
      "l1 weight: 0.1483510285615921\n",
      "avg viol: 1.7495707743434468, max viol: 1.769425479345955 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27207040786743164, valid regret : -0.2739814221858978 \n",
      "---------------------------------------iteration: 1512\n",
      "l1 decision: 0.08881080150604248\n",
      "l1 weight: 0.14920459687709808\n",
      "avg viol: 1.765860289612392, max viol: 1.785668532247655 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2746257483959198, valid regret : -0.2770577371120453 \n",
      "---------------------------------------iteration: 1513\n",
      "l1 decision: 0.0885079950094223\n",
      "l1 weight: 0.14912711083889008\n",
      "avg viol: 1.768626203603708, max viol: 1.789684308663709 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2831147015094757, valid regret : -0.28512734174728394 \n",
      "---------------------------------------iteration: 1514\n",
      "l1 decision: 0.09098239243030548\n",
      "l1 weight: 0.15094104409217834\n",
      "avg viol: 1.7845408902445343, max viol: 1.7974281732458621 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28230127692222595, valid regret : -0.272821307182312 \n",
      "---------------------------------------iteration: 1515\n",
      "l1 decision: 0.08842671662569046\n",
      "l1 weight: 0.15109741687774658\n",
      "avg viol: 1.7665778288978617, max viol: 1.7823989372700453 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2651086449623108, valid regret : -0.28098249435424805 \n",
      "---------------------------------------iteration: 1516\n",
      "l1 decision: 0.08984527736902237\n",
      "l1 weight: 0.14954648911952972\n",
      "avg viol: 1.7825446073763305, max viol: 1.8040900627383962 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2886883616447449, valid regret : -0.2865534722805023 \n",
      "---------------------------------------iteration: 1517\n",
      "l1 decision: 0.0893898606300354\n",
      "l1 weight: 0.14838416874408722\n",
      "avg viol: 1.7836335227219389, max viol: 1.7990863847080618 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28222939372062683, valid regret : -0.2778577208518982 \n",
      "---------------------------------------iteration: 1518\n",
      "l1 decision: 0.09021268784999847\n",
      "l1 weight: 0.14954210817813873\n",
      "avg viol: 1.7836008964013308, max viol: 1.801912642084062 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28895172476768494, valid regret : -0.27373936772346497 \n",
      "---------------------------------------iteration: 1519\n",
      "l1 decision: 0.08796842396259308\n",
      "l1 weight: 0.1476346254348755\n",
      "avg viol: 1.7584435295980074, max viol: 1.7770639995578676 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28564727306365967, valid regret : -0.2853342294692993 \n",
      "---------------------------------------iteration: 1520\n",
      "l1 decision: 0.09010810405015945\n",
      "l1 weight: 0.14778634905815125\n",
      "avg viol: 1.7800139053456951, max viol: 1.800297316396609 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27944108843803406, valid regret : -0.27136996388435364 \n",
      "---------------------------------------iteration: 1521\n",
      "l1 decision: 0.08815932273864746\n",
      "l1 weight: 0.14771439135074615\n",
      "avg viol: 1.761498938469449, max viol: 1.7777310858946294 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2681156396865845, valid regret : -0.2766999900341034 \n",
      "---------------------------------------iteration: 1522\n",
      "l1 decision: 0.08996667712926865\n",
      "l1 weight: 0.14832176268100739\n",
      "avg viol: 1.7775602386728862, max viol: 1.790360629092902 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2840132415294647, valid regret : -0.2736424505710602 \n",
      "---------------------------------------iteration: 1523\n",
      "l1 decision: 0.08750305324792862\n",
      "l1 weight: 0.14858879148960114\n",
      "avg viol: 1.7497829852899303, max viol: 1.7655790918506682 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.273689866065979, valid regret : -0.2737463414669037 \n",
      "---------------------------------------iteration: 1524\n",
      "l1 decision: 0.0886593908071518\n",
      "l1 weight: 0.14883096516132355\n",
      "avg viol: 1.771693822434172, max viol: 1.7928079480770975 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2759537994861603, valid regret : -0.2792509198188782 \n",
      "---------------------------------------iteration: 1525\n",
      "l1 decision: 0.08910280466079712\n",
      "l1 weight: 0.15012334287166595\n",
      "avg viol: 1.7793313074507022, max viol: 1.798361231572926 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28579357266426086, valid regret : -0.28739455342292786 \n",
      "---------------------------------------iteration: 1526\n",
      "l1 decision: 0.09017226845026016\n",
      "l1 weight: 0.1505543440580368\n",
      "avg viol: 1.7910622244363186, max viol: 1.8032738359179348 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28480035066604614, valid regret : -0.2760065495967865 \n",
      "---------------------------------------iteration: 1527\n",
      "l1 decision: 0.08890728652477264\n",
      "l1 weight: 0.15143178403377533\n",
      "avg viol: 1.7773976200749166, max viol: 1.7952692593680695 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26901084184646606, valid regret : -0.27878764271736145 \n",
      "---------------------------------------iteration: 1528\n",
      "l1 decision: 0.08987388759851456\n",
      "l1 weight: 0.14970436692237854\n",
      "avg viol: 1.773518368585501, max viol: 1.7948361767921597 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28668317198753357, valid regret : -0.2790880501270294 \n",
      "---------------------------------------iteration: 1529\n",
      "l1 decision: 0.08806242793798447\n",
      "l1 weight: 0.14792056381702423\n",
      "avg viol: 1.7619982628698927, max viol: 1.7757896587718278 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27481329441070557, valid regret : -0.276529461145401 \n",
      "---------------------------------------iteration: 1530\n",
      "l1 decision: 0.09006664901971817\n",
      "l1 weight: 0.14948953688144684\n",
      "avg viol: 1.780747139349114, max viol: 1.7988440562039614 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2867739200592041, valid regret : -0.27782121300697327 \n",
      "---------------------------------------iteration: 1531\n",
      "l1 decision: 0.08850236982107162\n",
      "l1 weight: 0.14829401671886444\n",
      "avg viol: 1.7688979684763764, max viol: 1.7916806292487308 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28973308205604553, valid regret : -0.28173571825027466 \n",
      "---------------------------------------iteration: 1532\n",
      "l1 decision: 0.08973138779401779\n",
      "l1 weight: 0.1477358341217041\n",
      "avg viol: 1.7716765742353164, max viol: 1.7924439314519987 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27756762504577637, valid regret : -0.27064716815948486 \n",
      "---------------------------------------iteration: 1533\n",
      "l1 decision: 0.08790431916713715\n",
      "l1 weight: 0.148236945271492\n",
      "avg viol: 1.7588238658820046, max viol: 1.7794818566180766 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26818546652793884, valid regret : -0.27961474657058716 \n",
      "---------------------------------------iteration: 1534\n",
      "l1 decision: 0.08984795212745667\n",
      "l1 weight: 0.14797750115394592\n",
      "avg viol: 1.7868393406842369, max viol: 1.8015535352751613 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28735288977622986, valid regret : -0.2854223847389221 \n",
      "---------------------------------------iteration: 1535\n",
      "l1 decision: 0.08898614346981049\n",
      "l1 weight: 0.1486642211675644\n",
      "avg viol: 1.7760917336356215, max viol: 1.797140563314315 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28496864438056946, valid regret : -0.2768612205982208 \n",
      "---------------------------------------iteration: 1536\n",
      "l1 decision: 0.08947128057479858\n",
      "l1 weight: 0.14920920133590698\n",
      "avg viol: 1.778707898509201, max viol: 1.8008348372532055 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2782115638256073, valid regret : -0.2781556248664856 \n",
      "---------------------------------------iteration: 1537\n",
      "l1 decision: 0.0890282690525055\n",
      "l1 weight: 0.14986902475357056\n",
      "avg viol: 1.7766690107623435, max viol: 1.7921995520591736 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28539809584617615, valid regret : -0.28341731429100037 \n",
      "---------------------------------------iteration: 1538\n",
      "l1 decision: 0.08998772501945496\n",
      "l1 weight: 0.15109924972057343\n",
      "avg viol: 1.7805723544943612, max viol: 1.7980542660225183 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2821141183376312, valid regret : -0.26777616143226624 \n",
      "---------------------------------------iteration: 1539\n",
      "l1 decision: 0.08801452815532684\n",
      "l1 weight: 0.15055575966835022\n",
      "avg viol: 1.7570890183211305, max viol: 1.770674018887803 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26153135299682617, valid regret : -0.2792712450027466 \n",
      "---------------------------------------iteration: 1540\n",
      "l1 decision: 0.08936262130737305\n",
      "l1 weight: 0.1489110141992569\n",
      "avg viol: 1.7810760814021342, max viol: 1.7983593927929178 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28789031505584717, valid regret : -0.2863081693649292 \n",
      "---------------------------------------iteration: 1541\n",
      "l1 decision: 0.08943778276443481\n",
      "l1 weight: 0.1482868492603302\n",
      "avg viol: 1.7779604701796599, max viol: 1.8024419161956757 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2793404459953308, valid regret : -0.2772357761859894 \n",
      "---------------------------------------iteration: 1542\n",
      "l1 decision: 0.08988933265209198\n",
      "l1 weight: 0.14974144101142883\n",
      "avg viol: 1.780433458966436, max viol: 1.7974606949137524 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2883089780807495, valid regret : -0.27115029096603394 \n",
      "---------------------------------------iteration: 1543\n",
      "l1 decision: 0.08793411403894424\n",
      "l1 weight: 0.14774620532989502\n",
      "avg viol: 1.7569959073490464, max viol: 1.7705199113115668 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28379449248313904, valid regret : -0.28533244132995605 \n",
      "---------------------------------------iteration: 1544\n",
      "l1 decision: 0.08959232270717621\n",
      "l1 weight: 0.14774329960346222\n",
      "avg viol: 1.7782207553536864, max viol: 1.800141709856689 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2792088985443115, valid regret : -0.2761686444282532 \n",
      "---------------------------------------iteration: 1545\n",
      "l1 decision: 0.08855132013559341\n",
      "l1 weight: 0.14771400392055511\n",
      "avg viol: 1.7700968799786643, max viol: 1.792033745907247 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2728378176689148, valid regret : -0.27620717883110046 \n",
      "---------------------------------------iteration: 1546\n",
      "l1 decision: 0.09075628966093063\n",
      "l1 weight: 0.1483713686466217\n",
      "avg viol: 1.7742003580118761, max viol: 1.7906287191435695 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28239914774894714, valid regret : -0.2659948170185089 \n",
      "---------------------------------------iteration: 1547\n",
      "l1 decision: 0.08650609105825424\n",
      "l1 weight: 0.1482999622821808\n",
      "avg viol: 1.7303604568273294, max viol: 1.744253354612738 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2659614682197571, valid regret : -0.27159368991851807 \n",
      "---------------------------------------iteration: 1548\n",
      "l1 decision: 0.08881314843893051\n",
      "l1 weight: 0.14875879883766174\n",
      "avg viol: 1.7647920474177226, max viol: 1.7888150498038158 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2728551924228668, valid regret : -0.2772963047027588 \n",
      "---------------------------------------iteration: 1549\n",
      "l1 decision: 0.08870650082826614\n",
      "l1 weight: 0.14917077124118805\n",
      "avg viol: 1.772872383775575, max viol: 1.7930538724176586 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28437986969947815, valid regret : -0.28568536043167114 \n",
      "---------------------------------------iteration: 1550\n",
      "l1 decision: 0.09051411598920822\n",
      "l1 weight: 0.15083211660385132\n",
      "avg viol: 1.7814241554419277, max viol: 1.7994519262574613 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28115153312683105, valid regret : -0.2736700475215912 \n",
      "---------------------------------------iteration: 1551\n",
      "l1 decision: 0.08835415542125702\n",
      "l1 weight: 0.15107661485671997\n",
      "avg viol: 1.7669073064276017, max viol: 1.7849232624284923 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26589909195899963, valid regret : -0.2803068161010742 \n",
      "---------------------------------------iteration: 1552\n",
      "l1 decision: 0.08985327929258347\n",
      "l1 weight: 0.1495637148618698\n",
      "avg viol: 1.7802512586524244, max viol: 1.7997808505315334 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2885623872280121, valid regret : -0.28432536125183105 \n",
      "---------------------------------------iteration: 1553\n",
      "l1 decision: 0.08853377401828766\n",
      "l1 weight: 0.14801569283008575\n",
      "avg viol: 1.7704283232152376, max viol: 1.7942327421624213 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2787398099899292, valid regret : -0.2767820656299591 \n",
      "---------------------------------------iteration: 1554\n",
      "l1 decision: 0.09054006636142731\n",
      "l1 weight: 0.14958560466766357\n",
      "avg viol: 1.781367301782593, max viol: 1.7975118120666593 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2878165543079376, valid regret : -0.27354851365089417 \n",
      "---------------------------------------iteration: 1555\n",
      "l1 decision: 0.08797488361597061\n",
      "l1 weight: 0.14775727689266205\n",
      "avg viol: 1.7601060001266888, max viol: 1.7783565879799426 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28537505865097046, valid regret : -0.2863790988922119 \n",
      "---------------------------------------iteration: 1556\n",
      "l1 decision: 0.09016747772693634\n",
      "l1 weight: 0.14697115123271942\n",
      "avg viol: 1.782762167219771, max viol: 1.801125808735378 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2793901860713959, valid regret : -0.2770780324935913 \n",
      "---------------------------------------iteration: 1557\n",
      "l1 decision: 0.08866526931524277\n",
      "l1 weight: 0.148856520652771\n",
      "avg viol: 1.7723083904039596, max viol: 1.7967447392002214 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2734977602958679, valid regret : -0.2792913019657135 \n",
      "---------------------------------------iteration: 1558\n",
      "l1 decision: 0.09048128128051758\n",
      "l1 weight: 0.1490936130285263\n",
      "avg viol: 1.7795235687389503, max viol: 1.7953436020761728 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2852386236190796, valid regret : -0.27864164113998413 \n",
      "---------------------------------------iteration: 1559\n",
      "l1 decision: 0.08795943856239319\n",
      "l1 weight: 0.14866489171981812\n",
      "avg viol: 1.7592292737058597, max viol: 1.7754273156169802 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27856871485710144, valid regret : -0.27763110399246216 \n",
      "---------------------------------------iteration: 1560\n",
      "l1 decision: 0.08984627574682236\n",
      "l1 weight: 0.14797501266002655\n",
      "avg viol: 1.7812699253467144, max viol: 1.800028005382046 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27762866020202637, valid regret : -0.2781204879283905 \n",
      "---------------------------------------iteration: 1561\n",
      "l1 decision: 0.08884014189243317\n",
      "l1 weight: 0.1494484543800354\n",
      "avg viol: 1.7753680898819584, max viol: 1.7901494200341403 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28539714217185974, valid regret : -0.2850462794303894 \n",
      "---------------------------------------iteration: 1562\n",
      "l1 decision: 0.09031356126070023\n",
      "l1 weight: 0.1504717469215393\n",
      "avg viol: 1.7815601075836458, max viol: 1.7977041811682284 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28162717819213867, valid regret : -0.2733462452888489 \n",
      "---------------------------------------iteration: 1563\n",
      "l1 decision: 0.08830927312374115\n",
      "l1 weight: 0.150429368019104\n",
      "avg viol: 1.766460312657291, max viol: 1.7854709124658257 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26568853855133057, valid regret : -0.28205424547195435 \n",
      "---------------------------------------iteration: 1564\n",
      "l1 decision: 0.09002819657325745\n",
      "l1 weight: 0.14935828745365143\n",
      "avg viol: 1.787035988406278, max viol: 1.803655326133594 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2903779149055481, valid regret : -0.2859436273574829 \n",
      "---------------------------------------iteration: 1565\n",
      "l1 decision: 0.08912727981805801\n",
      "l1 weight: 0.14834946393966675\n",
      "avg viol: 1.7794900347590739, max viol: 1.7988986640993971 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2805165946483612, valid regret : -0.27685317397117615 \n",
      "---------------------------------------iteration: 1566\n",
      "l1 decision: 0.09016640484333038\n",
      "l1 weight: 0.14959663152694702\n",
      "avg viol: 1.7820314732787665, max viol: 1.796866310061887 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28875407576560974, valid regret : -0.2744012773036957 \n",
      "---------------------------------------iteration: 1567\n",
      "l1 decision: 0.08783028274774551\n",
      "l1 weight: 0.14810138940811157\n",
      "avg viol: 1.7574472955823877, max viol: 1.7787834526970983 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28525879979133606, valid regret : -0.28629612922668457 \n",
      "---------------------------------------iteration: 1568\n",
      "l1 decision: 0.09032769501209259\n",
      "l1 weight: 0.1466698944568634\n",
      "avg viol: 1.7866328236379194, max viol: 1.802055709529668 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28151652216911316, valid regret : -0.2775231599807739 \n",
      "---------------------------------------iteration: 1569\n",
      "l1 decision: 0.08894827216863632\n",
      "l1 weight: 0.14829537272453308\n",
      "avg viol: 1.77755482843575, max viol: 1.798556980502326 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27462488412857056, valid regret : -0.279118150472641 \n",
      "---------------------------------------iteration: 1570\n",
      "l1 decision: 0.0905015766620636\n",
      "l1 weight: 0.14952825009822845\n",
      "avg viol: 1.7797695506195306, max viol: 1.7950469455681741 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2856278121471405, valid regret : -0.2750024199485779 \n",
      "---------------------------------------iteration: 1571\n",
      "l1 decision: 0.08772128075361252\n",
      "l1 weight: 0.1485840380191803\n",
      "avg viol: 1.7536181987158488, max viol: 1.7699830268975347 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2754055857658386, valid regret : -0.27456116676330566 \n",
      "---------------------------------------iteration: 1572\n",
      "l1 decision: 0.08939846605062485\n",
      "l1 weight: 0.14854475855827332\n",
      "avg viol: 1.772859890567488, max viol: 1.7908320757560432 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2750454246997833, valid regret : -0.27787071466445923 \n",
      "---------------------------------------iteration: 1573\n",
      "l1 decision: 0.08854056149721146\n",
      "l1 weight: 0.14908921718597412\n",
      "avg viol: 1.7693417067590054, max viol: 1.7855831135530025 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28371667861938477, valid regret : -0.2864544987678528 \n",
      "---------------------------------------iteration: 1574\n",
      "l1 decision: 0.09022404253482819\n",
      "l1 weight: 0.15061794221401215\n",
      "avg viol: 1.7887053668429145, max viol: 1.801516946288757 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2836836874485016, valid regret : -0.27875128388404846 \n",
      "---------------------------------------iteration: 1575\n",
      "l1 decision: 0.0893511027097702\n",
      "l1 weight: 0.1512228399515152\n",
      "avg viol: 1.7846238678151531, max viol: 1.8032219064771198 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27089837193489075, valid regret : -0.2817821204662323 \n",
      "---------------------------------------iteration: 1576\n",
      "l1 decision: 0.08968843519687653\n",
      "l1 weight: 0.14945510029792786\n",
      "avg viol: 1.7835793257901968, max viol: 1.8030520051252097 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2905691862106323, valid regret : -0.2821010649204254 \n",
      "---------------------------------------iteration: 1577\n",
      "l1 decision: 0.0886451005935669\n",
      "l1 weight: 0.1482056975364685\n",
      "avg viol: 1.7690885073551907, max viol: 1.7837350340560079 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2771323323249817, valid regret : -0.27606362104415894 \n",
      "---------------------------------------iteration: 1578\n",
      "l1 decision: 0.08948786556720734\n",
      "l1 weight: 0.15021218359470367\n",
      "avg viol: 1.7756065211922396, max viol: 1.7926182546652853 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28655871748924255, valid regret : -0.27090707421302795 \n",
      "---------------------------------------iteration: 1579\n",
      "l1 decision: 0.08756225556135178\n",
      "l1 weight: 0.14775186777114868\n",
      "avg viol: 1.7493580359773477, max viol: 1.7676783157512546 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2809997498989105, valid regret : -0.28601282835006714 \n",
      "---------------------------------------iteration: 1580\n",
      "l1 decision: 0.08938150852918625\n",
      "l1 weight: 0.147710382938385\n",
      "avg viol: 1.7787446717353306, max viol: 1.799521129927598 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27882739901542664, valid regret : -0.27824801206588745 \n",
      "---------------------------------------iteration: 1581\n",
      "l1 decision: 0.0890653058886528\n",
      "l1 weight: 0.14827284216880798\n",
      "avg viol: 1.7791492685663979, max viol: 1.7987833784427494 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2739018499851227, valid regret : -0.28163421154022217 \n",
      "---------------------------------------iteration: 1582\n",
      "l1 decision: 0.09047114849090576\n",
      "l1 weight: 0.1488540917634964\n",
      "avg viol: 1.7878907673928188, max viol: 1.8014683171641082 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2885686159133911, valid regret : -0.27793216705322266 \n",
      "---------------------------------------iteration: 1583\n",
      "l1 decision: 0.08776871860027313\n",
      "l1 weight: 0.14857929944992065\n",
      "avg viol: 1.7559132886840962, max viol: 1.7745357850799337 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27795228362083435, valid regret : -0.2760109603404999 \n",
      "---------------------------------------iteration: 1584\n",
      "l1 decision: 0.08979000896215439\n",
      "l1 weight: 0.14797426760196686\n",
      "avg viol: 1.778560453580576, max viol: 1.7972296279622242 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27675843238830566, valid regret : -0.2753799259662628 \n",
      "---------------------------------------iteration: 1585\n",
      "l1 decision: 0.08793862164020538\n",
      "l1 weight: 0.1490926593542099\n",
      "avg viol: 1.7593490185186966, max viol: 1.7786327812355012 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2806081473827362, valid regret : -0.28334513306617737 \n",
      "---------------------------------------iteration: 1586\n",
      "l1 decision: 0.0899091362953186\n",
      "l1 weight: 0.15083065629005432\n",
      "avg viol: 1.781390162158059, max viol: 1.795512696262449 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.281188428401947, valid regret : -0.27334511280059814 \n",
      "---------------------------------------iteration: 1587\n",
      "l1 decision: 0.08844372630119324\n",
      "l1 weight: 0.1510440856218338\n",
      "avg viol: 1.7695410454267404, max viol: 1.786428571678698 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.267085462808609, valid regret : -0.28078266978263855 \n",
      "---------------------------------------iteration: 1588\n",
      "l1 decision: 0.08993436396121979\n",
      "l1 weight: 0.14991939067840576\n",
      "avg viol: 1.782637637455482, max viol: 1.8025411050766706 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2889114320278168, valid regret : -0.2837265133857727 \n",
      "---------------------------------------iteration: 1589\n",
      "l1 decision: 0.08871864527463913\n",
      "l1 weight: 0.14909924566745758\n",
      "avg viol: 1.7741331897251076, max viol: 1.7956043718440924 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.279428094625473, valid regret : -0.2778467833995819 \n",
      "---------------------------------------iteration: 1590\n",
      "l1 decision: 0.09017395973205566\n",
      "l1 weight: 0.15006916224956512\n",
      "avg viol: 1.783857931935927, max viol: 1.8015903278719634 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2884407043457031, valid regret : -0.2763141095638275 \n",
      "---------------------------------------iteration: 1591\n",
      "l1 decision: 0.08820922672748566\n",
      "l1 weight: 0.1475684642791748\n",
      "avg viol: 1.7634107412263984, max viol: 1.7822813522070646 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28723421692848206, valid regret : -0.2843039631843567 \n",
      "---------------------------------------iteration: 1592\n",
      "l1 decision: 0.09007108211517334\n",
      "l1 weight: 0.14721845090389252\n",
      "avg viol: 1.783714142831741, max viol: 1.8019906056579202 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28036653995513916, valid regret : -0.2757275700569153 \n",
      "---------------------------------------iteration: 1593\n",
      "l1 decision: 0.08855132758617401\n",
      "l1 weight: 0.14787912368774414\n",
      "avg viol: 1.7697182776370028, max viol: 1.7936915324244183 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2721381187438965, valid regret : -0.27998074889183044 \n",
      "---------------------------------------iteration: 1594\n",
      "l1 decision: 0.09052858501672745\n",
      "l1 weight: 0.1487523317337036\n",
      "avg viol: 1.7806131400488083, max viol: 1.7968908252660185 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2854708731174469, valid regret : -0.2751631438732147 \n",
      "---------------------------------------iteration: 1595\n",
      "l1 decision: 0.0876542180776596\n",
      "l1 weight: 0.14841212332248688\n",
      "avg viol: 1.7533352686971193, max viol: 1.7689930085325614 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27528154850006104, valid regret : -0.2736579477787018 \n",
      "---------------------------------------iteration: 1596\n",
      "l1 decision: 0.0891517922282219\n",
      "l1 weight: 0.14862972497940063\n",
      "avg viol: 1.7775618136668345, max viol: 1.7958083937410265 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2767375707626343, valid regret : -0.27911847829818726 \n",
      "---------------------------------------iteration: 1597\n",
      "l1 decision: 0.08929293602705002\n",
      "l1 weight: 0.14897605776786804\n",
      "avg viol: 1.7808927635969303, max viol: 1.7941173263825476 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28592780232429504, valid regret : -0.28595197200775146 \n",
      "---------------------------------------iteration: 1598\n",
      "l1 decision: 0.09039074927568436\n",
      "l1 weight: 0.15044549107551575\n",
      "avg viol: 1.7882457494083792, max viol: 1.8011967074126005 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28347092866897583, valid regret : -0.2715327739715576 \n",
      "---------------------------------------iteration: 1599\n",
      "l1 decision: 0.088498055934906\n",
      "l1 weight: 0.15098422765731812\n",
      "avg viol: 1.7690652191929985, max viol: 1.7841989954467863 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26525750756263733, valid regret : -0.28001633286476135 \n",
      "---------------------------------------iteration: 1600\n",
      "l1 decision: 0.0896708145737648\n",
      "l1 weight: 0.14890076220035553\n",
      "avg viol: 1.7800608393753645, max viol: 1.7991788380313665 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28769367933273315, valid regret : -0.2835007309913635 \n",
      "---------------------------------------iteration: 1601\n",
      "l1 decision: 0.0884804055094719\n",
      "l1 weight: 0.14833804965019226\n",
      "avg viol: 1.768393822176149, max viol: 1.789770025992766 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.277233362197876, valid regret : -0.2758077383041382 \n",
      "---------------------------------------iteration: 1602\n",
      "l1 decision: 0.08993855118751526\n",
      "l1 weight: 0.1494635045528412\n",
      "avg viol: 1.783235101363971, max viol: 1.7985584780108184 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2889505922794342, valid regret : -0.27644485235214233 \n",
      "---------------------------------------iteration: 1603\n",
      "l1 decision: 0.08845982700586319\n",
      "l1 weight: 0.14714758098125458\n",
      "avg viol: 1.768714348815265, max viol: 1.7851537386886775 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2894658148288727, valid regret : -0.2851589620113373 \n",
      "---------------------------------------iteration: 1604\n",
      "l1 decision: 0.09021361172199249\n",
      "l1 weight: 0.14817164838314056\n",
      "avg viol: 1.7803975753445411, max viol: 1.800986239220947 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2796848714351654, valid regret : -0.2728537619113922 \n",
      "---------------------------------------iteration: 1605\n",
      "l1 decision: 0.08856306225061417\n",
      "l1 weight: 0.14742237329483032\n",
      "avg viol: 1.7706678626849317, max viol: 1.7867792788892984 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2714330554008484, valid regret : -0.2806340456008911 \n",
      "---------------------------------------iteration: 1606\n",
      "l1 decision: 0.0903661698102951\n",
      "l1 weight: 0.1487712413072586\n",
      "avg viol: 1.7806527593755164, max viol: 1.801870875991881 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2849454879760742, valid regret : -0.2808781564235687 \n",
      "---------------------------------------iteration: 1607\n",
      "l1 decision: 0.08812808245420456\n",
      "l1 weight: 0.14916564524173737\n",
      "avg viol: 1.7625464052763709, max viol: 1.7802861323580146 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.280417263507843, valid regret : -0.27521610260009766 \n",
      "---------------------------------------iteration: 1608\n",
      "l1 decision: 0.0898372009396553\n",
      "l1 weight: 0.1483856439590454\n",
      "avg viol: 1.7805351914279164, max viol: 1.7997906066011637 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27754417061805725, valid regret : -0.27712076902389526 \n",
      "---------------------------------------iteration: 1609\n",
      "l1 decision: 0.08865871280431747\n",
      "l1 weight: 0.1491701900959015\n",
      "avg viol: 1.7732383315754123, max viol: 1.7888205058407038 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2844389081001282, valid regret : -0.28508350253105164 \n",
      "---------------------------------------iteration: 1610\n",
      "l1 decision: 0.09012924134731293\n",
      "l1 weight: 0.15074403584003448\n",
      "avg viol: 1.7815989080897998, max viol: 1.798308617901057 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2814674377441406, valid regret : -0.2720998525619507 \n",
      "---------------------------------------iteration: 1611\n",
      "l1 decision: 0.08823632448911667\n",
      "l1 weight: 0.15121610462665558\n",
      "avg viol: 1.765177452591597, max viol: 1.7869129743194208 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2651861310005188, valid regret : -0.2800664007663727 \n",
      "---------------------------------------iteration: 1612\n",
      "l1 decision: 0.08984870463609695\n",
      "l1 weight: 0.14950810372829437\n",
      "avg viol: 1.78639231481764, max viol: 1.8046326270559803 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28961679339408875, valid regret : -0.2868964672088623 \n",
      "---------------------------------------iteration: 1613\n",
      "l1 decision: 0.08931439369916916\n",
      "l1 weight: 0.14829367399215698\n",
      "avg viol: 1.782590574446367, max viol: 1.8009932028362527 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2812581956386566, valid regret : -0.27656084299087524 \n",
      "---------------------------------------iteration: 1614\n",
      "l1 decision: 0.09000533819198608\n",
      "l1 weight: 0.149494931101799\n",
      "avg viol: 1.7848875339890946, max viol: 1.7998891727766022 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2902942895889282, valid regret : -0.27440863847732544 \n",
      "---------------------------------------iteration: 1615\n",
      "l1 decision: 0.08863683044910431\n",
      "l1 weight: 0.14778384566307068\n",
      "avg viol: 1.7688917620608118, max viol: 1.7818333124741912 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28861063718795776, valid regret : -0.2841515839099884 \n",
      "---------------------------------------iteration: 1616\n",
      "l1 decision: 0.08982862532138824\n",
      "l1 weight: 0.14802828431129456\n",
      "avg viol: 1.7736443280766252, max viol: 1.7925869522150606 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2780790627002716, valid regret : -0.2664673626422882 \n",
      "---------------------------------------iteration: 1617\n",
      "l1 decision: 0.08766358345746994\n",
      "l1 weight: 0.14747875928878784\n",
      "avg viol: 1.7511205772438552, max viol: 1.7693093726411462 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2628098726272583, valid regret : -0.2806682884693146 \n",
      "---------------------------------------iteration: 1618\n",
      "l1 decision: 0.08896379917860031\n",
      "l1 weight: 0.14918392896652222\n",
      "avg viol: 1.7754527524649166, max viol: 1.7987897912971675 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2839409112930298, valid regret : -0.2874211370944977 \n",
      "---------------------------------------iteration: 1619\n",
      "l1 decision: 0.0899810791015625\n",
      "l1 weight: 0.14873570203781128\n",
      "avg viol: 1.7885100328823136, max viol: 1.8033092797850259 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2877691388130188, valid regret : -0.27844372391700745 \n",
      "---------------------------------------iteration: 1620\n",
      "l1 decision: 0.0899251401424408\n",
      "l1 weight: 0.14813220500946045\n",
      "avg viol: 1.785781283499673, max viol: 1.8020911015337333 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.280048668384552, valid regret : -0.2739783227443695 \n",
      "---------------------------------------iteration: 1621\n",
      "l1 decision: 0.08802138268947601\n",
      "l1 weight: 0.149389386177063\n",
      "avg viol: 1.7608533631294268, max viol: 1.7778220077743754 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28007352352142334, valid regret : -0.2835935056209564 \n",
      "---------------------------------------iteration: 1622\n",
      "l1 decision: 0.09040367603302002\n",
      "l1 weight: 0.15066556632518768\n",
      "avg viol: 1.7784587604831905, max viol: 1.7943110243650153 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2797401547431946, valid regret : -0.26743385195732117 \n",
      "---------------------------------------iteration: 1623\n",
      "l1 decision: 0.08786392956972122\n",
      "l1 weight: 0.1506595015525818\n",
      "avg viol: 1.7559628623415484, max viol: 1.7666690087644383 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2601577043533325, valid regret : -0.27932026982307434 \n",
      "---------------------------------------iteration: 1624\n",
      "l1 decision: 0.08879595249891281\n",
      "l1 weight: 0.14939647912979126\n",
      "avg viol: 1.772063165305881, max viol: 1.7923834193497896 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2844017744064331, valid regret : -0.282530277967453 \n",
      "---------------------------------------iteration: 1625\n",
      "l1 decision: 0.08895261585712433\n",
      "l1 weight: 0.14795376360416412\n",
      "avg viol: 1.7721306501538492, max viol: 1.7885089596966282 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27732688188552856, valid regret : -0.2764650881290436 \n",
      "---------------------------------------iteration: 1626\n",
      "l1 decision: 0.08929479867219925\n",
      "l1 weight: 0.14915934205055237\n",
      "avg viol: 1.7791569180064835, max viol: 1.7957721911370754 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2878369987010956, valid regret : -0.27671438455581665 \n",
      "---------------------------------------iteration: 1627\n",
      "l1 decision: 0.08851098269224167\n",
      "l1 weight: 0.1470220983028412\n",
      "avg viol: 1.7705443383287638, max viol: 1.7879153470275924 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2891595959663391, valid regret : -0.2858686149120331 \n",
      "---------------------------------------iteration: 1628\n",
      "l1 decision: 0.09045746177434921\n",
      "l1 weight: 0.14697660505771637\n",
      "avg viol: 1.7831869164295495, max viol: 1.8011009615147486 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28081557154655457, valid regret : -0.2738282084465027 \n",
      "---------------------------------------iteration: 1629\n",
      "l1 decision: 0.08829706907272339\n",
      "l1 weight: 0.14756585657596588\n",
      "avg viol: 1.765461375534069, max viol: 1.7861348842270672 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2704105079174042, valid regret : -0.28171706199645996 \n",
      "---------------------------------------iteration: 1630\n",
      "l1 decision: 0.09045969694852829\n",
      "l1 weight: 0.14867913722991943\n",
      "avg viol: 1.7870696789975045, max viol: 1.8015996376052499 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2874818742275238, valid regret : -0.28273776173591614 \n",
      "---------------------------------------iteration: 1631\n",
      "l1 decision: 0.08834818750619888\n",
      "l1 weight: 0.14816564321517944\n",
      "avg viol: 1.7660597700381186, max viol: 1.7868235770147294 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.281203955411911, valid regret : -0.2772422730922699 \n",
      "---------------------------------------iteration: 1632\n",
      "l1 decision: 0.08969953656196594\n",
      "l1 weight: 0.14882872998714447\n",
      "avg viol: 1.77963967216725, max viol: 1.8024511693511158 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27770814299583435, valid regret : -0.28099650144577026 \n",
      "---------------------------------------iteration: 1633\n",
      "l1 decision: 0.0892648920416832\n",
      "l1 weight: 0.1488511711359024\n",
      "avg viol: 1.782650168691107, max viol: 1.800412525772117 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28761062026023865, valid regret : -0.28655895590782166 \n",
      "---------------------------------------iteration: 1634\n",
      "l1 decision: 0.09065073728561401\n",
      "l1 weight: 0.150844007730484\n",
      "avg viol: 1.7880354332679418, max viol: 1.8014603364281356 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2836841940879822, valid regret : -0.27109482884407043 \n",
      "---------------------------------------iteration: 1635\n",
      "l1 decision: 0.08813919872045517\n",
      "l1 weight: 0.15161770582199097\n",
      "avg viol: 1.762415450041881, max viol: 1.777072326745838 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26353251934051514, valid regret : -0.2817705273628235 \n",
      "---------------------------------------iteration: 1636\n",
      "l1 decision: 0.09004264324903488\n",
      "l1 weight: 0.14927931129932404\n",
      "avg viol: 1.7865732206171379, max viol: 1.8047579381382093 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2892572283744812, valid regret : -0.28626179695129395 \n",
      "---------------------------------------iteration: 1637\n",
      "l1 decision: 0.08925450593233109\n",
      "l1 weight: 0.14795337617397308\n",
      "avg viol: 1.7827374884943674, max viol: 1.7996673219604418 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28162869811058044, valid regret : -0.2771454155445099 \n",
      "---------------------------------------iteration: 1638\n",
      "l1 decision: 0.09045501053333282\n",
      "l1 weight: 0.14927880465984344\n",
      "avg viol: 1.7880671738728415, max viol: 1.8008439074037597 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29070109128952026, valid regret : -0.27520450949668884 \n",
      "---------------------------------------iteration: 1639\n",
      "l1 decision: 0.08821815997362137\n",
      "l1 weight: 0.14762833714485168\n",
      "avg viol: 1.7638743486360182, max viol: 1.7780408755643293 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28691592812538147, valid regret : -0.28713852167129517 \n",
      "---------------------------------------iteration: 1640\n",
      "l1 decision: 0.09019692242145538\n",
      "l1 weight: 0.14761947095394135\n",
      "avg viol: 1.7874519957887243, max viol: 1.8034035348100588 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2814588248729706, valid regret : -0.2758645713329315 \n",
      "---------------------------------------iteration: 1641\n",
      "l1 decision: 0.08871467411518097\n",
      "l1 weight: 0.14784018695354462\n",
      "avg viol: 1.7735880136006745, max viol: 1.7914839941076934 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2727326452732086, valid regret : -0.2808590531349182 \n",
      "---------------------------------------iteration: 1642\n",
      "l1 decision: 0.09013843536376953\n",
      "l1 weight: 0.14850230515003204\n",
      "avg viol: 1.7785941687750164, max viol: 1.7983243048656732 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.284330815076828, valid regret : -0.2783448398113251 \n",
      "---------------------------------------iteration: 1643\n",
      "l1 decision: 0.08776375651359558\n",
      "l1 weight: 0.14859189093112946\n",
      "avg viol: 1.7563141372066458, max viol: 1.7734800004400313 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27781954407691956, valid regret : -0.277019739151001 \n",
      "---------------------------------------iteration: 1644\n",
      "l1 decision: 0.08973697572946548\n",
      "l1 weight: 0.14801473915576935\n",
      "avg viol: 1.7844241944496753, max viol: 1.802285886136815 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27895933389663696, valid regret : -0.2813447117805481 \n",
      "---------------------------------------iteration: 1645\n",
      "l1 decision: 0.08947304636240005\n",
      "l1 weight: 0.14902642369270325\n",
      "avg viol: 1.7854599082909408, max viol: 1.8032239149324596 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28782278299331665, valid regret : -0.2881311774253845 \n",
      "---------------------------------------iteration: 1646\n",
      "l1 decision: 0.09032057970762253\n",
      "l1 weight: 0.1508551687002182\n",
      "avg viol: 1.791193508014403, max viol: 1.802751197712496 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2850777506828308, valid regret : -0.2746342420578003 \n",
      "---------------------------------------iteration: 1647\n",
      "l1 decision: 0.0888781026005745\n",
      "l1 weight: 0.1510399729013443\n",
      "avg viol: 1.7721876844367943, max viol: 1.7876818163786083 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26699158549308777, valid regret : -0.27994996309280396 \n",
      "---------------------------------------iteration: 1648\n",
      "l1 decision: 0.08968453854322433\n",
      "l1 weight: 0.14896152913570404\n",
      "avg viol: 1.777326354504912, max viol: 1.7931612000102177 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2882179915904999, valid regret : -0.2783505618572235 \n",
      "---------------------------------------iteration: 1649\n",
      "l1 decision: 0.08803310990333557\n",
      "l1 weight: 0.14817221462726593\n",
      "avg viol: 1.7560079502523878, max viol: 1.7755230085458606 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2727898359298706, valid regret : -0.27624091506004333 \n",
      "---------------------------------------iteration: 1650\n",
      "l1 decision: 0.0895339697599411\n",
      "l1 weight: 0.14972829818725586\n",
      "avg viol: 1.780215551656438, max viol: 1.7974446545122191 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2883869409561157, valid regret : -0.2779741585254669 \n",
      "---------------------------------------iteration: 1651\n",
      "l1 decision: 0.08916473388671875\n",
      "l1 weight: 0.14788773655891418\n",
      "avg viol: 1.7744160817249213, max viol: 1.7901829069014639 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2894911766052246, valid regret : -0.2847062945365906 \n",
      "---------------------------------------iteration: 1652\n",
      "l1 decision: 0.08947335928678513\n",
      "l1 weight: 0.14828303456306458\n",
      "avg viol: 1.7757029279251584, max viol: 1.7968429075554013 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2790009677410126, valid regret : -0.27222833037376404 \n",
      "---------------------------------------iteration: 1653\n",
      "l1 decision: 0.08821219205856323\n",
      "l1 weight: 0.14718356728553772\n",
      "avg viol: 1.762315164183965, max viol: 1.7834906997159123 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26838183403015137, valid regret : -0.2804577350616455 \n",
      "---------------------------------------iteration: 1654\n",
      "l1 decision: 0.09047912806272507\n",
      "l1 weight: 0.1480032056570053\n",
      "avg viol: 1.7844195246195886, max viol: 1.7973829635884613 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28605183959007263, valid regret : -0.27995479106903076 \n",
      "---------------------------------------iteration: 1655\n",
      "l1 decision: 0.08807909488677979\n",
      "l1 weight: 0.1487598419189453\n",
      "avg viol: 1.7624454433686332, max viol: 1.7800862087169662 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2792210280895233, valid regret : -0.2770892381668091 \n",
      "---------------------------------------iteration: 1656\n",
      "l1 decision: 0.08976980298757553\n",
      "l1 weight: 0.14836537837982178\n",
      "avg viol: 1.7846079284517327, max viol: 1.8034691989887506 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27850931882858276, valid regret : -0.2801121771335602 \n",
      "---------------------------------------iteration: 1657\n",
      "l1 decision: 0.08899185061454773\n",
      "l1 weight: 0.1492529660463333\n",
      "avg viol: 1.7784178265806987, max viol: 1.7932911973912269 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28584393858909607, valid regret : -0.2863384783267975 \n",
      "---------------------------------------iteration: 1658\n",
      "l1 decision: 0.0901610404253006\n",
      "l1 weight: 0.15109851956367493\n",
      "avg viol: 1.7849207683536223, max viol: 1.8011297048069537 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2829986810684204, valid regret : -0.27221494913101196 \n",
      "---------------------------------------iteration: 1659\n",
      "l1 decision: 0.0884007066488266\n",
      "l1 weight: 0.15164931118488312\n",
      "avg viol: 1.7678444975346792, max viol: 1.7842262528138235 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26540520787239075, valid regret : -0.2823306918144226 \n",
      "---------------------------------------iteration: 1660\n",
      "l1 decision: 0.09020006656646729\n",
      "l1 weight: 0.1488175392150879\n",
      "avg viol: 1.7911190144967986, max viol: 1.8053890515584499 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2910618185997009, valid regret : -0.28682059049606323 \n",
      "---------------------------------------iteration: 1661\n",
      "l1 decision: 0.08882789313793182\n",
      "l1 weight: 0.1489110141992569\n",
      "avg viol: 1.7746277537171773, max viol: 1.7998329672846012 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2790849208831787, valid regret : -0.2761845588684082 \n",
      "---------------------------------------iteration: 1662\n",
      "l1 decision: 0.0902799442410469\n",
      "l1 weight: 0.14978359639644623\n",
      "avg viol: 1.786016586635378, max viol: 1.8016116758808494 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28949475288391113, valid regret : -0.2735610604286194 \n",
      "---------------------------------------iteration: 1663\n",
      "l1 decision: 0.08791621774435043\n",
      "l1 weight: 0.1482178121805191\n",
      "avg viol: 1.7576996959722602, max viol: 1.7789343786425889 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2851814329624176, valid regret : -0.284913033246994 \n",
      "---------------------------------------iteration: 1664\n",
      "l1 decision: 0.0897156149148941\n",
      "l1 weight: 0.14816318452358246\n",
      "avg viol: 1.779728196238866, max viol: 1.8002135703573003 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2793283462524414, valid regret : -0.27496621012687683 \n",
      "---------------------------------------iteration: 1665\n",
      "l1 decision: 0.08875276893377304\n",
      "l1 weight: 0.1482343077659607\n",
      "avg viol: 1.7746198376989923, max viol: 1.7940573948726524 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2730233073234558, valid regret : -0.2801404297351837 \n",
      "---------------------------------------iteration: 1666\n",
      "l1 decision: 0.0898723155260086\n",
      "l1 weight: 0.14889021217823029\n",
      "avg viol: 1.7750766676862257, max viol: 1.7992631439119577 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2830702066421509, valid regret : -0.27824100852012634 \n",
      "---------------------------------------iteration: 1667\n",
      "l1 decision: 0.08771788328886032\n",
      "l1 weight: 0.14874351024627686\n",
      "avg viol: 1.7557169758644886, max viol: 1.7746661303099245 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27733004093170166, valid regret : -0.2758021652698517 \n",
      "---------------------------------------iteration: 1668\n",
      "l1 decision: 0.08954015374183655\n",
      "l1 weight: 0.14895452558994293\n",
      "avg viol: 1.7842292581591754, max viol: 1.8028212777571753 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27879321575164795, valid regret : -0.28001508116722107 \n",
      "---------------------------------------iteration: 1669\n",
      "l1 decision: 0.08931411057710648\n",
      "l1 weight: 0.14941167831420898\n",
      "avg viol: 1.783231555470993, max viol: 1.803707817918621 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2872667908668518, valid regret : -0.287102073431015 \n",
      "---------------------------------------iteration: 1670\n",
      "l1 decision: 0.09011169523000717\n",
      "l1 weight: 0.15155908465385437\n",
      "avg viol: 1.7877694128490111, max viol: 1.8032078586984426 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2836662530899048, valid regret : -0.2749856412410736 \n",
      "---------------------------------------iteration: 1671\n",
      "l1 decision: 0.08898790180683136\n",
      "l1 weight: 0.15177153050899506\n",
      "avg viol: 1.772954337720348, max viol: 1.7914819398429245 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2672223746776581, valid regret : -0.2799893319606781 \n",
      "---------------------------------------iteration: 1672\n",
      "l1 decision: 0.08999001234769821\n",
      "l1 weight: 0.1484985202550888\n",
      "avg viol: 1.7798298286425416, max viol: 1.7953830361366272 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28891050815582275, valid regret : -0.2729549705982208 \n",
      "---------------------------------------iteration: 1673\n",
      "l1 decision: 0.08783257752656937\n",
      "l1 weight: 0.14774450659751892\n",
      "avg viol: 1.7436258311290294, max viol: 1.759284696658142 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2669483423233032, valid regret : -0.27516594529151917 \n",
      "---------------------------------------iteration: 1674\n",
      "l1 decision: 0.08887304365634918\n",
      "l1 weight: 0.14954695105552673\n",
      "avg viol: 1.776964064798376, max viol: 1.794409218011424 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28785350918769836, valid regret : -0.2819114327430725 \n",
      "---------------------------------------iteration: 1675\n",
      "l1 decision: 0.09121125191450119\n",
      "l1 weight: 0.14755848050117493\n",
      "avg viol: 1.7890046730590985, max viol: 1.799723674193956 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29338130354881287, valid regret : -0.2824738323688507 \n",
      "---------------------------------------iteration: 1676\n",
      "l1 decision: 0.0883035957813263\n",
      "l1 weight: 0.14775729179382324\n",
      "avg viol: 1.7646620588518271, max viol: 1.78545148804551 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2778109908103943, valid regret : -0.2746085822582245 \n",
      "---------------------------------------iteration: 1677\n",
      "l1 decision: 0.09068474173545837\n",
      "l1 weight: 0.14806538820266724\n",
      "avg viol: 1.7784468412830028, max viol: 1.795251684379764 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27132323384284973, valid regret : -0.2742875814437866 \n",
      "---------------------------------------iteration: 1678\n",
      "l1 decision: 0.08798863738775253\n",
      "l1 weight: 0.14833636581897736\n",
      "avg viol: 1.7591345743706917, max viol: 1.7777669528732076 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2797282338142395, valid regret : -0.28679776191711426 \n",
      "---------------------------------------iteration: 1679\n",
      "l1 decision: 0.08977007865905762\n",
      "l1 weight: 0.14936314523220062\n",
      "avg viol: 1.7854559741690172, max viol: 1.8040482996730134 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28618648648262024, valid regret : -0.27826568484306335 \n",
      "---------------------------------------iteration: 1680\n",
      "l1 decision: 0.08899544924497604\n",
      "l1 weight: 0.14813897013664246\n",
      "avg viol: 1.775615275492146, max viol: 1.8011421124683693 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27714747190475464, valid regret : -0.2823326885700226 \n",
      "---------------------------------------iteration: 1681\n",
      "l1 decision: 0.09027789533138275\n",
      "l1 weight: 0.14913545548915863\n",
      "avg viol: 1.7886673565208913, max viol: 1.8016716800630093 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2881338596343994, valid regret : -0.28017884492874146 \n",
      "---------------------------------------iteration: 1682\n",
      "l1 decision: 0.08827293664216995\n",
      "l1 weight: 0.15076477825641632\n",
      "avg viol: 1.7652730317006353, max viol: 1.7813272475032136 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2773782014846802, valid regret : -0.277454137802124 \n",
      "---------------------------------------iteration: 1683\n",
      "l1 decision: 0.0900135263800621\n",
      "l1 weight: 0.15168438851833344\n",
      "avg viol: 1.7858043002628257, max viol: 1.8031898837070912 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2695808410644531, valid regret : -0.2785513699054718 \n",
      "---------------------------------------iteration: 1684\n",
      "l1 decision: 0.0886387750506401\n",
      "l1 weight: 0.14836043119430542\n",
      "avg viol: 1.7723791337799049, max viol: 1.789359407266602 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2869298756122589, valid regret : -0.2836619019508362 \n",
      "---------------------------------------iteration: 1685\n",
      "l1 decision: 0.09000492095947266\n",
      "l1 weight: 0.14858423173427582\n",
      "avg viol: 1.7762536594184348, max viol: 1.7940570167265832 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2789562940597534, valid regret : -0.2712021470069885 \n",
      "---------------------------------------iteration: 1686\n",
      "l1 decision: 0.08800461888313293\n",
      "l1 weight: 0.14955104887485504\n",
      "avg viol: 1.7604027721961029, max viol: 1.7796088376780972 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2828707695007324, valid regret : -0.28218361735343933 \n",
      "---------------------------------------iteration: 1687\n",
      "l1 decision: 0.09028145670890808\n",
      "l1 weight: 0.14741401374340057\n",
      "avg viol: 1.790520801176317, max viol: 1.802361833746545 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2944086492061615, valid regret : -0.28576380014419556 \n",
      "---------------------------------------iteration: 1688\n",
      "l1 decision: 0.08893698453903198\n",
      "l1 weight: 0.14755010604858398\n",
      "avg viol: 1.7764589327752036, max viol: 1.7985462683718652 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28035593032836914, valid regret : -0.2780839800834656 \n",
      "---------------------------------------iteration: 1689\n",
      "l1 decision: 0.09035208821296692\n",
      "l1 weight: 0.14828743040561676\n",
      "avg viol: 1.786982928009529, max viol: 1.800732919946313 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2746976613998413, valid regret : -0.2764783501625061 \n",
      "---------------------------------------iteration: 1690\n",
      "l1 decision: 0.08819056302309036\n",
      "l1 weight: 0.14873963594436646\n",
      "avg viol: 1.761836969231008, max viol: 1.7818386463914067 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2813202142715454, valid regret : -0.28580817580223083 \n",
      "---------------------------------------iteration: 1691\n",
      "l1 decision: 0.09059982001781464\n",
      "l1 weight: 0.14910505712032318\n",
      "avg viol: 1.7829704235657118, max viol: 1.7987938628066331 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2855202257633209, valid regret : -0.27205342054367065 \n",
      "---------------------------------------iteration: 1692\n",
      "l1 decision: 0.08824864774942398\n",
      "l1 weight: 0.14826729893684387\n",
      "avg viol: 1.7631046995532234, max viol: 1.78023249481339 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27339017391204834, valid regret : -0.2812577188014984 \n",
      "---------------------------------------iteration: 1693\n",
      "l1 decision: 0.08981556445360184\n",
      "l1 weight: 0.14912906289100647\n",
      "avg viol: 1.7865238731063438, max viol: 1.799468778539449 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28698307275772095, valid regret : -0.28517788648605347 \n",
      "---------------------------------------iteration: 1694\n",
      "l1 decision: 0.08947360515594482\n",
      "l1 weight: 0.15109482407569885\n",
      "avg viol: 1.7780967145325848, max viol: 1.7936145327985287 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28109532594680786, valid regret : -0.2760397791862488 \n",
      "---------------------------------------iteration: 1695\n",
      "l1 decision: 0.09010493755340576\n",
      "l1 weight: 0.15116436779499054\n",
      "avg viol: 1.7818000919924817, max viol: 1.7957178597571328 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26883652806282043, valid regret : -0.2692331075668335 \n",
      "---------------------------------------iteration: 1696\n",
      "l1 decision: 0.08733764290809631\n",
      "l1 weight: 0.14820106327533722\n",
      "avg viol: 1.7478729138761993, max viol: 1.764054540079087 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2760051488876343, valid regret : -0.2852097749710083 \n",
      "---------------------------------------iteration: 1697\n",
      "l1 decision: 0.08963121473789215\n",
      "l1 weight: 0.1485331952571869\n",
      "avg viol: 1.780728025942808, max viol: 1.7962879077531397 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2800239026546478, valid regret : -0.27601566910743713 \n",
      "---------------------------------------iteration: 1698\n",
      "l1 decision: 0.08937182277441025\n",
      "l1 weight: 0.149253249168396\n",
      "avg viol: 1.7817366138163198, max viol: 1.7963477987796068 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28850823640823364, valid regret : -0.2796005308628082 \n",
      "---------------------------------------iteration: 1699\n",
      "l1 decision: 0.09045068174600601\n",
      "l1 weight: 0.14803950488567352\n",
      "avg viol: 1.7731719328358304, max viol: 1.7882247855886817 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2897219657897949, valid regret : -0.27389395236968994 \n",
      "---------------------------------------iteration: 1700\n",
      "l1 decision: 0.08741553872823715\n",
      "l1 weight: 0.1472150683403015\n",
      "avg viol: 1.7473624202853535, max viol: 1.765258739469573 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26871415972709656, valid regret : -0.27464720606803894 \n",
      "---------------------------------------iteration: 1701\n",
      "l1 decision: 0.08875121921300888\n",
      "l1 weight: 0.14789624512195587\n",
      "avg viol: 1.7740348267788066, max viol: 1.7942110350122675 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2714819312095642, valid regret : -0.28239554166793823 \n",
      "---------------------------------------iteration: 1702\n",
      "l1 decision: 0.08953618258237839\n",
      "l1 weight: 0.14916068315505981\n",
      "avg viol: 1.7842802436491365, max viol: 1.8036791996564716 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2867010533809662, valid regret : -0.28723374009132385 \n",
      "---------------------------------------iteration: 1703\n",
      "l1 decision: 0.0900559052824974\n",
      "l1 weight: 0.14885687828063965\n",
      "avg viol: 1.786553226558608, max viol: 1.802985992981121 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28725993633270264, valid regret : -0.27603888511657715 \n",
      "---------------------------------------iteration: 1704\n",
      "l1 decision: 0.08909612149000168\n",
      "l1 weight: 0.14811637997627258\n",
      "avg viol: 1.776069777625562, max viol: 1.7961313996929675 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2771683633327484, valid regret : -0.281899631023407 \n",
      "---------------------------------------iteration: 1705\n",
      "l1 decision: 0.08984304964542389\n",
      "l1 weight: 0.1489676684141159\n",
      "avg viol: 1.7859160039392008, max viol: 1.8010851992294192 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2872501611709595, valid regret : -0.2860388159751892 \n",
      "---------------------------------------iteration: 1706\n",
      "l1 decision: 0.08941084891557693\n",
      "l1 weight: 0.15117697417736053\n",
      "avg viol: 1.7800015553003687, max viol: 1.7970845252275467 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28182369470596313, valid regret : -0.27581849694252014 \n",
      "---------------------------------------iteration: 1707\n",
      "l1 decision: 0.0892845019698143\n",
      "l1 weight: 0.1514463573694229\n",
      "avg viol: 1.7793493374515674, max viol: 1.7971652917913161 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26861411333084106, valid regret : -0.2816751003265381 \n",
      "---------------------------------------iteration: 1708\n",
      "l1 decision: 0.08998965471982956\n",
      "l1 weight: 0.14816558361053467\n",
      "avg viol: 1.7937265882239444, max viol: 1.8053299805615097 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29214200377464294, valid regret : -0.2878207266330719 \n",
      "---------------------------------------iteration: 1709\n",
      "l1 decision: 0.08988439291715622\n",
      "l1 weight: 0.14843174815177917\n",
      "avg viol: 1.7889045205815273, max viol: 1.8020751317963004 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2834746241569519, valid regret : -0.2775558531284332 \n",
      "---------------------------------------iteration: 1710\n",
      "l1 decision: 0.08923204243183136\n",
      "l1 weight: 0.1504238247871399\n",
      "avg viol: 1.7794632245898538, max viol: 1.79974463081453 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2879005968570709, valid regret : -0.2811601459980011 \n",
      "---------------------------------------iteration: 1711\n",
      "l1 decision: 0.0902305319905281\n",
      "l1 weight: 0.14784839749336243\n",
      "avg viol: 1.7877174243994522, max viol: 1.799663653364405 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29366761445999146, valid regret : -0.28225669264793396 \n",
      "---------------------------------------iteration: 1712\n",
      "l1 decision: 0.08864270150661469\n",
      "l1 weight: 0.14693328738212585\n",
      "avg viol: 1.7664204438531306, max viol: 1.7835958899522666 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2765876054763794, valid regret : -0.2737328112125397 \n",
      "---------------------------------------iteration: 1713\n",
      "l1 decision: 0.08967968076467514\n",
      "l1 weight: 0.14861340820789337\n",
      "avg viol: 1.7702652822306846, max viol: 1.7894183919997886 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2710668444633484, valid regret : -0.2701421082019806 \n",
      "---------------------------------------iteration: 1714\n",
      "l1 decision: 0.08750790357589722\n",
      "l1 weight: 0.14799755811691284\n",
      "avg viol: 1.7507755606528372, max viol: 1.7675556859467179 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27632907032966614, valid regret : -0.28626057505607605 \n",
      "---------------------------------------iteration: 1715\n",
      "l1 decision: 0.08946488797664642\n",
      "l1 weight: 0.14877988398075104\n",
      "avg viol: 1.7843354791851016, max viol: 1.8013118812814355 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28642043471336365, valid regret : -0.2778542637825012 \n",
      "---------------------------------------iteration: 1716\n",
      "l1 decision: 0.08924710005521774\n",
      "l1 weight: 0.14794623851776123\n",
      "avg viol: 1.781367411175088, max viol: 1.801617884892039 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2791118323802948, valid regret : -0.28190281987190247 \n",
      "---------------------------------------iteration: 1717\n",
      "l1 decision: 0.08983706682920456\n",
      "l1 weight: 0.15030059218406677\n",
      "avg viol: 1.783547260579071, max viol: 1.8037080538924783 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28676047921180725, valid regret : -0.2820383310317993 \n",
      "---------------------------------------iteration: 1718\n",
      "l1 decision: 0.08841504156589508\n",
      "l1 weight: 0.15054233372211456\n",
      "avg viol: 1.767330505634891, max viol: 1.7837176030734554 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27897900342941284, valid regret : -0.27528971433639526 \n",
      "---------------------------------------iteration: 1719\n",
      "l1 decision: 0.09040972590446472\n",
      "l1 weight: 0.15150319039821625\n",
      "avg viol: 1.779050262416713, max viol: 1.7973203375004232 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2672104239463806, valid regret : -0.2760712802410126 \n",
      "---------------------------------------iteration: 1720\n",
      "l1 decision: 0.08815307915210724\n",
      "l1 weight: 0.1489860564470291\n",
      "avg viol: 1.763902537365211, max viol: 1.7822323157452047 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2842317819595337, valid regret : -0.2857653498649597 \n",
      "---------------------------------------iteration: 1721\n",
      "l1 decision: 0.09020893275737762\n",
      "l1 weight: 0.1487131416797638\n",
      "avg viol: 1.7824024727055803, max viol: 1.7962344292318448 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2808595597743988, valid regret : -0.27275824546813965 \n",
      "---------------------------------------iteration: 1722\n",
      "l1 decision: 0.0880700871348381\n",
      "l1 weight: 0.14932572841644287\n",
      "avg viol: 1.76181587100029, max viol: 1.7827584436163306 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2846654951572418, valid regret : -0.28047072887420654 \n",
      "---------------------------------------iteration: 1723\n",
      "l1 decision: 0.08997651189565659\n",
      "l1 weight: 0.148436039686203\n",
      "avg viol: 1.7819130763201974, max viol: 1.8014700771309435 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29216068983078003, valid regret : -0.28525328636169434 \n",
      "---------------------------------------iteration: 1724\n",
      "l1 decision: 0.0888812467455864\n",
      "l1 weight: 0.1470266878604889\n",
      "avg viol: 1.7767009010211223, max viol: 1.7979683908633888 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28038179874420166, valid regret : -0.2786979377269745 \n",
      "---------------------------------------iteration: 1725\n",
      "l1 decision: 0.09005720913410187\n",
      "l1 weight: 0.14852198958396912\n",
      "avg viol: 1.7845368938660249, max viol: 1.8037108103744686 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27457907795906067, valid regret : -0.2786361277103424 \n",
      "---------------------------------------iteration: 1726\n",
      "l1 decision: 0.08870954066514969\n",
      "l1 weight: 0.14809423685073853\n",
      "avg viol: 1.7726442476734519, max viol: 1.790385075029917 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2848093509674072, valid regret : -0.28449204564094543 \n",
      "---------------------------------------iteration: 1727\n",
      "l1 decision: 0.09060002863407135\n",
      "l1 weight: 0.1493009477853775\n",
      "avg viol: 1.7800061893207022, max viol: 1.7961554597131908 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28393733501434326, valid regret : -0.2711276113986969 \n",
      "---------------------------------------iteration: 1728\n",
      "l1 decision: 0.08816703408956528\n",
      "l1 weight: 0.14731813967227936\n",
      "avg viol: 1.7627468267577933, max viol: 1.7808513566851616 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2732495367527008, valid regret : -0.28254464268684387 \n",
      "---------------------------------------iteration: 1729\n",
      "l1 decision: 0.08983413875102997\n",
      "l1 weight: 0.14973768591880798\n",
      "avg viol: 1.784212516261614, max viol: 1.8039045811165124 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28540757298469543, valid regret : -0.287543386220932 \n",
      "---------------------------------------iteration: 1730\n",
      "l1 decision: 0.08935880661010742\n",
      "l1 weight: 0.15116527676582336\n",
      "avg viol: 1.784819241311361, max viol: 1.8020437761442736 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2843458354473114, valid regret : -0.2774693965911865 \n",
      "---------------------------------------iteration: 1731\n",
      "l1 decision: 0.09037338942289352\n",
      "l1 weight: 0.15129207074642181\n",
      "avg viol: 1.7824417450890178, max viol: 1.799562124768272 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26871609687805176, valid regret : -0.27329981327056885 \n",
      "---------------------------------------iteration: 1732\n",
      "l1 decision: 0.08779598772525787\n",
      "l1 weight: 0.14886194467544556\n",
      "avg viol: 1.7557624504086562, max viol: 1.7758081970969215 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28122588992118835, valid regret : -0.2861849069595337 \n",
      "---------------------------------------iteration: 1733\n",
      "l1 decision: 0.09024808555841446\n",
      "l1 weight: 0.14909175038337708\n",
      "avg viol: 1.7876989438314923, max viol: 1.804155768826604 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2815408408641815, valid regret : -0.2769855558872223 \n",
      "---------------------------------------iteration: 1734\n",
      "l1 decision: 0.08862894773483276\n",
      "l1 weight: 0.15006853640079498\n",
      "avg viol: 1.7717670602242652, max viol: 1.796329058415722 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2869333326816559, valid regret : -0.28153884410858154 \n",
      "---------------------------------------iteration: 1735\n",
      "l1 decision: 0.09042641520500183\n",
      "l1 weight: 0.14860141277313232\n",
      "avg viol: 1.7872482249554014, max viol: 1.8006237506051548 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2936657965183258, valid regret : -0.28084227442741394 \n",
      "---------------------------------------iteration: 1736\n",
      "l1 decision: 0.08840568363666534\n",
      "l1 weight: 0.1470663994550705\n",
      "avg viol: 1.7652405890345109, max viol: 1.7832807444501668 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27593305706977844, valid regret : -0.27593082189559937 \n",
      "---------------------------------------iteration: 1737\n",
      "l1 decision: 0.08931535482406616\n",
      "l1 weight: 0.14806075394153595\n",
      "avg viol: 1.7781947418820345, max viol: 1.799414792447351 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2733175754547119, valid regret : -0.2805517911911011 \n",
      "---------------------------------------iteration: 1738\n",
      "l1 decision: 0.08898705244064331\n",
      "l1 weight: 0.14893515408039093\n",
      "avg viol: 1.7751678963552695, max viol: 1.796250278246589 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2841411530971527, valid regret : -0.28497180342674255 \n",
      "---------------------------------------iteration: 1739\n",
      "l1 decision: 0.08972718566656113\n",
      "l1 weight: 0.1492457389831543\n",
      "avg viol: 1.7814565831568325, max viol: 1.798175645293668 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28580379486083984, valid regret : -0.268263578414917 \n",
      "---------------------------------------iteration: 1740\n",
      "l1 decision: 0.08832745254039764\n",
      "l1 weight: 0.147225022315979\n",
      "avg viol: 1.7638644530746388, max viol: 1.779448005836457 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2724646031856537, valid regret : -0.2802462875843048 \n",
      "---------------------------------------iteration: 1741\n",
      "l1 decision: 0.08927714824676514\n",
      "l1 weight: 0.15006475150585175\n",
      "avg viol: 1.7802349866967415, max viol: 1.7970104544656351 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2849562168121338, valid regret : -0.28551796078681946 \n",
      "---------------------------------------iteration: 1742\n",
      "l1 decision: 0.08921150863170624\n",
      "l1 weight: 0.15108142793178558\n",
      "avg viol: 1.7793379543489027, max viol: 1.8004296312574297 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2812937796115875, valid regret : -0.27754586935043335 \n",
      "---------------------------------------iteration: 1743\n",
      "l1 decision: 0.09008925408124924\n",
      "l1 weight: 0.1511283814907074\n",
      "avg viol: 1.7904418599180645, max viol: 1.8041193361859769 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27100107073783875, valid regret : -0.2741820812225342 \n",
      "---------------------------------------iteration: 1744\n",
      "l1 decision: 0.08764495700597763\n",
      "l1 weight: 0.14953608810901642\n",
      "avg viol: 1.7539878607244463, max viol: 1.7764621230307966 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2806779146194458, valid regret : -0.2839084565639496 \n",
      "---------------------------------------iteration: 1745\n",
      "l1 decision: 0.0898049995303154\n",
      "l1 weight: 0.14892326295375824\n",
      "avg viol: 1.7764183312753448, max viol: 1.7974820449016988 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27776527404785156, valid regret : -0.27161797881126404 \n",
      "---------------------------------------iteration: 1746\n",
      "l1 decision: 0.08816330879926682\n",
      "l1 weight: 0.14940980076789856\n",
      "avg viol: 1.7629067334142747, max viol: 1.7821302355732769 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2848871350288391, valid regret : -0.28005099296569824 \n",
      "---------------------------------------iteration: 1747\n",
      "l1 decision: 0.09002738445997238\n",
      "l1 weight: 0.1484062671661377\n",
      "avg viol: 1.7817934544442686, max viol: 1.7960593868047 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29170483350753784, valid regret : -0.2833622097969055 \n",
      "---------------------------------------iteration: 1748\n",
      "l1 decision: 0.08879022300243378\n",
      "l1 weight: 0.14668798446655273\n",
      "avg viol: 1.7746951507586528, max viol: 1.7936418921453878 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27996188402175903, valid regret : -0.2767391502857208 \n",
      "---------------------------------------iteration: 1749\n",
      "l1 decision: 0.08972997218370438\n",
      "l1 weight: 0.14858296513557434\n",
      "avg viol: 1.7773927573143737, max viol: 1.7980032325722277 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2729388475418091, valid regret : -0.27679455280303955 \n",
      "---------------------------------------iteration: 1750\n",
      "l1 decision: 0.08821556717157364\n",
      "l1 weight: 0.14832912385463715\n",
      "avg viol: 1.7635521672840695, max viol: 1.7832666125614196 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28216737508773804, valid regret : -0.2862951457500458 \n",
      "---------------------------------------iteration: 1751\n",
      "l1 decision: 0.09008577466011047\n",
      "l1 weight: 0.149532288312912\n",
      "avg viol: 1.7871856822422705, max viol: 1.8036988417152315 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2864924669265747, valid regret : -0.27682581543922424 \n",
      "---------------------------------------iteration: 1752\n",
      "l1 decision: 0.08922781050205231\n",
      "l1 weight: 0.14688651263713837\n",
      "avg viol: 1.7816652593342224, max viol: 1.7986156570841558 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27942362427711487, valid regret : -0.281938374042511 \n",
      "---------------------------------------iteration: 1753\n",
      "l1 decision: 0.08972557634115219\n",
      "l1 weight: 0.150217205286026\n",
      "avg viol: 1.7804859621677316, max viol: 1.8024442396126688 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28499558568000793, valid regret : -0.2813621759414673 \n",
      "---------------------------------------iteration: 1754\n",
      "l1 decision: 0.08836927264928818\n",
      "l1 weight: 0.15095122158527374\n",
      "avg viol: 1.7663835849263705, max viol: 1.7844215049408376 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27811139822006226, valid regret : -0.2767719030380249 \n",
      "---------------------------------------iteration: 1755\n",
      "l1 decision: 0.09043557941913605\n",
      "l1 weight: 0.15124304592609406\n",
      "avg viol: 1.7883058350207284, max viol: 1.801753755658865 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27021339535713196, valid regret : -0.27870839834213257 \n",
      "---------------------------------------iteration: 1756\n",
      "l1 decision: 0.08839654177427292\n",
      "l1 weight: 0.14922183752059937\n",
      "avg viol: 1.7681661549246563, max viol: 1.7901553004048765 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2868272364139557, valid regret : -0.2844603955745697 \n",
      "---------------------------------------iteration: 1757\n",
      "l1 decision: 0.08995214104652405\n",
      "l1 weight: 0.14986905455589294\n",
      "avg viol: 1.7750003176281461, max viol: 1.7966267324518412 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27804887294769287, valid regret : -0.27048373222351074 \n",
      "---------------------------------------iteration: 1758\n",
      "l1 decision: 0.08803167939186096\n",
      "l1 weight: 0.14986887574195862\n",
      "avg viol: 1.7610124521004036, max viol: 1.7802538234973326 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2822708189487457, valid regret : -0.28166499733924866 \n",
      "---------------------------------------iteration: 1759\n",
      "l1 decision: 0.09025058150291443\n",
      "l1 weight: 0.14818154275417328\n",
      "avg viol: 1.790174392189365, max viol: 1.8023078951518983 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2941039204597473, valid regret : -0.28563469648361206 \n",
      "---------------------------------------iteration: 1760\n",
      "l1 decision: 0.08950982987880707\n",
      "l1 weight: 0.1471550613641739\n",
      "avg viol: 1.7844833935727364, max viol: 1.8023229689570144 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2822641134262085, valid regret : -0.2769370973110199 \n",
      "---------------------------------------iteration: 1761\n",
      "l1 decision: 0.08943301439285278\n",
      "l1 weight: 0.14823800325393677\n",
      "avg viol: 1.7786110022920365, max viol: 1.8005569622619078 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2732400596141815, valid regret : -0.2795003652572632 \n",
      "---------------------------------------iteration: 1762\n",
      "l1 decision: 0.08892125636339188\n",
      "l1 weight: 0.14831867814064026\n",
      "avg viol: 1.7738409843237242, max viol: 1.7952061295509338 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2842325270175934, valid regret : -0.2861008942127228 \n",
      "---------------------------------------iteration: 1763\n",
      "l1 decision: 0.09019194543361664\n",
      "l1 weight: 0.14902916550636292\n",
      "avg viol: 1.7849856555083534, max viol: 1.799038861412555 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28667980432510376, valid regret : -0.27165934443473816 \n",
      "---------------------------------------iteration: 1764\n",
      "l1 decision: 0.08833663910627365\n",
      "l1 weight: 0.14758095145225525\n",
      "avg viol: 1.7646484606876038, max viol: 1.7842518606339581 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27419352531433105, valid regret : -0.27982285618782043 \n",
      "---------------------------------------iteration: 1765\n",
      "l1 decision: 0.08983774483203888\n",
      "l1 weight: 0.14915908873081207\n",
      "avg viol: 1.7834115849377121, max viol: 1.8019672605441883 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28571900725364685, valid regret : -0.28467464447021484 \n",
      "---------------------------------------iteration: 1766\n",
      "l1 decision: 0.08891819417476654\n",
      "l1 weight: 0.15087354183197021\n",
      "avg viol: 1.7773543729961785, max viol: 1.7976183716382366 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2822374105453491, valid regret : -0.2739544212818146 \n",
      "---------------------------------------iteration: 1767\n",
      "l1 decision: 0.0905882865190506\n",
      "l1 weight: 0.15219925343990326\n",
      "avg viol: 1.7743583855987526, max viol: 1.794394598575309 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26548635959625244, valid regret : -0.26923033595085144 \n",
      "---------------------------------------iteration: 1768\n",
      "l1 decision: 0.08731671422719955\n",
      "l1 weight: 0.14837193489074707\n",
      "avg viol: 1.7474653634265997, max viol: 1.7651077159680426 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2765742540359497, valid regret : -0.2842863202095032 \n",
      "---------------------------------------iteration: 1769\n",
      "l1 decision: 0.08931735903024673\n",
      "l1 weight: 0.14918053150177002\n",
      "avg viol: 1.7775677661551164, max viol: 1.7973633345682174 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2793717682361603, valid regret : -0.2757677733898163 \n",
      "---------------------------------------iteration: 1770\n",
      "l1 decision: 0.08903513848781586\n",
      "l1 weight: 0.14950412511825562\n",
      "avg viol: 1.7783962532275472, max viol: 1.7982260049320757 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2884616255760193, valid regret : -0.28006699681282043 \n",
      "---------------------------------------iteration: 1771\n",
      "l1 decision: 0.09068512171506882\n",
      "l1 weight: 0.1483374983072281\n",
      "avg viol: 1.7855906061158748, max viol: 1.7981077290605754 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29305699467658997, valid regret : -0.28012776374816895 \n",
      "---------------------------------------iteration: 1772\n",
      "l1 decision: 0.08821100741624832\n",
      "l1 weight: 0.14721697568893433\n",
      "avg viol: 1.764031135943369, max viol: 1.7806808043969795 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27660661935806274, valid regret : -0.2751571536064148 \n",
      "---------------------------------------iteration: 1773\n",
      "l1 decision: 0.08974042534828186\n",
      "l1 weight: 0.1486089825630188\n",
      "avg viol: 1.7758100613526766, max viol: 1.7948836549185216 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27176687121391296, valid regret : -0.27721989154815674 \n",
      "---------------------------------------iteration: 1774\n",
      "l1 decision: 0.0881829559803009\n",
      "l1 weight: 0.1481907218694687\n",
      "avg viol: 1.7632766883989097, max viol: 1.7843144717626274 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2819008231163025, valid regret : -0.28594884276390076 \n",
      "---------------------------------------iteration: 1775\n",
      "l1 decision: 0.0892876386642456\n",
      "l1 weight: 0.14962570369243622\n",
      "avg viol: 1.7742996882885926, max viol: 1.797857201192528 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28306880593299866, valid regret : -0.27583155035972595 \n",
      "---------------------------------------iteration: 1776\n",
      "l1 decision: 0.08892130851745605\n",
      "l1 weight: 0.14696554839611053\n",
      "avg viol: 1.7779664314003458, max viol: 1.7958938404917717 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27824264764785767, valid regret : -0.28257811069488525 \n",
      "---------------------------------------iteration: 1777\n",
      "l1 decision: 0.08980140089988708\n",
      "l1 weight: 0.15021462738513947\n",
      "avg viol: 1.782403536622878, max viol: 1.8045712534803897 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2857835292816162, valid regret : -0.28439709544181824 \n",
      "---------------------------------------iteration: 1778\n",
      "l1 decision: 0.08922893553972244\n",
      "l1 weight: 0.15042349696159363\n",
      "avg viol: 1.7822986818198114, max viol: 1.7981675027986057 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28292182087898254, valid regret : -0.27544665336608887 \n",
      "---------------------------------------iteration: 1779\n",
      "l1 decision: 0.09053067117929459\n",
      "l1 weight: 0.15147651731967926\n",
      "avg viol: 1.7797897960222326, max viol: 1.795746270334348 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2670952379703522, valid regret : -0.2741885185241699 \n",
      "---------------------------------------iteration: 1780\n",
      "l1 decision: 0.08795460313558578\n",
      "l1 weight: 0.14966550469398499\n",
      "avg viol: 1.7595073956041596, max viol: 1.776676301495172 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2819133698940277, valid regret : -0.2835654318332672 \n",
      "---------------------------------------iteration: 1781\n",
      "l1 decision: 0.09008385986089706\n",
      "l1 weight: 0.14837895333766937\n",
      "avg viol: 1.7809590111818396, max viol: 1.7978874515974894 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27948975563049316, valid regret : -0.2715483009815216 \n",
      "---------------------------------------iteration: 1782\n",
      "l1 decision: 0.08836910128593445\n",
      "l1 weight: 0.1492304652929306\n",
      "avg viol: 1.7659511990069587, max viol: 1.7814831617288291 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2839277386665344, valid regret : -0.27688369154930115 \n",
      "---------------------------------------iteration: 1783\n",
      "l1 decision: 0.08926152437925339\n",
      "l1 weight: 0.14836961030960083\n",
      "avg viol: 1.7743792489927728, max viol: 1.787330202292651 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2889012098312378, valid regret : -0.27549588680267334 \n",
      "---------------------------------------iteration: 1784\n",
      "l1 decision: 0.08787255734205246\n",
      "l1 weight: 0.147024005651474\n",
      "avg viol: 1.7559281563898548, max viol: 1.7736530267866328 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27082598209381104, valid regret : -0.2761511504650116 \n",
      "---------------------------------------iteration: 1785\n",
      "l1 decision: 0.08901358395814896\n",
      "l1 weight: 0.14782141149044037\n",
      "avg viol: 1.7766458689811406, max viol: 1.7961859593633562 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2718157470226288, valid regret : -0.2797316014766693 \n",
      "---------------------------------------iteration: 1786\n",
      "l1 decision: 0.08879450708627701\n",
      "l1 weight: 0.14842697978019714\n",
      "avg viol: 1.7764325179820297, max viol: 1.796128459944157 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2852191627025604, valid regret : -0.2863308787345886 \n",
      "---------------------------------------iteration: 1787\n",
      "l1 decision: 0.0900542363524437\n",
      "l1 weight: 0.14939630031585693\n",
      "avg viol: 1.7865367135772248, max viol: 1.802967008203268 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2867636978626251, valid regret : -0.27162832021713257 \n",
      "---------------------------------------iteration: 1788\n",
      "l1 decision: 0.08828176558017731\n",
      "l1 weight: 0.14725539088249207\n",
      "avg viol: 1.765575193258701, max viol: 1.786655696341768 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2749216556549072, valid regret : -0.28221794962882996 \n",
      "---------------------------------------iteration: 1789\n",
      "l1 decision: 0.08956453204154968\n",
      "l1 weight: 0.15019552409648895\n",
      "avg viol: 1.7834861166431801, max viol: 1.804005944984965 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2859129309654236, valid regret : -0.28490787744522095 \n",
      "---------------------------------------iteration: 1790\n",
      "l1 decision: 0.089131660759449\n",
      "l1 weight: 0.15070700645446777\n",
      "avg viol: 1.7812086192542482, max viol: 1.7975587310502306 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28279221057891846, valid regret : -0.2752505838871002 \n",
      "---------------------------------------iteration: 1791\n",
      "l1 decision: 0.09067001193761826\n",
      "l1 weight: 0.15129464864730835\n",
      "avg viol: 1.7826757662184536, max viol: 1.7962050177156925 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2687811255455017, valid regret : -0.2718391716480255 \n",
      "---------------------------------------iteration: 1792\n",
      "l1 decision: 0.08762243390083313\n",
      "l1 weight: 0.1496698409318924\n",
      "avg viol: 1.7512514229223597, max viol: 1.774731490877457 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.278146356344223, valid regret : -0.28432056307792664 \n",
      "---------------------------------------iteration: 1793\n",
      "l1 decision: 0.08911912143230438\n",
      "l1 weight: 0.1494571566581726\n",
      "avg viol: 1.77905406577338, max viol: 1.800385954673402 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27975955605506897, valid regret : -0.277412086725235 \n",
      "---------------------------------------iteration: 1794\n",
      "l1 decision: 0.08940216153860092\n",
      "l1 weight: 0.1500394493341446\n",
      "avg viol: 1.7834097033648504, max viol: 1.8024378195987083 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2891332507133484, valid regret : -0.28167855739593506 \n",
      "---------------------------------------iteration: 1795\n",
      "l1 decision: 0.09018578380346298\n",
      "l1 weight: 0.1484488695859909\n",
      "avg viol: 1.782822034120327, max viol: 1.8009968481492251 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29216012358665466, valid regret : -0.28100642561912537 \n",
      "---------------------------------------iteration: 1796\n",
      "l1 decision: 0.0883551612496376\n",
      "l1 weight: 0.14733663201332092\n",
      "avg viol: 1.7667422190291109, max viol: 1.7865194296464324 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2780274450778961, valid regret : -0.27726510167121887 \n",
      "---------------------------------------iteration: 1797\n",
      "l1 decision: 0.09029626101255417\n",
      "l1 weight: 0.14766457676887512\n",
      "avg viol: 1.784616962831933, max viol: 1.8015978096518666 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27354010939598083, valid regret : -0.27746671438217163 \n",
      "---------------------------------------iteration: 1798\n",
      "l1 decision: 0.08783868700265884\n",
      "l1 weight: 0.14896470308303833\n",
      "avg viol: 1.7565444010068314, max viol: 1.7882266163360327 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2788371741771698, valid regret : -0.2864324152469635 \n",
      "---------------------------------------iteration: 1799\n",
      "l1 decision: 0.08994419127702713\n",
      "l1 weight: 0.14925730228424072\n",
      "avg viol: 1.7885394677310251, max viol: 1.8051033120136708 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2874438166618347, valid regret : -0.2766471207141876 \n",
      "---------------------------------------iteration: 1800\n",
      "l1 decision: 0.08932164311408997\n",
      "l1 weight: 0.1474352478981018\n",
      "avg viol: 1.7830546147069253, max viol: 1.8012090326519683 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2797812223434448, valid regret : -0.2820892035961151 \n",
      "---------------------------------------iteration: 1801\n",
      "l1 decision: 0.08975425362586975\n",
      "l1 weight: 0.15027476847171783\n",
      "avg viol: 1.7807731049804716, max viol: 1.8004680662415922 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28591597080230713, valid regret : -0.281991571187973 \n",
      "---------------------------------------iteration: 1802\n",
      "l1 decision: 0.08880504220724106\n",
      "l1 weight: 0.1507178097963333\n",
      "avg viol: 1.773433940399118, max viol: 1.7916968691861257 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2801241874694824, valid regret : -0.27535679936408997 \n",
      "---------------------------------------iteration: 1803\n",
      "l1 decision: 0.09005391597747803\n",
      "l1 weight: 0.15169183909893036\n",
      "avg viol: 1.777872367092641, max viol: 1.7973574514035136 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2674531936645508, valid regret : -0.2762700915336609 \n",
      "---------------------------------------iteration: 1804\n",
      "l1 decision: 0.08811288326978683\n",
      "l1 weight: 0.15014946460723877\n",
      "avg viol: 1.7615579431285733, max viol: 1.7861875725502614 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2834346890449524, valid regret : -0.287177711725235 \n",
      "---------------------------------------iteration: 1805\n",
      "l1 decision: 0.08967722207307816\n",
      "l1 weight: 0.14946764707565308\n",
      "avg viol: 1.7823470020113745, max viol: 1.8042637110920623 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2804412841796875, valid regret : -0.27615299820899963 \n",
      "---------------------------------------iteration: 1806\n",
      "l1 decision: 0.0887908861041069\n",
      "l1 weight: 0.1495787650346756\n",
      "avg viol: 1.7755179363567732, max viol: 1.7941792485071346 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28748148679733276, valid regret : -0.28112727403640747 \n",
      "---------------------------------------iteration: 1807\n",
      "l1 decision: 0.09054841101169586\n",
      "l1 weight: 0.1485101580619812\n",
      "avg viol: 1.7864140034024603, max viol: 1.800002019153908 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29288750886917114, valid regret : -0.27973198890686035 \n",
      "---------------------------------------iteration: 1808\n",
      "l1 decision: 0.08814618736505508\n",
      "l1 weight: 0.147088423371315\n",
      "avg viol: 1.7633063233225585, max viol: 1.7789354387205094 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2753877341747284, valid regret : -0.27495700120925903 \n",
      "---------------------------------------iteration: 1809\n",
      "l1 decision: 0.09009161591529846\n",
      "l1 weight: 0.1483895182609558\n",
      "avg viol: 1.7790638061787467, max viol: 1.7957545487442985 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27215421199798584, valid regret : -0.2779715359210968 \n",
      "---------------------------------------iteration: 1810\n",
      "l1 decision: 0.08826997876167297\n",
      "l1 weight: 0.1484278440475464\n",
      "avg viol: 1.764980961674737, max viol: 1.7885402874089777 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2823086977005005, valid regret : -0.2862507402896881 \n",
      "---------------------------------------iteration: 1811\n",
      "l1 decision: 0.08964809030294418\n",
      "l1 weight: 0.14894719421863556\n",
      "avg viol: 1.7812163942755432, max viol: 1.798409324605018 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28580743074417114, valid regret : -0.27638110518455505 \n",
      "---------------------------------------iteration: 1812\n",
      "l1 decision: 0.08891460299491882\n",
      "l1 weight: 0.1468842327594757\n",
      "avg viol: 1.7777832285972908, max viol: 1.7973463627276942 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2786600887775421, valid regret : -0.28208696842193604 \n",
      "---------------------------------------iteration: 1813\n",
      "l1 decision: 0.09024013578891754\n",
      "l1 weight: 0.14910274744033813\n",
      "avg viol: 1.7886703323281836, max viol: 1.805736338486895 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2880032956600189, valid regret : -0.28313401341438293 \n",
      "---------------------------------------iteration: 1814\n",
      "l1 decision: 0.0886208787560463\n",
      "l1 weight: 0.15059013664722443\n",
      "avg viol: 1.771858499943628, max viol: 1.7889353709761053 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28001299500465393, valid regret : -0.2760859429836273 \n",
      "---------------------------------------iteration: 1815\n",
      "l1 decision: 0.09072677791118622\n",
      "l1 weight: 0.1511649787425995\n",
      "avg viol: 1.7853668629052117, max viol: 1.7981497909640893 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2688077986240387, valid regret : -0.2731579542160034 \n",
      "---------------------------------------iteration: 1816\n",
      "l1 decision: 0.08791442215442657\n",
      "l1 weight: 0.14868545532226562\n",
      "avg viol: 1.7588567171420437, max viol: 1.7764101100619882 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28160420060157776, valid regret : -0.2871345281600952 \n",
      "---------------------------------------iteration: 1817\n",
      "l1 decision: 0.0900697261095047\n",
      "l1 weight: 0.14868712425231934\n",
      "avg viol: 1.7863547320547513, max viol: 1.802600218798034 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2815273404121399, valid regret : -0.277856707572937 \n",
      "---------------------------------------iteration: 1818\n",
      "l1 decision: 0.08921761810779572\n",
      "l1 weight: 0.14967380464076996\n",
      "avg viol: 1.7822422694378839, max viol: 1.8019075512420386 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2899482548236847, valid regret : -0.2828790545463562 \n",
      "---------------------------------------iteration: 1819\n",
      "l1 decision: 0.0906711146235466\n",
      "l1 weight: 0.14854197204113007\n",
      "avg viol: 1.788958198222681, max viol: 1.803256233513821 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2944902181625366, valid regret : -0.28142666816711426 \n",
      "---------------------------------------iteration: 1820\n",
      "l1 decision: 0.08831292390823364\n",
      "l1 weight: 0.14678403735160828\n",
      "avg viol: 1.7640354166121688, max viol: 1.782296549063176 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27663668990135193, valid regret : -0.2776041626930237 \n",
      "---------------------------------------iteration: 1821\n",
      "l1 decision: 0.09011553972959518\n",
      "l1 weight: 0.14774711430072784\n",
      "avg viol: 1.7854244562226813, max viol: 1.8037030664272606 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2743566930294037, valid regret : -0.2773451805114746 \n",
      "---------------------------------------iteration: 1822\n",
      "l1 decision: 0.08850757777690887\n",
      "l1 weight: 0.148426815867424\n",
      "avg viol: 1.7696588032296858, max viol: 1.7898250871803612 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28372642397880554, valid regret : -0.286039263010025 \n",
      "---------------------------------------iteration: 1823\n",
      "l1 decision: 0.08993227034807205\n",
      "l1 weight: 0.14925271272659302\n",
      "avg viol: 1.7774160435167141, max viol: 1.7969906490761787 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2830067574977875, valid regret : -0.27253589034080505 \n",
      "---------------------------------------iteration: 1824\n",
      "l1 decision: 0.08855939656496048\n",
      "l1 weight: 0.14738722145557404\n",
      "avg viol: 1.768655946641229, max viol: 1.7868350138887763 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.274336576461792, valid regret : -0.28103771805763245 \n",
      "---------------------------------------iteration: 1825\n",
      "l1 decision: 0.0896720290184021\n",
      "l1 weight: 0.1492631882429123\n",
      "avg viol: 1.7827952232700772, max viol: 1.7989484544377774 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28581517934799194, valid regret : -0.28620678186416626 \n",
      "---------------------------------------iteration: 1826\n",
      "l1 decision: 0.08915799111127853\n",
      "l1 weight: 0.15028971433639526\n",
      "avg viol: 1.7827952774497497, max viol: 1.798017248929682 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2830839157104492, valid regret : -0.2758514881134033 \n",
      "---------------------------------------iteration: 1827\n",
      "l1 decision: 0.09036826342344284\n",
      "l1 weight: 0.1516641080379486\n",
      "avg viol: 1.7802762670727679, max viol: 1.7968077935511246 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26808467507362366, valid regret : -0.2720750868320465 \n",
      "---------------------------------------iteration: 1828\n",
      "l1 decision: 0.08776601403951645\n",
      "l1 weight: 0.14887213706970215\n",
      "avg viol: 1.7566805556678446, max viol: 1.7732134775724262 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2803637385368347, valid regret : -0.28638315200805664 \n",
      "---------------------------------------iteration: 1829\n",
      "l1 decision: 0.08955258876085281\n",
      "l1 weight: 0.14885251224040985\n",
      "avg viol: 1.7827883752214257, max viol: 1.800832764361985 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2808893322944641, valid regret : -0.27768412232398987 \n",
      "---------------------------------------iteration: 1830\n",
      "l1 decision: 0.08948180824518204\n",
      "l1 weight: 0.14913813769817352\n",
      "avg viol: 1.786135884476971, max viol: 1.8017562334425747 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29103049635887146, valid regret : -0.28271692991256714 \n",
      "---------------------------------------iteration: 1831\n",
      "l1 decision: 0.09058333188295364\n",
      "l1 weight: 0.14761991798877716\n",
      "avg viol: 1.792635637194544, max viol: 1.802201222628355 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2959166467189789, valid regret : -0.28535687923431396 \n",
      "---------------------------------------iteration: 1832\n",
      "l1 decision: 0.08911015838384628\n",
      "l1 weight: 0.14744919538497925\n",
      "avg viol: 1.7736081510863733, max viol: 1.7960365717299283 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27891701459884644, valid regret : -0.2770799398422241 \n",
      "---------------------------------------iteration: 1833\n",
      "l1 decision: 0.08945401757955551\n",
      "l1 weight: 0.14796610176563263\n",
      "avg viol: 1.7765746814841987, max viol: 1.797886760206893 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27340370416641235, valid regret : -0.2758052349090576 \n",
      "---------------------------------------iteration: 1834\n",
      "l1 decision: 0.08856181800365448\n",
      "l1 weight: 0.14805972576141357\n",
      "avg viol: 1.7682212648479618, max viol: 1.784362626465736 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.282398521900177, valid regret : -0.2861323058605194 \n",
      "---------------------------------------iteration: 1835\n",
      "l1 decision: 0.08987310528755188\n",
      "l1 weight: 0.14949452877044678\n",
      "avg viol: 1.7782023066841066, max viol: 1.7965452978387475 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2849467098712921, valid regret : -0.2699275016784668 \n",
      "---------------------------------------iteration: 1836\n",
      "l1 decision: 0.08796156942844391\n",
      "l1 weight: 0.14738166332244873\n",
      "avg viol: 1.759247104934766, max viol: 1.7794009922072291 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2721822261810303, valid regret : -0.2823425233364105 \n",
      "---------------------------------------iteration: 1837\n",
      "l1 decision: 0.08978018164634705\n",
      "l1 weight: 0.1492152363061905\n",
      "avg viol: 1.7865553302050103, max viol: 1.8047464075498283 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2868333160877228, valid regret : -0.28772664070129395 \n",
      "---------------------------------------iteration: 1838\n",
      "l1 decision: 0.08942472189664841\n",
      "l1 weight: 0.15028449892997742\n",
      "avg viol: 1.7841820951889895, max viol: 1.8023538567358628 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28363528847694397, valid regret : -0.27737608551979065 \n",
      "---------------------------------------iteration: 1839\n",
      "l1 decision: 0.09055393189191818\n",
      "l1 weight: 0.15121513605117798\n",
      "avg viol: 1.7876660055323736, max viol: 1.7996810593176633 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2704291045665741, valid regret : -0.27361610531806946 \n",
      "---------------------------------------iteration: 1840\n",
      "l1 decision: 0.08790970593690872\n",
      "l1 weight: 0.14798350632190704\n",
      "avg viol: 1.7573021815845278, max viol: 1.773392500472255 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28191491961479187, valid regret : -0.28802943229675293 \n",
      "---------------------------------------iteration: 1841\n",
      "l1 decision: 0.09016598761081696\n",
      "l1 weight: 0.1485346108675003\n",
      "avg viol: 1.784329623724916, max viol: 1.8042840352281928 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2813592255115509, valid regret : -0.27755531668663025 \n",
      "---------------------------------------iteration: 1842\n",
      "l1 decision: 0.08906499296426773\n",
      "l1 weight: 0.14907768368721008\n",
      "avg viol: 1.7798162149219205, max viol: 1.798802729434101 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2894144356250763, valid regret : -0.2826889157295227 \n",
      "---------------------------------------iteration: 1843\n",
      "l1 decision: 0.09032587707042694\n",
      "l1 weight: 0.14790897071361542\n",
      "avg viol: 1.769793996892404, max viol: 1.7976416619494557 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28731000423431396, valid regret : -0.27930355072021484 \n",
      "---------------------------------------iteration: 1844\n",
      "l1 decision: 0.08793740719556808\n",
      "l1 weight: 0.14722703397274017\n",
      "avg viol: 1.7578368661663262, max viol: 1.7801137391943485 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2740761339664459, valid regret : -0.2770647704601288 \n",
      "---------------------------------------iteration: 1845\n",
      "l1 decision: 0.09031649678945541\n",
      "l1 weight: 0.1473303884267807\n",
      "avg viol: 1.7857173428300301, max viol: 1.802156051271595 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27367785573005676, valid regret : -0.2808316648006439 \n",
      "---------------------------------------iteration: 1846\n",
      "l1 decision: 0.08829135447740555\n",
      "l1 weight: 0.1478474736213684\n",
      "avg viol: 1.7649953721207567, max viol: 1.7924594392534345 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2830159068107605, valid regret : -0.28295302391052246 \n",
      "---------------------------------------iteration: 1847\n",
      "l1 decision: 0.08903481811285019\n",
      "l1 weight: 0.1502208411693573\n",
      "avg viol: 1.748636792813195, max viol: 1.7890527518466115 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2750067412853241, valid regret : -0.27124646306037903 \n",
      "---------------------------------------iteration: 1848\n",
      "l1 decision: 0.08822618424892426\n",
      "l1 weight: 0.14768634736537933\n",
      "avg viol: 1.7651571478985715, max viol: 1.7863048939034343 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27394530177116394, valid regret : -0.2835533022880554 \n",
      "---------------------------------------iteration: 1849\n",
      "l1 decision: 0.08984795957803726\n",
      "l1 weight: 0.1490672528743744\n",
      "avg viol: 1.786121048372006, max viol: 1.8028152777114883 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2869349718093872, valid regret : -0.2875259518623352 \n",
      "---------------------------------------iteration: 1850\n",
      "l1 decision: 0.08950944244861603\n",
      "l1 weight: 0.15055860579013824\n",
      "avg viol: 1.787625860806147, max viol: 1.8037430037511513 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2843288481235504, valid regret : -0.27703672647476196 \n",
      "---------------------------------------iteration: 1851\n",
      "l1 decision: 0.09018804877996445\n",
      "l1 weight: 0.15170922875404358\n",
      "avg viol: 1.7809467413532547, max viol: 1.7965565486811101 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2691143751144409, valid regret : -0.2738567292690277 \n",
      "---------------------------------------iteration: 1852\n",
      "l1 decision: 0.08768351376056671\n",
      "l1 weight: 0.1477334052324295\n",
      "avg viol: 1.751970508256345, max viol: 1.7725052593741566 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2801666259765625, valid regret : -0.28786301612854004 \n",
      "---------------------------------------iteration: 1853\n",
      "l1 decision: 0.09032489359378815\n",
      "l1 weight: 0.14850109815597534\n",
      "avg viol: 1.7916037144040455, max viol: 1.8043782234890386 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28351137042045593, valid regret : -0.27793002128601074 \n",
      "---------------------------------------iteration: 1854\n",
      "l1 decision: 0.08915642648935318\n",
      "l1 weight: 0.1495266854763031\n",
      "avg viol: 1.780788114609495, max viol: 1.8001288208179176 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2897454500198364, valid regret : -0.28315937519073486 \n",
      "---------------------------------------iteration: 1855\n",
      "l1 decision: 0.09084011614322662\n",
      "l1 weight: 0.14816784858703613\n",
      "avg viol: 1.7826411916513463, max viol: 1.8002496571280062 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2909840941429138, valid regret : -0.27624180912971497 \n",
      "---------------------------------------iteration: 1856\n",
      "l1 decision: 0.08739104866981506\n",
      "l1 weight: 0.14682155847549438\n",
      "avg viol: 1.7472067982307635, max viol: 1.77059938153252 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27154672145843506, valid regret : -0.2784756124019623 \n",
      "---------------------------------------iteration: 1857\n",
      "l1 decision: 0.08977247774600983\n",
      "l1 weight: 0.14782041311264038\n",
      "avg viol: 1.7832699197757755, max viol: 1.8041992688085884 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27361318469047546, valid regret : -0.2826131582260132 \n",
      "---------------------------------------iteration: 1858\n",
      "l1 decision: 0.08915292471647263\n",
      "l1 weight: 0.14869073033332825\n",
      "avg viol: 1.7808250181483527, max viol: 1.8008708281558938 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28767120838165283, valid regret : -0.2856284976005554 \n",
      "---------------------------------------iteration: 1859\n",
      "l1 decision: 0.0906921997666359\n",
      "l1 weight: 0.14888925850391388\n",
      "avg viol: 1.7827629945764785, max viol: 1.7977830320596695 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28560248017311096, valid regret : -0.2680555582046509 \n",
      "---------------------------------------iteration: 1860\n",
      "l1 decision: 0.08811488002538681\n",
      "l1 weight: 0.1469063013792038\n",
      "avg viol: 1.7589889658475295, max viol: 1.7724033509148285 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2708829641342163, valid regret : -0.2799482047557831 \n",
      "---------------------------------------iteration: 1861\n",
      "l1 decision: 0.08972590416669846\n",
      "l1 weight: 0.14883668720722198\n",
      "avg viol: 1.7807155008905102, max viol: 1.792012607678771 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2851870357990265, valid regret : -0.2825890779495239 \n",
      "---------------------------------------iteration: 1862\n",
      "l1 decision: 0.08898875117301941\n",
      "l1 weight: 0.15021149814128876\n",
      "avg viol: 1.773610647264977, max viol: 1.7882277253083885 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2789475619792938, valid regret : -0.2730826437473297 \n",
      "---------------------------------------iteration: 1863\n",
      "l1 decision: 0.0892975777387619\n",
      "l1 weight: 0.151418536901474\n",
      "avg viol: 1.7730100803950335, max viol: 1.7875826999079436 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2658218443393707, valid regret : -0.2731798589229584 \n",
      "---------------------------------------iteration: 1864\n",
      "l1 decision: 0.08766202628612518\n",
      "l1 weight: 0.14786529541015625\n",
      "avg viol: 1.7538878678821492, max viol: 1.7694395905127749 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2799156904220581, valid regret : -0.2854975759983063 \n",
      "---------------------------------------iteration: 1865\n",
      "l1 decision: 0.08925595879554749\n",
      "l1 weight: 0.14829428493976593\n",
      "avg viol: 1.7694267572753597, max viol: 1.796282707946375 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2755495309829712, valid regret : -0.27525267004966736 \n",
      "---------------------------------------iteration: 1866\n",
      "l1 decision: 0.08866194635629654\n",
      "l1 weight: 0.14898549020290375\n",
      "avg viol: 1.7721957807758009, max viol: 1.7916166097857058 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28735753893852234, valid regret : -0.2833748161792755 \n",
      "---------------------------------------iteration: 1867\n",
      "l1 decision: 0.09028393775224686\n",
      "l1 weight: 0.14786896109580994\n",
      "avg viol: 1.7834004830144112, max viol: 1.8014909124467522 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2922441065311432, valid regret : -0.2835272550582886 \n",
      "---------------------------------------iteration: 1868\n",
      "l1 decision: 0.0888274535536766\n",
      "l1 weight: 0.14698748290538788\n",
      "avg viol: 1.7754952332971152, max viol: 1.791341931791976 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27990618348121643, valid regret : -0.2772075831890106 \n",
      "---------------------------------------iteration: 1869\n",
      "l1 decision: 0.0903354287147522\n",
      "l1 weight: 0.14769716560840607\n",
      "avg viol: 1.787486613385263, max viol: 1.8016297543654218 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27418234944343567, valid regret : -0.2770327627658844 \n",
      "---------------------------------------iteration: 1870\n",
      "l1 decision: 0.08874370157718658\n",
      "l1 weight: 0.148121640086174\n",
      "avg viol: 1.7735311687598005, max viol: 1.790645451983437 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28387635946273804, valid regret : -0.2868059277534485 \n",
      "---------------------------------------iteration: 1871\n",
      "l1 decision: 0.08965598791837692\n",
      "l1 weight: 0.14858762919902802\n",
      "avg viol: 1.7828814090281957, max viol: 1.7981736480724066 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28643226623535156, valid regret : -0.27417489886283875 \n",
      "---------------------------------------iteration: 1872\n",
      "l1 decision: 0.08887628465890884\n",
      "l1 weight: 0.14741036295890808\n",
      "avg viol: 1.7757676177925896, max viol: 1.792987432796508 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27704519033432007, valid regret : -0.2807594835758209 \n",
      "---------------------------------------iteration: 1873\n",
      "l1 decision: 0.09012074768543243\n",
      "l1 weight: 0.14913155138492584\n",
      "avg viol: 1.7839414105424658, max viol: 1.7979660821147263 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.286792516708374, valid regret : -0.2801954746246338 \n",
      "---------------------------------------iteration: 1874\n",
      "l1 decision: 0.08835398405790329\n",
      "l1 weight: 0.15039658546447754\n",
      "avg viol: 1.7659818647801877, max viol: 1.782651239540428 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27670466899871826, valid regret : -0.2775275409221649 \n",
      "---------------------------------------iteration: 1875\n",
      "l1 decision: 0.09003103524446487\n",
      "l1 weight: 0.150918111205101\n",
      "avg viol: 1.788389782840386, max viol: 1.802401399007067 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2705211937427521, valid regret : -0.28106990456581116 \n",
      "---------------------------------------iteration: 1876\n",
      "l1 decision: 0.0892365425825119\n",
      "l1 weight: 0.14826905727386475\n",
      "avg viol: 1.783474128954731, max viol: 1.800570684572449 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29047539830207825, valid regret : -0.2867667078971863 \n",
      "---------------------------------------iteration: 1877\n",
      "l1 decision: 0.09076683223247528\n",
      "l1 weight: 0.148060142993927\n",
      "avg viol: 1.7891926432898617, max viol: 1.7998575284145772 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28269222378730774, valid regret : -0.270059198141098 \n",
      "---------------------------------------iteration: 1878\n",
      "l1 decision: 0.0881398543715477\n",
      "l1 weight: 0.1492418646812439\n",
      "avg viol: 1.7622499141725712, max viol: 1.7789605607977137 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28241094946861267, valid regret : -0.2818443775177002 \n",
      "---------------------------------------iteration: 1879\n",
      "l1 decision: 0.09022224694490433\n",
      "l1 weight: 0.14752836525440216\n",
      "avg viol: 1.7916948046709877, max viol: 1.80205643188674 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29423853754997253, valid regret : -0.2874765992164612 \n",
      "---------------------------------------iteration: 1880\n",
      "l1 decision: 0.08929892629384995\n",
      "l1 weight: 0.14795446395874023\n",
      "avg viol: 1.7817749361716961, max viol: 1.8038218831643462 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2822456657886505, valid regret : -0.27727627754211426 \n",
      "---------------------------------------iteration: 1881\n",
      "l1 decision: 0.08976048976182938\n",
      "l1 weight: 0.14819839596748352\n",
      "avg viol: 1.7815663403074722, max viol: 1.7980648529483005 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2736872434616089, valid regret : -0.27687060832977295 \n",
      "---------------------------------------iteration: 1882\n",
      "l1 decision: 0.08834382146596909\n",
      "l1 weight: 0.14824722707271576\n",
      "avg viol: 1.7657160557503813, max viol: 1.7848847890272737 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28280994296073914, valid regret : -0.285983145236969 \n",
      "---------------------------------------iteration: 1883\n",
      "l1 decision: 0.09022604674100876\n",
      "l1 weight: 0.1486825942993164\n",
      "avg viol: 1.7814131519844523, max viol: 1.7994341026060283 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2851596474647522, valid regret : -0.2713819146156311 \n",
      "---------------------------------------iteration: 1884\n",
      "l1 decision: 0.08819027990102768\n",
      "l1 weight: 0.14774486422538757\n",
      "avg viol: 1.7631638804113026, max viol: 1.786572812590748 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2741551697254181, valid regret : -0.2825027406215668 \n",
      "---------------------------------------iteration: 1885\n",
      "l1 decision: 0.09025967121124268\n",
      "l1 weight: 0.14865459501743317\n",
      "avg viol: 1.7934199995390372, max viol: 1.8023607805371284 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2893151342868805, valid regret : -0.28541040420532227 \n",
      "---------------------------------------iteration: 1886\n",
      "l1 decision: 0.08918257802724838\n",
      "l1 weight: 0.15039169788360596\n",
      "avg viol: 1.7804292151116534, max viol: 1.79707459686324 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28174132108688354, valid regret : -0.2745557427406311 \n",
      "---------------------------------------iteration: 1887\n",
      "l1 decision: 0.09008610993623734\n",
      "l1 weight: 0.15150606632232666\n",
      "avg viol: 1.773678638843121, max viol: 1.7912853749003261 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2662440836429596, valid regret : -0.27089476585388184 \n",
      "---------------------------------------iteration: 1888\n",
      "l1 decision: 0.08746606111526489\n",
      "l1 weight: 0.14761072397232056\n",
      "avg viol: 1.75039377478417, max viol: 1.7718823157483712 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2779860198497772, valid regret : -0.28582480549812317 \n",
      "---------------------------------------iteration: 1889\n",
      "l1 decision: 0.08958777040243149\n",
      "l1 weight: 0.1481981724500656\n",
      "avg viol: 1.7814198480907362, max viol: 1.8005609540268779 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28061336278915405, valid regret : -0.2767219841480255 \n",
      "---------------------------------------iteration: 1890\n",
      "l1 decision: 0.08942274749279022\n",
      "l1 weight: 0.14902742207050323\n",
      "avg viol: 1.7851626616598515, max viol: 1.8018262793775648 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2908577620983124, valid regret : -0.28255581855773926 \n",
      "---------------------------------------iteration: 1891\n",
      "l1 decision: 0.09099508821964264\n",
      "l1 weight: 0.147689089179039\n",
      "avg viol: 1.7898942069336772, max viol: 1.8035874487832189 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29433801770210266, valid regret : -0.2823188602924347 \n",
      "---------------------------------------iteration: 1892\n",
      "l1 decision: 0.0883883461356163\n",
      "l1 weight: 0.14771121740341187\n",
      "avg viol: 1.7667681497969898, max viol: 1.7890595177887008 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2772669494152069, valid regret : -0.2772505581378937 \n",
      "---------------------------------------iteration: 1893\n",
      "l1 decision: 0.089803047478199\n",
      "l1 weight: 0.1479678601026535\n",
      "avg viol: 1.7849294172029477, max viol: 1.7996076045092195 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2748114764690399, valid regret : -0.2795225977897644 \n",
      "---------------------------------------iteration: 1894\n",
      "l1 decision: 0.08846425265073776\n",
      "l1 weight: 0.14804109930992126\n",
      "avg viol: 1.7680256730528345, max viol: 1.7920845365151763 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28377804160118103, valid regret : -0.28479039669036865 \n",
      "---------------------------------------iteration: 1895\n",
      "l1 decision: 0.09043729305267334\n",
      "l1 weight: 0.14833855628967285\n",
      "avg viol: 1.7785568159271496, max viol: 1.7925764010287821 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2838422656059265, valid regret : -0.2702866196632385 \n",
      "---------------------------------------iteration: 1896\n",
      "l1 decision: 0.08839455246925354\n",
      "l1 weight: 0.14748749136924744\n",
      "avg viol: 1.7671817685780116, max viol: 1.7818204200593755 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27428188920021057, valid regret : -0.2787603735923767 \n",
      "---------------------------------------iteration: 1897\n",
      "l1 decision: 0.08960671722888947\n",
      "l1 weight: 0.14943744242191315\n",
      "avg viol: 1.7759942075109576, max viol: 1.7954999534413218 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28374341130256653, valid regret : -0.28313517570495605 \n",
      "---------------------------------------iteration: 1898\n",
      "l1 decision: 0.08889185637235641\n",
      "l1 weight: 0.15037740767002106\n",
      "avg viol: 1.7741140991323483, max viol: 1.788204612210393 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27972209453582764, valid regret : -0.2745232880115509 \n",
      "---------------------------------------iteration: 1899\n",
      "l1 decision: 0.08939634263515472\n",
      "l1 weight: 0.15041443705558777\n",
      "avg viol: 1.780813530040905, max viol: 1.794222094467841 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.268001526594162, valid regret : -0.27574121952056885 \n",
      "---------------------------------------iteration: 1900\n",
      "l1 decision: 0.08832212537527084\n",
      "l1 weight: 0.14758600294589996\n",
      "avg viol: 1.7647615928726736, max viol: 1.7827692292630672 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2835122048854828, valid regret : -0.2858870029449463 \n",
      "---------------------------------------iteration: 1901\n",
      "l1 decision: 0.08966498076915741\n",
      "l1 weight: 0.1484719216823578\n",
      "avg viol: 1.7796391296410001, max viol: 1.7964997807284817 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2793072760105133, valid regret : -0.27292904257774353 \n",
      "---------------------------------------iteration: 1902\n",
      "l1 decision: 0.08851820975542068\n",
      "l1 weight: 0.14900654554367065\n",
      "avg viol: 1.7699856946949148, max viol: 1.7876402356196195 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28602930903434753, valid regret : -0.2811148762702942 \n",
      "---------------------------------------iteration: 1903\n",
      "l1 decision: 0.08975546061992645\n",
      "l1 weight: 0.14788192510604858\n",
      "avg viol: 1.7814086281257915, max viol: 1.7947153230197728 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29262280464172363, valid regret : -0.2848161458969116 \n",
      "---------------------------------------iteration: 1904\n",
      "l1 decision: 0.08939870446920395\n",
      "l1 weight: 0.14680519700050354\n",
      "avg viol: 1.7787350727860394, max viol: 1.7964685870101675 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28034037351608276, valid regret : -0.2754051685333252 \n",
      "---------------------------------------iteration: 1905\n",
      "l1 decision: 0.08923130482435226\n",
      "l1 weight: 0.14795421063899994\n",
      "avg viol: 1.775975573308533, max viol: 1.7940256732981652 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27260974049568176, valid regret : -0.2760058343410492 \n",
      "---------------------------------------iteration: 1906\n",
      "l1 decision: 0.08871044218540192\n",
      "l1 weight: 0.14789116382598877\n",
      "avg viol: 1.7660663189447952, max viol: 1.783355372492224 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28100547194480896, valid regret : -0.2863776385784149 \n",
      "---------------------------------------iteration: 1907\n",
      "l1 decision: 0.08964031934738159\n",
      "l1 weight: 0.1483648121356964\n",
      "avg viol: 1.7856162778253202, max viol: 1.797396313631907 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2870873510837555, valid regret : -0.27570754289627075 \n",
      "---------------------------------------iteration: 1908\n",
      "l1 decision: 0.08968782424926758\n",
      "l1 weight: 0.14804905652999878\n",
      "avg viol: 1.7772482300395496, max viol: 1.7982343907351606 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2763417661190033, valid regret : -0.2808607816696167 \n",
      "---------------------------------------iteration: 1909\n",
      "l1 decision: 0.08941489458084106\n",
      "l1 weight: 0.14989833533763885\n",
      "avg viol: 1.7804774132341845, max viol: 1.796836657449603 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2866694927215576, valid regret : -0.2775048315525055 \n",
      "---------------------------------------iteration: 1910\n",
      "l1 decision: 0.08798807859420776\n",
      "l1 weight: 0.15034601092338562\n",
      "avg viol: 1.759927312382497, max viol: 1.7791479236911982 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.274927020072937, valid regret : -0.27733421325683594 \n",
      "---------------------------------------iteration: 1911\n",
      "l1 decision: 0.08983166515827179\n",
      "l1 weight: 0.15085825324058533\n",
      "avg viol: 1.7864626667962875, max viol: 1.8033964410424232 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2697754502296448, valid regret : -0.28081849217414856 \n",
      "---------------------------------------iteration: 1912\n",
      "l1 decision: 0.0887603759765625\n",
      "l1 weight: 0.14858600497245789\n",
      "avg viol: 1.7749419915798352, max viol: 1.800184486724902 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2880041003227234, valid regret : -0.2845596373081207 \n",
      "---------------------------------------iteration: 1913\n",
      "l1 decision: 0.09096348285675049\n",
      "l1 weight: 0.14803914725780487\n",
      "avg viol: 1.7823691791959573, max viol: 1.795111234067008 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27997511625289917, valid regret : -0.26400864124298096 \n",
      "---------------------------------------iteration: 1914\n",
      "l1 decision: 0.08755595237016678\n",
      "l1 weight: 0.1491093784570694\n",
      "avg viol: 1.750135282871779, max viol: 1.7662678400520235 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27685704827308655, valid regret : -0.27769404649734497 \n",
      "---------------------------------------iteration: 1915\n",
      "l1 decision: 0.0892411395907402\n",
      "l1 weight: 0.14732478559017181\n",
      "avg viol: 1.7798767682386096, max viol: 1.7906125677982345 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29098427295684814, valid regret : -0.28736886382102966 \n",
      "---------------------------------------iteration: 1916\n",
      "l1 decision: 0.08960862457752228\n",
      "l1 weight: 0.14722001552581787\n",
      "avg viol: 1.7845048704707733, max viol: 1.804875339497812 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28154757618904114, valid regret : -0.27748745679855347 \n",
      "---------------------------------------iteration: 1917\n",
      "l1 decision: 0.08982027322053909\n",
      "l1 weight: 0.14784032106399536\n",
      "avg viol: 1.7840013106982224, max viol: 1.7992086943704635 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2748110294342041, valid regret : -0.2764478921890259 \n",
      "---------------------------------------iteration: 1918\n",
      "l1 decision: 0.08833223581314087\n",
      "l1 weight: 0.14785082638263702\n",
      "avg viol: 1.7657292148692068, max viol: 1.784988924395293 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28291866183280945, valid regret : -0.2863074243068695 \n",
      "---------------------------------------iteration: 1919\n",
      "l1 decision: 0.09019529074430466\n",
      "l1 weight: 0.1492031216621399\n",
      "avg viol: 1.7825320131913758, max viol: 1.7983685862272978 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2857682704925537, valid regret : -0.27245551347732544 \n",
      "---------------------------------------iteration: 1920\n",
      "l1 decision: 0.08825524896383286\n",
      "l1 weight: 0.14838282763957977\n",
      "avg viol: 1.7654445553343248, max viol: 1.7876866615843028 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2745814621448517, valid regret : -0.2819647192955017 \n",
      "---------------------------------------iteration: 1921\n",
      "l1 decision: 0.0897500291466713\n",
      "l1 weight: 0.14953865110874176\n",
      "avg viol: 1.787991699638078, max viol: 1.804618892725557 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2881959080696106, valid regret : -0.28771844506263733 \n",
      "---------------------------------------iteration: 1922\n",
      "l1 decision: 0.08939146250486374\n",
      "l1 weight: 0.15063057839870453\n",
      "avg viol: 1.7840860781825358, max viol: 1.8032034903299063 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2835724949836731, valid regret : -0.27763739228248596 \n",
      "---------------------------------------iteration: 1923\n",
      "l1 decision: 0.08976435661315918\n",
      "l1 weight: 0.15142449736595154\n",
      "avg viol: 1.7795875841597444, max viol: 1.7995183003367856 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2683553993701935, valid regret : -0.2753397226333618 \n",
      "---------------------------------------iteration: 1924\n",
      "l1 decision: 0.08797794580459595\n",
      "l1 weight: 0.14908088743686676\n",
      "avg viol: 1.7589047029730864, max viol: 1.7819587838603184 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2816585302352905, valid regret : -0.2875969111919403 \n",
      "---------------------------------------iteration: 1925\n",
      "l1 decision: 0.09002280980348587\n",
      "l1 weight: 0.14852504432201385\n",
      "avg viol: 1.7841628643509466, max viol: 1.8022658257978037 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28168484568595886, valid regret : -0.27241599559783936 \n",
      "---------------------------------------iteration: 1926\n",
      "l1 decision: 0.08855441212654114\n",
      "l1 weight: 0.14913266897201538\n",
      "avg viol: 1.7700158590089996, max viol: 1.7873770205769688 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2857007086277008, valid regret : -0.28230586647987366 \n",
      "---------------------------------------iteration: 1927\n",
      "l1 decision: 0.09067840874195099\n",
      "l1 weight: 0.14753377437591553\n",
      "avg viol: 1.7923413285054266, max viol: 1.8040156282950193 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29464074969291687, valid regret : -0.2855900526046753 \n",
      "---------------------------------------iteration: 1928\n",
      "l1 decision: 0.08888303488492966\n",
      "l1 weight: 0.147492915391922\n",
      "avg viol: 1.7763478005841171, max viol: 1.7963472975534387 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28129544854164124, valid regret : -0.27747565507888794 \n",
      "---------------------------------------iteration: 1929\n",
      "l1 decision: 0.09045924991369247\n",
      "l1 weight: 0.14799651503562927\n",
      "avg viol: 1.7870688807440456, max viol: 1.8034106632694602 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27469170093536377, valid regret : -0.27669453620910645 \n",
      "---------------------------------------iteration: 1930\n",
      "l1 decision: 0.0885186567902565\n",
      "l1 weight: 0.147969588637352\n",
      "avg viol: 1.7696760410413845, max viol: 1.7889624699018896 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28336048126220703, valid regret : -0.28673461079597473 \n",
      "---------------------------------------iteration: 1931\n",
      "l1 decision: 0.09036983549594879\n",
      "l1 weight: 0.14898791909217834\n",
      "avg viol: 1.789907614677213, max viol: 1.80387297202833 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2877787947654724, valid regret : -0.27587851881980896 \n",
      "---------------------------------------iteration: 1932\n",
      "l1 decision: 0.08908423781394958\n",
      "l1 weight: 0.14762276411056519\n",
      "avg viol: 1.780485277750995, max viol: 1.7984960027970374 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2793080806732178, valid regret : -0.28155720233917236 \n",
      "---------------------------------------iteration: 1933\n",
      "l1 decision: 0.09048224985599518\n",
      "l1 weight: 0.14877401292324066\n",
      "avg viol: 1.7900097432118491, max viol: 1.802760479040444 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2878345251083374, valid regret : -0.2817364037036896 \n",
      "---------------------------------------iteration: 1934\n",
      "l1 decision: 0.08848841488361359\n",
      "l1 weight: 0.15025611221790314\n",
      "avg viol: 1.769062446340431, max viol: 1.7863661652663723 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27870050072669983, valid regret : -0.2766132056713104 \n",
      "---------------------------------------iteration: 1935\n",
      "l1 decision: 0.08986897021532059\n",
      "l1 weight: 0.1520271748304367\n",
      "avg viol: 1.7777661922876724, max viol: 1.7977358526550233 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2674270570278168, valid regret : -0.27804437279701233 \n",
      "---------------------------------------iteration: 1936\n",
      "l1 decision: 0.08827218413352966\n",
      "l1 weight: 0.14840160310268402\n",
      "avg viol: 1.7650288889434886, max viol: 1.7881381730549037 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.285572350025177, valid regret : -0.28589770197868347 \n",
      "---------------------------------------iteration: 1937\n",
      "l1 decision: 0.09046793729066849\n",
      "l1 weight: 0.1488805115222931\n",
      "avg viol: 1.7829607930791098, max viol: 1.7979381335899234 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2806043028831482, valid regret : -0.27038994431495667 \n",
      "---------------------------------------iteration: 1938\n",
      "l1 decision: 0.08826036751270294\n",
      "l1 weight: 0.14952366054058075\n",
      "avg viol: 1.7649968691449613, max viol: 1.782614670228213 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.283274382352829, valid regret : -0.27909335494041443 \n",
      "---------------------------------------iteration: 1939\n",
      "l1 decision: 0.09031392633914948\n",
      "l1 weight: 0.14705097675323486\n",
      "avg viol: 1.787228427445516, max viol: 1.7957525681704283 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29317817091941833, valid regret : -0.2859150171279907 \n",
      "---------------------------------------iteration: 1940\n",
      "l1 decision: 0.08911386877298355\n",
      "l1 weight: 0.1470741629600525\n",
      "avg viol: 1.7762142726550518, max viol: 1.8002669636625797 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2798023819923401, valid regret : -0.27651169896125793 \n",
      "---------------------------------------iteration: 1941\n",
      "l1 decision: 0.0893530398607254\n",
      "l1 weight: 0.14836911857128143\n",
      "avg viol: 1.777841108610155, max viol: 1.7941285339184105 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2729928493499756, valid regret : -0.272250235080719 \n",
      "---------------------------------------iteration: 1942\n",
      "l1 decision: 0.08803923428058624\n",
      "l1 weight: 0.14830425381660461\n",
      "avg viol: 1.7588484511041316, max viol: 1.7773987812688574 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2777116000652313, valid regret : -0.2840985357761383 \n",
      "---------------------------------------iteration: 1943\n",
      "l1 decision: 0.08890079706907272\n",
      "l1 weight: 0.14905136823654175\n",
      "avg viol: 1.773516009519226, max viol: 1.7921951680909842 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28286856412887573, valid regret : -0.276945024728775 \n",
      "---------------------------------------iteration: 1944\n",
      "l1 decision: 0.08980157226324081\n",
      "l1 weight: 0.14724062383174896\n",
      "avg viol: 1.7890080868507174, max viol: 1.8024776293896139 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2808596193790436, valid regret : -0.28238531947135925 \n",
      "---------------------------------------iteration: 1945\n",
      "l1 decision: 0.08993527293205261\n",
      "l1 weight: 0.14902754127979279\n",
      "avg viol: 1.7891883347381372, max viol: 1.7997923633083701 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28941231966018677, valid regret : -0.28508174419403076 \n",
      "---------------------------------------iteration: 1946\n",
      "l1 decision: 0.08910574018955231\n",
      "l1 weight: 0.15070077776908875\n",
      "avg viol: 1.7809358189492923, max viol: 1.800104424735764 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28223803639411926, valid regret : -0.2754565477371216 \n",
      "---------------------------------------iteration: 1947\n",
      "l1 decision: 0.0899265930056572\n",
      "l1 weight: 0.15181328356266022\n",
      "avg viol: 1.775066952992929, max viol: 1.7912436430342495 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26712146401405334, valid regret : -0.27320101857185364 \n",
      "---------------------------------------iteration: 1948\n",
      "l1 decision: 0.08758513629436493\n",
      "l1 weight: 0.1482769399881363\n",
      "avg viol: 1.7527935701282695, max viol: 1.7719883364625275 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2802046835422516, valid regret : -0.28643831610679626 \n",
      "---------------------------------------iteration: 1949\n",
      "l1 decision: 0.09023945778608322\n",
      "l1 weight: 0.14808562397956848\n",
      "avg viol: 1.787994238769752, max viol: 1.802382406196557 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2818965017795563, valid regret : -0.27758878469467163 \n",
      "---------------------------------------iteration: 1950\n",
      "l1 decision: 0.08953391760587692\n",
      "l1 weight: 0.14902234077453613\n",
      "avg viol: 1.787088959766843, max viol: 1.8034121236996725 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29126617312431335, valid regret : -0.28224092721939087 \n",
      "---------------------------------------iteration: 1951\n",
      "l1 decision: 0.09038179367780685\n",
      "l1 weight: 0.14754445850849152\n",
      "avg viol: 1.7910891872918, max viol: 1.8008141294121742 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29504841566085815, valid regret : -0.2852414548397064 \n",
      "---------------------------------------iteration: 1952\n",
      "l1 decision: 0.08893119543790817\n",
      "l1 weight: 0.1478910893201828\n",
      "avg viol: 1.7768195875824313, max viol: 1.7971795261837542 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27976471185684204, valid regret : -0.2760383188724518 \n",
      "---------------------------------------iteration: 1953\n",
      "l1 decision: 0.0895019918680191\n",
      "l1 weight: 0.14821037650108337\n",
      "avg viol: 1.7810292257066067, max viol: 1.7978356520761736 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2733905613422394, valid regret : -0.2823868691921234 \n",
      "---------------------------------------iteration: 1954\n",
      "l1 decision: 0.08971958607435226\n",
      "l1 weight: 0.14794333279132843\n",
      "avg viol: 1.7863711708743357, max viol: 1.8012064752401784 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.287604421377182, valid regret : -0.2818932831287384 \n",
      "---------------------------------------iteration: 1955\n",
      "l1 decision: 0.08871258795261383\n",
      "l1 weight: 0.14861635863780975\n",
      "avg viol: 1.771538204656681, max viol: 1.7859816220588982 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2827960252761841, valid regret : -0.27499040961265564 \n",
      "---------------------------------------iteration: 1956\n",
      "l1 decision: 0.08994966745376587\n",
      "l1 weight: 0.1479261815547943\n",
      "avg viol: 1.7743231556675163, max viol: 1.7928999742725864 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27521374821662903, valid regret : -0.2764222323894501 \n",
      "---------------------------------------iteration: 1957\n",
      "l1 decision: 0.08796780556440353\n",
      "l1 weight: 0.14822879433631897\n",
      "avg viol: 1.7588115975499385, max viol: 1.7812177075538784 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2819286584854126, valid regret : -0.28677594661712646 \n",
      "---------------------------------------iteration: 1958\n",
      "l1 decision: 0.09019344300031662\n",
      "l1 weight: 0.15061134099960327\n",
      "avg viol: 1.7889939213189063, max viol: 1.8014518914278597 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2840850353240967, valid regret : -0.278097003698349 \n",
      "---------------------------------------iteration: 1959\n",
      "l1 decision: 0.08957374840974808\n",
      "l1 weight: 0.15104074776172638\n",
      "avg viol: 1.7869651889212037, max viol: 1.8042874694801867 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2711910903453827, valid regret : -0.2824214994907379 \n",
      "---------------------------------------iteration: 1960\n",
      "l1 decision: 0.08963137120008469\n",
      "l1 weight: 0.14866280555725098\n",
      "avg viol: 1.784786482203126, max viol: 1.8032328620320186 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.29025232791900635, valid regret : -0.28759264945983887 \n",
      "---------------------------------------iteration: 1961\n",
      "l1 decision: 0.08955124020576477\n",
      "l1 weight: 0.14846061170101166\n",
      "avg viol: 1.7830800395284678, max viol: 1.8019258161075413 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28145909309387207, valid regret : -0.27746301889419556 \n",
      "---------------------------------------iteration: 1962\n",
      "l1 decision: 0.0892685204744339\n",
      "l1 weight: 0.14941763877868652\n",
      "avg viol: 1.7796117824537578, max viol: 1.7983692830894142 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28889304399490356, valid regret : -0.28109505772590637 \n",
      "---------------------------------------iteration: 1963\n",
      "l1 decision: 0.09002953767776489\n",
      "l1 weight: 0.1473826766014099\n",
      "avg viol: 1.7897356297977967, max viol: 1.8008494885871187 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2944023609161377, valid regret : -0.28505048155784607 \n",
      "---------------------------------------iteration: 1964\n",
      "l1 decision: 0.08917815238237381\n",
      "l1 weight: 0.14709702134132385\n",
      "avg viol: 1.776454473455815, max viol: 1.7941882556769997 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2803802192211151, valid regret : -0.27810442447662354 \n",
      "---------------------------------------iteration: 1965\n",
      "l1 decision: 0.08981576561927795\n",
      "l1 weight: 0.14740414917469025\n",
      "avg viol: 1.7870383373106598, max viol: 1.8035780865466222 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27412793040275574, valid regret : -0.28053951263427734 \n",
      "---------------------------------------iteration: 1966\n",
      "l1 decision: 0.0888056829571724\n",
      "l1 weight: 0.14819467067718506\n",
      "avg viol: 1.7738223092046064, max viol: 1.7912178871920332 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28584209084510803, valid regret : -0.28620803356170654 \n",
      "---------------------------------------iteration: 1967\n",
      "l1 decision: 0.09037858992815018\n",
      "l1 weight: 0.1489029973745346\n",
      "avg viol: 1.7843151322973427, max viol: 1.8012691647745669 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28599393367767334, valid regret : -0.27390256524086 \n",
      "---------------------------------------iteration: 1968\n",
      "l1 decision: 0.08847107738256454\n",
      "l1 weight: 0.14795908331871033\n",
      "avg viol: 1.7694184668151138, max viol: 1.7920688966842135 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27599650621414185, valid regret : -0.2822876274585724 \n",
      "---------------------------------------iteration: 1969\n",
      "l1 decision: 0.09002279490232468\n",
      "l1 weight: 0.1489260047674179\n",
      "avg viol: 1.7901641390303848, max viol: 1.806350269005634 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.288075715303421, valid regret : -0.28637370467185974 \n",
      "---------------------------------------iteration: 1970\n",
      "l1 decision: 0.08929268270730972\n",
      "l1 weight: 0.15034878253936768\n",
      "avg viol: 1.783661606001442, max viol: 1.8008658275939524 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28386738896369934, valid regret : -0.27447375655174255 \n",
      "---------------------------------------iteration: 1971\n",
      "l1 decision: 0.08992432802915573\n",
      "l1 weight: 0.15115751326084137\n",
      "avg viol: 1.7710895859077573, max viol: 1.788469392224215 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2652190327644348, valid regret : -0.2735889256000519 \n",
      "---------------------------------------iteration: 1972\n",
      "l1 decision: 0.08802831172943115\n",
      "l1 weight: 0.1492062509059906\n",
      "avg viol: 1.758554280733224, max viol: 1.776996117318049 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28103840351104736, valid regret : -0.2866559624671936 \n",
      "---------------------------------------iteration: 1973\n",
      "l1 decision: 0.08949678391218185\n",
      "l1 weight: 0.14807583391666412\n",
      "avg viol: 1.7827354471944272, max viol: 1.8023794709006324 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.280706524848938, valid regret : -0.27845486998558044 \n",
      "---------------------------------------iteration: 1974\n",
      "l1 decision: 0.08926940709352493\n",
      "l1 weight: 0.14908644556999207\n",
      "avg viol: 1.7834200056167537, max viol: 1.8034481630893424 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2901131808757782, valid regret : -0.28445538878440857 \n",
      "---------------------------------------iteration: 1975\n",
      "l1 decision: 0.0903455913066864\n",
      "l1 weight: 0.1480010747909546\n",
      "avg viol: 1.7931602306940477, max viol: 1.805209997924976 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2954826056957245, valid regret : -0.28634998202323914 \n",
      "---------------------------------------iteration: 1976\n",
      "l1 decision: 0.08935360610485077\n",
      "l1 weight: 0.14670826494693756\n",
      "avg viol: 1.7826357489398288, max viol: 1.8025216927053407 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2820722758769989, valid regret : -0.2772940695285797 \n",
      "---------------------------------------iteration: 1977\n",
      "l1 decision: 0.08975259214639664\n",
      "l1 weight: 0.14796580374240875\n",
      "avg viol: 1.7805007348797517, max viol: 1.7974158071447164 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2735854983329773, valid regret : -0.27626994252204895 \n",
      "---------------------------------------iteration: 1978\n",
      "l1 decision: 0.08815309405326843\n",
      "l1 weight: 0.1474016010761261\n",
      "avg viol: 1.7624153522122652, max viol: 1.7808829174609855 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28148797154426575, valid regret : -0.28659066557884216 \n",
      "---------------------------------------iteration: 1979\n",
      "l1 decision: 0.09019085764884949\n",
      "l1 weight: 0.1491130143404007\n",
      "avg viol: 1.7855485435709124, max viol: 1.801211719866842 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.285945862531662, valid regret : -0.2726084291934967 \n",
      "---------------------------------------iteration: 1980\n",
      "l1 decision: 0.08838921785354614\n",
      "l1 weight: 0.14714880287647247\n",
      "avg viol: 1.7673547779663932, max viol: 1.7873658232856542 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27548161149024963, valid regret : -0.28366246819496155 \n",
      "---------------------------------------iteration: 1981\n",
      "l1 decision: 0.08988496661186218\n",
      "l1 weight: 0.1489807665348053\n",
      "avg viol: 1.7873583974369103, max viol: 1.805061249411665 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.287102609872818, valid regret : -0.2847592830657959 \n",
      "---------------------------------------iteration: 1982\n",
      "l1 decision: 0.08901563286781311\n",
      "l1 weight: 0.1505201756954193\n",
      "avg viol: 1.779624072959996, max viol: 1.7939163889968768 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2817186415195465, valid regret : -0.2761509418487549 \n",
      "---------------------------------------iteration: 1983\n",
      "l1 decision: 0.09033326059579849\n",
      "l1 weight: 0.1514776349067688\n",
      "avg viol: 1.7801068909245077, max viol: 1.7961739010643214 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26836520433425903, valid regret : -0.27497947216033936 \n",
      "---------------------------------------iteration: 1984\n",
      "l1 decision: 0.08810435980558395\n",
      "l1 weight: 0.14908182621002197\n",
      "avg viol: 1.76225665866863, max viol: 1.7791682772804052 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2830123007297516, valid regret : -0.2869372069835663 \n",
      "---------------------------------------iteration: 1985\n",
      "l1 decision: 0.08968155831098557\n",
      "l1 weight: 0.14852671325206757\n",
      "avg viol: 1.783390096607036, max viol: 1.8027108514215797 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28120461106300354, valid regret : -0.27840203046798706 \n",
      "---------------------------------------iteration: 1986\n",
      "l1 decision: 0.08924395591020584\n",
      "l1 weight: 0.14975935220718384\n",
      "avg viol: 1.7820495847810163, max viol: 1.8052496003219858 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28964972496032715, valid regret : -0.28474363684654236 \n",
      "---------------------------------------iteration: 1987\n",
      "l1 decision: 0.0901295468211174\n",
      "l1 weight: 0.14799150824546814\n",
      "avg viol: 1.7925462001411325, max viol: 1.8053425842663273 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.296145498752594, valid regret : -0.28702038526535034 \n",
      "---------------------------------------iteration: 1988\n",
      "l1 decision: 0.08989796787500381\n",
      "l1 weight: 0.14705048501491547\n",
      "avg viol: 1.7895605641353176, max viol: 1.8013776817824692 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2831135392189026, valid regret : -0.2757486402988434 \n",
      "---------------------------------------iteration: 1989\n",
      "l1 decision: 0.08910877257585526\n",
      "l1 weight: 0.14797650277614594\n",
      "avg viol: 1.7771251394590946, max viol: 1.7952042599208653 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.272746741771698, valid regret : -0.28206026554107666 \n",
      "---------------------------------------iteration: 1990\n",
      "l1 decision: 0.08990871161222458\n",
      "l1 weight: 0.14821265637874603\n",
      "avg viol: 1.7876933382591234, max viol: 1.7996072734240443 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28827303647994995, valid regret : -0.28158652782440186 \n",
      "---------------------------------------iteration: 1991\n",
      "l1 decision: 0.08856537938117981\n",
      "l1 weight: 0.14847543835639954\n",
      "avg viol: 1.7703445374791045, max viol: 1.7858770091552287 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28235408663749695, valid regret : -0.2773967981338501 \n",
      "---------------------------------------iteration: 1992\n",
      "l1 decision: 0.09006300568580627\n",
      "l1 weight: 0.14795321226119995\n",
      "avg viol: 1.7829656431323384, max viol: 1.8002241337671876 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.27862313389778137, valid regret : -0.2751104235649109 \n",
      "---------------------------------------iteration: 1993\n",
      "l1 decision: 0.0877009704709053\n",
      "l1 weight: 0.14938054978847504\n",
      "avg viol: 1.7544709389959463, max viol: 1.7816415767883882 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2777903378009796, valid regret : -0.28766509890556335 \n",
      "---------------------------------------iteration: 1994\n",
      "l1 decision: 0.09003659337759018\n",
      "l1 weight: 0.15071623027324677\n",
      "avg viol: 1.7892528039508033, max viol: 1.8025184986181557 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2841029465198517, valid regret : -0.27840253710746765 \n",
      "---------------------------------------iteration: 1995\n",
      "l1 decision: 0.08919961750507355\n",
      "l1 weight: 0.15090449154376984\n",
      "avg viol: 1.7806671022154297, max viol: 1.8049003493506461 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.26923346519470215, valid regret : -0.28285786509513855 \n",
      "---------------------------------------iteration: 1996\n",
      "l1 decision: 0.08963818103075027\n",
      "l1 weight: 0.14918196201324463\n",
      "avg viol: 1.785303988982796, max viol: 1.8016916809719987 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2905608117580414, valid regret : -0.28775185346603394 \n",
      "---------------------------------------iteration: 1997\n",
      "l1 decision: 0.0896776020526886\n",
      "l1 weight: 0.149028018116951\n",
      "avg viol: 1.7859117835990037, max viol: 1.8037337473360822 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28289639949798584, valid regret : -0.27643635869026184 \n",
      "---------------------------------------iteration: 1998\n",
      "l1 decision: 0.08937499672174454\n",
      "l1 weight: 0.1492420881986618\n",
      "avg viol: 1.782169492665107, max viol: 1.7968870354816318 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.28939589858055115, valid regret : -0.2827848494052887 \n",
      "---------------------------------------iteration: 1999\n",
      "l1 decision: 0.09029795229434967\n",
      "l1 weight: 0.14759260416030884\n",
      "avg viol: 1.7937481920293066, max viol: 1.804063809569925 \n",
      "eval----------\n",
      "eval done------\n",
      "train regret : -0.2958691418170929, valid regret : -0.28406262397766113 \n",
      "Finished Training\n",
      "number of infeasible solutions:  0\n",
      "CPU times: total: 15min 27s\n",
      "Wall time: 12min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "patience = 130\n",
    "#best_model = copy.deepcopy(pred_Net)\n",
    "fails = 0\n",
    "flag = False\n",
    "best = 1000\n",
    "\n",
    "infeasible_count = 0\n",
    "\n",
    "l1_error_weight_pred = [] # this is to compare distro of predicted arc weights and actual arc weights\n",
    "l2_error_weight_pred = []\n",
    "\n",
    "avg_constraint_viol_perbatch = []\n",
    "max_constraint_viol_perbatch = []\n",
    "\n",
    "#avg_constraint_viol_cvxpy = []\n",
    "#max_constraint_viol_cvxpy = []\n",
    "\n",
    "train_loss = [] \n",
    "val_loss = []\n",
    "\n",
    "train_regret = []\n",
    "val_regret_lst = []\n",
    "\n",
    "l1_error_decision_pred = []\n",
    "l2_error_decision_pred = []\n",
    "\n",
    "\n",
    "l1_loss_weight = nn.L1Loss()\n",
    "l1_loss_decision = nn.L1Loss()\n",
    "\n",
    "l2_loss_weight = nn.MSELoss()\n",
    "l2_loss_decision = nn.MSELoss()\n",
    "\n",
    "\n",
    "A = inci_matrix\n",
    "\n",
    "\n",
    "model_load = torch.load('shortest_path_proxy_{}.model'.format('L1'))\n",
    "\n",
    "\n",
    "\n",
    "train_iterator = itertools.cycle(train_dl)\n",
    "\n",
    "val_iter = itertools.cycle(val_dl)\n",
    "\n",
    "\n",
    "for iterations in range(0, params['iterations']):\n",
    "  # loop over the dataset multiple times\n",
    "  print(\"---------------------------------------iteration: {}\".format(iterations))\n",
    "  #running_loss = 0.0\n",
    "  #running_viol = 0.0\n",
    "  #stime = time.time()\n",
    "  model.train()\n",
    "  data = next(iter(train_iterator))\n",
    "  inputs, targets  = data\n",
    "  linear_layer_output = torch.nn.functional.normalize(model(inputs))\n",
    "  #print(linear_layer_output[0])\n",
    "  with torch.no_grad():\n",
    "    \n",
    "    selected_edges = model_load(linear_layer_output)  \n",
    "    #print(selected_edges[0])\n",
    "    #print(\"cvxpy\")   \n",
    "    #selected_edges_targets = cvx_py(A,linear_layer_output)\n",
    "    \n",
    "    try:\n",
    "      selected_edges_targets = cvx_py(A,linear_layer_output)\n",
    "    except:\n",
    "      print(\"iteration {} produced infeasible solution\".format(iterations))\n",
    "      #file = open('infeasible.pkl', 'wb')\n",
    "      # dump information to the file\n",
    "      #pickle.dump([linear_layer_output], file)\n",
    "      infeasible_count += 1\n",
    "      break\n",
    "      \n",
    "      #continue  \n",
    "    \n",
    "    l1_decision_value = l1_loss_decision(selected_edges,selected_edges_targets)\n",
    "    l2_decision_value = l2_loss_decision(selected_edges,selected_edges_targets)\n",
    "    l1_weight_value = l1_loss_weight(linear_layer_output,targets)\n",
    "    l2_weight_value = l2_loss_weight(linear_layer_output,targets)\n",
    "        \n",
    "    l1_error_decision_pred.append(l1_decision_value)\n",
    "    l2_error_decision_pred.append(l2_decision_value)\n",
    "    l1_error_weight_pred.append(l1_weight_value)\n",
    "    l2_error_weight_pred.append(l2_weight_value)\n",
    "    \n",
    "    print(\"l1 decision: {}\".format(l1_decision_value.item()))\n",
    "    print(\"l1 weight: {}\".format(l1_weight_value.item()))\n",
    "    \n",
    "    max_viol_perbatch ,avg_viol_perbatch = calc_violations(A,selected_edges)\n",
    "    max_constraint_viol_perbatch.append(max_viol_perbatch)\n",
    "    avg_constraint_viol_perbatch.append(avg_viol_perbatch)\n",
    "    \n",
    "    #max_viol_cvx, avg_viol_cvx = calc_violations(A,selected_edges_targets)\n",
    "    #max_constraint_viol_cvxpy.append(max_viol_cvx)\n",
    "    #avg_constraint_viol_cvxpy.append(avg_viol_cvx)\n",
    "    \n",
    "    print(\"avg viol: {}, max viol: {} \".format(avg_viol_perbatch, max_viol_perbatch))\n",
    "    \n",
    "      \n",
    "      \n",
    "              \n",
    "    \n",
    "  loss,regret = loss_fn(targets, linear_layer_output, model_load)\n",
    "\n",
    "  regret.backward()\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "  \n",
    "  #print(\"regret\", regret.item())\n",
    "  \n",
    "  train_regret.append(regret.item())\n",
    "  \n",
    "  train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  model.eval()\n",
    "  val_data = next(iter(val_iter))\n",
    "  \n",
    "  val_inputs, val_targets = val_data\n",
    "  with torch.no_grad():\n",
    "    print(\"eval----------\")\n",
    "    linear_layer_output_val = torch.nn.functional.normalize(model(val_inputs))\n",
    "    val_loss, val_regret = loss_fn(val_targets, linear_layer_output_val, model_load)\n",
    "    val_regret_lst.append(val_regret.item())\n",
    "    print(\"eval done------\")\n",
    "  \n",
    "   \n",
    "\n",
    "  print('train regret : {}, valid regret : {} '.format(regret, val_regret))\n",
    "  \n",
    "  \n",
    "  if val_regret < best - 1e-4:\n",
    "    if val_regret > 0:\n",
    "      print(\"\\n UPDATE \\n\")\n",
    "      best_model = copy.deepcopy(model)\n",
    "      fails = 0\n",
    "      best = val_regret\n",
    "  else:\n",
    "    fails = fails + 1\n",
    "  if fails > patience:\n",
    "    print(\"Early Stopping. Valid hasn't improved for {}\".format(patience))\n",
    "    flag = True\n",
    "  if flag:\n",
    "    break\n",
    "  val_regret = 0 \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "print('Finished Training')\n",
    "print(\"number of infeasible solutions: \",infeasible_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 weights tensor(0.0352, grad_fn=<DivBackward0>)\n",
      "l2 decision tensor(0.0155, grad_fn=<DivBackward0>)\n",
      "inf time 0.003125\n",
      "violations tensor(1.7734, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_iter = itertools.cycle(test_dl)\n",
    "test_l2 = nn.MSELoss() \n",
    "#test_l1 = nn.L1Loss() \n",
    "\n",
    "l2_weights = []\n",
    "l2_decision = []\n",
    "test_viol = []\n",
    "optimal_path_acc = []\n",
    "inf_time = []\n",
    "\n",
    "#optimal_path_acc = []\n",
    "\n",
    "i =0 \n",
    "for inputs, targets in test_iter:\n",
    "    \n",
    "    start = time.process_time()\n",
    "    linear_layer_output = torch.nn.functional.normalize(model(inputs))\n",
    "    selected_edges = model_load(linear_layer_output)\n",
    "    inf_time.append(time.process_time() - start)\n",
    "    \n",
    "    error_w = test_l2(linear_layer_output,targets)\n",
    "    l2_weights.append(error_w)\n",
    "    \n",
    "    selected_edges_targets = model_load(targets)\n",
    "    error_d = test_l2(selected_edges,selected_edges_targets)\n",
    "    l2_decision.append(error_d)\n",
    "    \n",
    "    vio = calc_violations(inci_matrix,selected_edges.detach())[1]\n",
    "    test_viol.append(vio)\n",
    "    #selected_edges = model_load(linear_layer_output)\n",
    "    #selected_edges_targets = cvx_py(A,linear_layer_output) \n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break\n",
    "\n",
    "print(\"l2 weights\", sum(l2_weights)/len(l2_weights))\n",
    "print(\"l2 decision\", sum(l2_decision)/len(l2_decision))\n",
    "print(\"inf time\", sum(inf_time)/len(inf_time))\n",
    "print(\"violations\", sum(test_viol)/len(test_viol))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_regret,color='r', label='train loss')\n",
    "plt.plot(val_regret_lst, color='g', label='val loss')\n",
    "\n",
    "plt.xlabel(\"regret\")\n",
    "plt.ylabel(\"iterations\")\n",
    "plt.title(\"regret\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(train_loss)\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('iterations')\n",
    "#plt.title(\"loss\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for i in range(len(val_losses)):\n",
    " #   val_losses[i] = val_losses[i].cpu().detach().numpy()\n",
    "\n",
    "plt.plot(l1_error_weight_pred)\n",
    "plt.ylabel('l1 weight error')\n",
    "plt.xlabel('iterations')\n",
    "plt.title(\"l1 weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(l2_error_weight_pred)\n",
    "plt.ylabel('l2 weight error')\n",
    "plt.xlabel('iterations')\n",
    "plt.title(\"l2 weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for i in range(len(l1_error_proxy)):\n",
    " #   l1_loss_prox[i] = l1_error_proxy[i].cpu().detach().numpy()\n",
    "plt.plot(l1_error_decision_pred)\n",
    "plt.ylabel('l1 decision error')\n",
    "plt.xlabel('iterations')\n",
    "plt.title(\"l1 decision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(l2_error_decision_pred)\n",
    "plt.ylabel('l2 decision error')\n",
    "plt.xlabel('iterations')\n",
    "plt.title(\"l2 decision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtzElEQVR4nO3dd3xV9f3H8dcnIUwhEBJ2IKAgUhDQIKCC4ESsWmuroj+tq1bbWltbra21trX9Ve3PDmutta2z7mqrVRy4R12giMgQBJS9907y+f1xTi73JjeTnNzE834+Hnnk3jM/OUnO536/5zvM3RERkfjKynQAIiKSWUoEIiIxp0QgIhJzSgQiIjGnRCAiEnNKBCIiMadEIFIHZnabmV1Ty23dzPar53nOMrPn6rOvSF2Z+hGIRMPMHOjv7vNr2K4IWAjkuHtJY8QmkkwlAhGRmFMikGbDzK4ys0/MbLOZzTKzU8Llrcxsg5kNTtq2wMy2m1mX8P2VZrbczJaZ2YVVVduY2elmNrXCsu+Z2RPh67vM7JdJ675uZvPNbJ2ZPWFmPaqI/QQze9/MNpnZYjP7WdLqV8PvG8xsi5mNNrNzzez1pP0PNbN3zWxj+P3QpHUvm9l1ZvZGeG2eM7P8cF1rM/uHma0Nr9G7Zta11hddYkGJQJqTT4AxQC7wc+AfZtbd3XcCjwGTkrY9DXjF3VeZ2QTgcuBoYD9gXDXn+A+wv5n1T1p2JnB/xQ3N7Ejg1+G5ugOfAg9WcdytwDlAR+AE4BIz+1K4bmz4vaO77+Pub1Y4Tx7wFHAz0Bn4LfCUmXWuEON5QBegJfCDcPnXCK5XYbjvxcD2Kn96iSUlAmk23P0Rd1/m7mXu/hAwDzgkXH0/cEbS5sk379OAO939I3ffBvysmnNsAx4nTCphQhgIPJFm87OAO9z9vTAZ/QgYHdb5Vzzuy+7+YRj7DOAB4Iha/ugnAPPc/V53L3H3B4A5wIlJ29zp7h+7+3bgYWBYuHw3QQLYz91L3X2au2+q5XklJpQIpNkws3PMbHpYxbEBGAzkh6tfAtqa2cjwRjwM+Fe4rgewOOlQya/TuZ89pYszgX+HCaKiHgSlAADcfQuwFuiZJvaRZvaSma02s40En8zzK25XhZTzhD6tcJ4VSa+3AfuEr+8FngUeDKvFbjSznFqeV2JCiUCaBTPrA/wV+DbQ2d07AjMBA3D3UoJPwpPCryfdfXO4+3KgV9LhCms43RSgwMyGhceqVC0UWgb0SYqxHcGn76Vptr2foFRR6O65wG3lsQM1Nd1LOU+odxXnSeHuu9395+4+CDgU+CJBFZVIghKBNBftCG6YqwHM7DyCEkGy+4HTCapskm/eDwPnmdkBZtYWqLYfgLvvBh4BfgPkESSGdB4IjzvMzFoB/wu87e6L0mzbHljn7jvM7BCCkka51UAZ0K+K80wGBpjZmWbWwsxOBwYBT1b3cwCY2XgzG2Jm2cAmgqqispr2k3hRIpBmwd1nATcBbwIrgSHAGxW2eZvgoWwP4Omk5U8TPGh9CZgPvBWu2lnNKe8neLj8SFVt+939eYKk8ihBqWNfUp9TJPsm8Asz2wz8lCA5lR9nG/Ar4I2w2mtUhfOsJfgk/32CqqcrgS+6+5pq4i/XDfgnQRKYDbxCUF0kkqAOZRI7ZnYAQbVSK3XgElGJQGLCzE4J+xt0Am4A/qMkIBJQIpC4+AawiqAvQilwSWbDEWk6VDUkIhJzKhGIiMRci0wHUFf5+fleVFSU6TBERJqVadOmrXH3gnTrml0iKCoqYurUqTVvKCIiCWZWsXd6gqqGRERiTolARCTmlAhERGJOiUBEJOYiSwRmdoeZrTKzmVWszzWz/5jZB2b2UTiImIiINLIoSwR3AROqWf8tYJa7DyWYMeomM2sZYTwiIpJGZInA3V8F1lW3CdDezIxgEo11gMZ+ERFpZJl8RnALcADBpBsfApe5e9px0s3sIjObamZTV69e3ZgxikgjKS1zGmLIm5LSMkpKy3B3SsvSH29XSRkPvftZlevrYuP23cxbuTnxfv3WXSnrl2/czuQPl6f92Rav28aWnXs+/+4u3XMLXLZhOx8u2ciS9dtYtWkHf3h+Hq/Ni+b+l8kOZccB04EjCcZxn2Jmr6WbT9XdbwduByguLtbgSBIrG7btomPboNb045WbadUiiz6d29W438crN1PYqS2frdvG/t3aA7CzpJTSMqdty9R//WmfruP9zzbwtUOLyMnOqrTuienLuOaLg3BIrJ+zYhN989vxzMwVFBfl8ezMFZw+opB5q7YwtFcuHyzZyNadJSxcs5XcNjksWL2VFtnGwG7t2barlOwsY9HarZx/WF9aZBn7Xf00o/rlce2JX+CA7h0AKCtz/vjifNZs2YnjFHVuxwWH9+XmF+Zz/JBubN1ZwuPTlzGiKI93F63jrv8uAqBbh9YU5rXh3UXrOe+wIu58Y1Hi57n3gkO46bmPmb54Ay/NWc0tZw5n9vLN/OCRD5i7cjNjBxTw6sfBDfftHx+FAfn7tOKFOavondeWe99axNBeHbninzMA6NWpDUvWb2fc/gX0zmvLPW9+yh/OGEZB+1ac+de3U67lnOsmsHjdNj5ZvYVNO0q4MjxGTraxu7TmW9ulR+7HmP5pOwfvlUgHnQvnjn3S3SvOJIWZPQVc7+6vhe9fBK5y93eqO2ZxcbGrZ7Gks3VnCVt2ltC1Q+uU5c/PWsndby7invMPYe3WXdz4zBx+ftJg2rTMrtPxV23awc6SMjq2zaGsDNq3bsHvn/+YpRt2MKhHB04Y0p2ObXNonRMcd3dpGaVlnnh/75uLeGvhOg7bN5+++e0Y1KMDuW2C6YPLypxX5q1mcI9cWmZncc6d7/DB4g0cM6grU2atpF9+O3p2asNr84K5aBb870SysoKZLk/84+t8uHRjSqyH7tuZ/36yNvH+0UtGM3XRen799BwArjv5C1zz+Ed1+vnLHTGggIvG9uOsv71d88b1NLpfZ95csLbmDWPm9OJCbvjKgfXa18ymuXtx2nUZTAR/Bla6+8/MrCvwHjC0plmXlAiaJ3enzCE7y2rcdt3WXbw8dxXZWcbJw/bMz75i4w5atciiU7vg03FpmbNwzRZufmE+Q3rm8qvJs4HgU9dTM5bzxvw1PPb+nml951w3gR8+OoPHpy8DYPYvJvD+Z+s5829v8+gloxle2IlVm3cyf9UWDu+fz2drtzH2Ny9xzKCu7NhdmrgJ18aU743lsgenM2t5pQJuJR1at2DTjro/Hps4pBsjivL4+X9m1XlfaZ5evWI8vTu3rde+GUkEZvYAQWugfIKpBa8FcgDc/TYz60HQsqg7wSTe17v7P2o6rhJB87F43TZWbtpBcVEelz34Po9PX8ZrV47n5/+ZxU1fHUpu2xzueXMREwZ3o0v74FP87tIyLn/4A/7zwbLEcR66aBSd2rXk2N+9CsCvThnM4B65PPbeEu5+s8rhU/bKoutPoOiqpyI5tkh9Lbr+hHrvm7ESQRSUCBrfb5+bS052FheM6Vupbrmix6cv5cMlG+nYNoc/vDCP3aXOv791GF/60xuVtm2Tk8323aX07NiG1384HjNjwu9fZc6KzWmOLBIf4/cv4KW5lR8MR5UImt3oo9Jwtu4soVWLLFpkp288tnLTDi5/eDpvzA/qam+a8jF//1oxF9w9ldOLC3lo6mJG9s1jSM9c/vb6wirPky4JAGzfXQrA0g3b6fujyXRsm8OGbbv38qeSuPjL2Qdz5xsLeWtB0Ep9aGFHPli8odb7981vx8I1W9Ou+9KwHvx7+rK062DPh5iaTP7OGG54Zg6vhA+fn/nuGO7+76c88M5niW2mfG8sx4Sl3XKXjNsvkQgmDunG5A9X1HiuvaESwefY7tIysswS9fIfr9xMwT6tOPq3r1CY15bpizdwwoHdGdClPVM/XcdvTxvGa/NWYwbvLFzPsx+tYF2FpnASb7ecOZxv3/9+vfd//vKx7FuwDwOveYadJZVbi0/+zhg+WrYx0SJn1i+OY8aSjZxx+1uJbS4/ZgC/nfIx8391PPNXb2HC718DYObPj6NNTjY3vzCPDdt28aOJB3Df259x3ZPBM5S5v5zA7OWbEx9MTj2oF4++t4QnLz2cLWHrphfnrKJzu5Zcf+qBvDRnFefd9S5HDCjgnNF9uODu4L7zx0nDOXFoDzZu303L7Cyen72SIT1zueWl+fxz2pJEnF3at+Kdq48GSFQzln+iL3//7tVHU9C+Fdt3lVL8yym0bJHF05eNpVtuaxav20a33NbkZGfx7fvfY0RRHl87tKje115VQ81Mefvn8k/qb8xfQ4+ObeibX3OTwWRFVz3Foft25o5zRwAw8Jpn6NahNSs27WjwmKVqxX06MfXT9ZWWnzO6D/fsxTOOS8btyzGDuvLlW/9b72Mkt8659Mj9+OOL8wG49sRBaR9CL7r+BD5atpETbn6d+y4cyZ1vLOL52SsT69+/5hiGXzclZZ/iPp348/8cTP4+LQn6jwYen76Uyx6cDsBrV47ntXlrOHNkb6DyjRPg4XcXc0D3DgzplZty/HcXrWNYYcdKzV7LJR9rx+5SBl7zDBA0HnhzwVrG798l7X4bt+1m3P+9xF/PKaa4KI8tO0v4dO1WvtAjN+32JaVlXPP4TJ6ZuYJD+ubxl7P33HPfWbiOgvatEv/DL89dRZ/O7VL+p8v7NNSmQUV9KBE0Mz/85wwemrq40qeHRdefgLuzq7SMFllZZBnc+9anDOjanlH9OvPw1MXc9/Zn/Pubh2JmetjZRFx1/ECuD5ttJvvmuH259eVPanWMk4f1SLR2+us5xQzs1p7CvLbMX7WZo38bVCs8dNEoTk/65FyV5KqG8r+p52evYtz+BfS/+mkAFv56IhfePZXVW3YycUj3RPzp6qiXb9zOtE/XM3Fwd7KyjHVbd/HTx2fy1oJ1XHB4X049uGeiMUBFL85ZSY+ObRjYrUPK8nSJoL4WrdnKsg3bOXS//L0+VnOmZwTNRNFVT3FacS8enhoUL/f78WSe+e6YxPrDb3iRHrlteGdRdSN3wPcf+YCLj9g30lijUtd63ob07HfHcvnD0/loWc1NPgHOGtmb+97+rNptBnZrz/GDu6VNBN8avx9mcP5hfTn4l88DwU3+wF65jPzfFxLb3XvBIYkqh9+dPpRjBnVNrGuRFXwK7tWpDSP7dWbSIb3ZtquEi8b2Y+GarRR2asvJYVXIH84YxmUPTufUg3oxe/lmvjG2HwBmljjmOz8+Cg+X/T0sSQLMWraJbrnpb+bdc9vwxQPbJN7ntWvJLWceVO11KXfkwK41b7SXivLbUVTH0nTcKBFkyOzlm3CHBWu2sGzD9sTy8iQAUFLmiU97AEvWb2fJ+u3U5LH3lvLYe0tr3K6pefSS0RzcJ69BSjIXHN6X/l32YcvOEn751Oxa7bN/t/Y8eenhvD5/DaP7dWbFph0cfsNLabc94cDu/OqUIXz/2P05qEJVyI1fOZCCfVpx3l3v0qF1Tsqn4W4dWjOoRwdOK+5Fu1YtuOK4gUDwCRxIVJ08972xieayY/oXUNS5Heu37eaYQd1SzlVens8K9/v1l4ck1pVXYWRnGaVlzklDezCoewf6d23PUQekvwF36ZD+Zn/zpOFpl0fl8W8dluiIJ9FTImhAG7ftpkObFin1oN+8bxozl27i1SvHA0Ev19y2OXz1tjczFWaTdXCfvCrXDezWnhOGdOeluat477MNjOmfz70XjGTQT59h267SxAPEcgaccUhQ31xdIujTuS2frt22Zz+zRBf+Xp0qd9zpV9CO+y4cSV7YqS2vXUvev+YY3l64liv/OYNNO0o4dlBX5q3aAoDjtGmZnbixXzJu37QP/JL/ZgAGdA2GhDhxaA8ACvPacs/5h1Tar8xrrld+75pjKC1zzIz+4XGbuqGFHTMdQqxoYpoGsmT9Nob+4jn+HjajXLxuG9M+Xc/kD1fw2bptvDE/6JV64T1TY50ECvPapH1901eHVrtfTnYWlx7VP/EJukPrcGiG8EbYoXXtPtOcXlyY8v6VK8bXar9yT182hu65bWjVYs+n1U7tWjJhcHduOfMgRvXLo33rHIYVduSkoT24/tRgOIABXdvz9o+P4pzRfWp9rg9/diy/O63669Im/NS8fzU3+Nw2OYnEJZKOSgQNpPxB3pRZK7lwTD/G3JhapRDluCzNxR8nDWfsgAKG/vw5AK6eeAAX/+M9zj+sL6ce3CvtPuUPQPuE3epH9cvjquMHcsaI4IZePnjkqQf3YuuuUjq2zeHqf81kQLc9N8Y3f3Qko3/9IicP68ENXzmQh6YuTjnHacW9OLhPp7Tn79qhFSs37eTtHx8FkJIAKho7oICxA4LSRDZWqTql4hhINWkfJrvq9OjYhn9cMJLhvTvW6dgiydRqqJ4+XbuVI37zMo9ecigH9+mUqNfum9+OP5wxjJNuSd+JKs7KW4AsXreN1jnZFLRvlXa78mt57wWHMKZ/AS/MXsmofp1p16ry55ZHpi7mhmfm8M6Pj04MwjZz6Ua+0KNDSnXLwjVb6dGxNa1aZPPWgrWJduk1tUpZt3UXqzfvTIzeKdJcVddqSFVD9TRlVtB2+tQ//5cFq7ckli9cszV2SeDcKjq5zLluzwR1t599cOJ1YV7bKpNAsvK6+qMO6Jo2CQB8tbiQqT85JpEEAAb3zK1U5943v13i0/yofp0BGFGUvhSQLK9dSyUB+dxT1VA9JY9vfuRNr2QukIj1y2/Hgiq64Xdp34pXrxxP65xspsxaydKk1k8tW2TRqsWezxlVtVJJ5/BGaO897SdHV5lcROJG/wl18OGSjcxevokvDe+ZctNrLDd+5cDERBblbvrqUL7/yAeRnO9Hxw8kyywxvHNFRx3QJdHEb2hhLks3bOeEId0577Aieue1xcx47JuHsm/+PnXqLfmPC0c2SPzV6bxPzSUSkbhQ1VAdnHjL61z56IyUqeUa02EVPikfNbBLlQ9ZK5r+02M4+oD0XekBfnDsgLTLneqeIVnSq+D18UO6UVyUl2iPflDvTuS2rfmhp4hkjhJBLezYXcpJt7yeeP/y3FWRn/MrtbjBnzy8Z7Xrbzz1QH51ymAeveRQOrZtyd++NqLKbc8eXQRAy+wsrjhuf6B2rVYqamZtD0QEVQ3Vyuzlm5ixZM9UgJc/HE1VTP4+LRnTv4ALx/TlCz1yU0YyTKemFl+njSiscp3Znpt2x7Y5JNfcXDS2Hx1at+D0EYX8/fUFQNCha1CPDjz23tJEJ6zkfgBEM06WiDQClQhqYWaF+WCjkp1l/O70YYmhAV65Yhz3XTiS/LA+OyfbUsYe2rdgn0rHqGmE0vx9go5FC3+9p9nk85cfkajDd5yc7CzOHl1EdpbROy9ov3/26D7c9NWh/OqUwTz73bHcee4IvjF2z3hG5SWYYeoRKtLsqERQC/Wd5Ls6Pzh2AE/PXJEywNnwwtTmjH06t6NP53Y8f/lY3l64ji7tW9OlfWuunngAhXltGdwzdTjc8jbxD7+7mP/MSD+pxuTvjOGzdcGQCr87fSh/e20h+fu0Ykc4yUbFQsaEwd155OLRFPfphJlx1sigZ+z4ganPG8bv36VBRooUkcanRFCDKDrcXfelwZw9qg/dc9vw/Uc+4JThPTn/sL7s16XyJ3yAjm1bctwX9gw29vVw1Mhkyc3mTxtRWGW1UJcOrRMPck8Z3otThgef5LOs6rqdEUVVjwEkIs2fEkE1dpWUJYZDqIvXrhxPTnYWv3jyI3rnteO2V4Ix57u0b0Wnti2ZODi4qY/sF9xgv1rcq9JkG3Xx1o+OSmmzXx8twqqhq44fuFfHEZHmR4mgGh8u3VireUkrKgzr1W8962DeWrA2kQj6dG7LIxcfmtiuV6e2DVKdUtU48XWRlWWq2hGJqcgeFpvZHWa2ysxmVrPNODObbmYfmVmT6567Ydvez9c7ql9n/nFB0EEq+eGqiEhTEWWJ4C7gFuCedCvNrCNwKzDB3T8zs6p7O2XIrjSTa9fH4f3z9WlbRJqsyEoE7v4qUN2cimcCj7n7Z+H20ffSqqOSMvWOEpHPv0z2IxgAdDKzl81smpmdU9WGZnaRmU01s6mrV69ulODcnUsfeL9RziUikkmZTAQtgIOBE4DjgGvMLO2AN+5+u7sXu3txQUFBowS3uQ7jCSVPJi4i0txkMhEsAZ51963uvgZ4Fah+Xr5GMHfFZlZv3smkcOKSmjx00aiIIxIRiVYmm48+DtxiZi2AlsBI4HcZjAeA437/ap22H9mvM0/PXAFAu5bZGuNeRJqdyO5aZvYAMA7IN7MlwLVADoC73+bus83sGWAGUAb8zd2rbGraGHbUo88ABJ2wRhTlccKB3Rs4IhGR6EWWCNx9Ui22+Q3wm6hiqKut9ZxnoHVOtpKAiDRbqsdIcvRva9en7c5zRzC0sCO7Sxumn4GISCYpESRZv213rbarOPKmiEhzpkRA0Gfg1pc/yXQYIiIZoYlpgH+89Sm/eXZupsMQEckIJQLgzQVr0y4/Mk0V0F/OPjjqcEREGpUSAbB1Z+Vmo/ecf0jam37yBDEiIp8HSgTA6s07Ky0b2L09Odm6PCLy+Rf7h8Wvz1vDrOV75g2+euIBHNgrly7tK0/2csOpQxozNBGRRhH7RPD+Z+tT3l9weF+ystLP33v6iN6NEZKISKNS3UcFVSUBEZHPq9gnghlLN1a7/n9GqRQgIp9vsU8EU2atTLzu0r5VpfW//JKeC4jI51vsE0Gykf06ZzoEEZFGF+tEUKo5iUVE4psItuwsYd8fT05ZpsfEIhJHsU0EG7fXbqRREZHPu9gmgpzsyp//TysuzEAkIiKZFfsOZeXu//pIDt03P+26mycNZ/uu+s1eJiLS1MU2Efzyydkp76tKAgAnDe0RdTgiIhkT26qhJz5YlukQRESahNgmAhERCUSWCMzsDjNbZWYza9huhJmVmNlXoopFRESqFmWJ4C5gQnUbmFk2cAPwXIRx1OjOc0dk8vQiIhkVWSJw91eBdTVsdinwKLAqqjhqY3yaKSlFROIiY88IzKwncArw51pse5GZTTWzqatXr44+OBGRGMnkw+LfAz9097KaNnT329292N2LCwoKoo9MRCRGMtmPoBh40MwA8oGJZlbi7v+O8qQfLdvIdx+cHuUpRESalYwlAnfvW/7azO4Cnow6CQD8bsrHzFu1JfFeE8+ISNxFlgjM7AFgHJBvZkuAa4EcAHe/Larz1iTLUscY2rdgnwxFIiLSNESWCNx9Uh22PTeqOCrq0iF1FrLdpTU+ohAR+VyLXc/idi1Tc9/uUk1OIyLxFrtEUFJhVrJdJSoRiEi8xS4RVJyesqRMiUBE4i12iaDijb91i+wMRSIi0jTELhHsLkktEVx0RL8MRSIi0jTELxEktRIa2TePVioRiEjMxS4R7ExKBDnZsfvxRUQqid2dcHdSKyGrPH+9iEjsxC4R7FIHMhGRFLFLBOpJLCKSKnaJILkDmatTsYhIDBOBhpQQEUkRv0SQVCKYOKR7BiMREWkaYpcIkp8RTDqkMIORiIg0DbFLBLtSmo+q/aiISOwSgVoNiYikqnJiGjM7qLod3f29hg8nehp2WkQkVXUzlN1UzToHjmzgWBqFOpSJiKSqMhG4+/jGDKQxbNlZwuYdJZkOQ0SkSalxzmIzywEuAcaGi14G/uLuuyOMKxIbtu3KdAgiIk1ObSav/zOQA9wavj87XHZhVEFFRT2JRUQqq00iGOHuQ5Pev2hmH9S0k5ndAXwRWOXug9OsPwv4IWDAZuASd6/xuHtDiUBEpLLaNB8tNbN9y9+YWT+gtBb73QVMqGb9QuAIdx8CXAfcXotj7pUyZQIRkUpqUyK4AnjJzBYQfHrvA5xX007u/qqZFVWz/r9Jb98CetUilr2iRCAiUlmNicDdXzCz/sD+4aK57r6zgeO4AHi6qpVmdhFwEUDv3r3rfZIy5QERkUqq61B2pLu/aGZfrrBqPzPD3R9riADMbDxBIji8qm3c/XbCqqPi4uK9uJ0rE4iIVFRdieAI4EXgxDTrHNjrRGBmBwJ/A45397V7e7yaqEQgIlJZdR3Krg1fXujutXk4XCdm1psgmZzt7h839PHT0TMCEZHKavOweKGZPQM8BLzoXru7qZk9AIwD8s1sCXAtQX8E3P024KdAZ+DWcBTQEncvrvNPUAdlGl1CRKSS2iSCgQT9Ab4F/N3MngQedPfXq9vJ3SfVsP5CGrlTmusZgYhIJTX2I3D3be7+sLt/GRgOdABeiTyyCKhmSESkslrNR2BmR5jZrcA0oDVwWqRRRUTPCEREKqvNoHOLgPeBh4Er3H1r1EFFpTRsNnTlhP0Zv3+XDEcjItI01OYZwYHuvinySBrBLS/OB6B7bmsO6N4hw9GIiDQNtXlG8LlIAgAvzFkFwLqtzW4EbRGRyMRuzmKAbM1ZLyKSEM9EkKVMICJSrjYPiy9Ps3gjMM3dpzd4RI1AbYdERPaoTYmgGLgY6Bl+fYNgnoG/mtmVEcYWmVINOiQiklCbVkO9gIPcfQuAmV0LPEUwh/E04MbowouGEoGIyB61KRF0AZLnH9gNdHX37RWWNxtKBCIie9SmRHAf8LaZPR6+PxG438zaAbMiiywCffPbsXDNVo77QrdMhyIi0mTUZoay68zsaeCwcNHF7j41fH1WZJFFoFenNnRsm0NRfrtMhyIi0mTUptXQzQSjjf6hEeKJVEmp00JNR0VEUtTmGcE04Cdm9omZ/Z+ZRTpnQJRK3dWHQESkgtoMMXG3u08ERgBzgRvMbF7kkUWgtEyJQESkorr0LN6PYJKaPsCcaMKJVpAIYtmZWkSkSjXeFc3sxrAE8AtgJlDs7ukmtG/ySstc4wyJiFRQm+ajnwCj3X1N1MFETSUCEZHKatN89C9m1snMDiGYnax8+auRRhaBIBFkOgoRkaalNs1HLwQuIxhqYjowCngTODLSyCJQ6k4LlQhERFLU5q54GUGLoU/dfTzBBPYbatrJzO4ws1VmNrOK9WZmN5vZfDObYWYH1SXw+igtc7LUakhEJEVtEsEOd98BYGat3H0OsH8t9ruLYJTSqhwP9A+/LgL+XItj7pXSMnUoExGpqDYPi5eYWUfg38AUM1sPfFrTTu7+qpkVVbPJycA97u7AW2bW0cy6u/vyWsRUL6VlTpYpEYiIJKvNw+JTwpc/M7OXgFzgmQY4d09gcdL7JeGySonAzC4iKDXQu3fvep9QD4tFRCqrTYkgwd1fiSqQGs57O3A7QHFxcb3HkC5R81ERkUoyeVdcChQmve8VLotMmatEICJSUSZvi08A54Sth0YBG6N8PgBQUlqm5qMiIhXUqWqoLszsAWAckG9mS4BrgRwAd78NmAxMBOYD24DzooqlXJmjh8UiIhVElgjcfVIN6x34VlTnT6e0zGmhwYZERFLEqp5EzUdFRCqLVyJwdSgTEakoNonA3TXEhIhIGrFJBGVh7wOVCEREUsUmEZSUlQFoqkoRkQpikwg8LBHoWbGISKrYJAIREUkvNokgUSJARQIRkWTxSQQEmUBVQyIiqWKTCMopD4iIpIpNIvB6D14tIvL5Fp9EEH5X1ZCISKr4JIKwSKCHxSIiqWKTCMqpRCAikio2iUCPCERE0otPIlAmEBFJKzaJoJypbkhEJEV8EoFKBCIiacUmESR6Fmc4DhGRpiY+iUCjj4qIpBWbRFBOeUBEJFWkicDMJpjZXDObb2ZXpVnf28xeMrP3zWyGmU2MKhY9IhARSS+yRGBm2cCfgOOBQcAkMxtUYbOfAA+7+3DgDODWqOJJ9CxW3ZCISIooSwSHAPPdfYG77wIeBE6usI0DHcLXucCyqILRWEMiIulFmQh6AouT3i8JlyX7GfA/ZrYEmAxcmu5AZnaRmU01s6mrV6/eq6CUB0REUmX6YfEk4C537wVMBO41s0oxufvt7l7s7sUFBQX1OpF6FouIpBdlIlgKFCa97xUuS3YB8DCAu78JtAbyowimvB+B6oZERFJFmQjeBfqbWV8za0nwMPiJCtt8BhwFYGYHECSCvav7qUpizmIREUkWWSJw9xLg28CzwGyC1kEfmdkvzOykcLPvA183sw+AB4Bz3aOtxFGBQEQkVYsoD+7ukwkeAicv+2nS61nAYVHGkDhXY5xERKQZyvTD4kaTGGJClUMiIinikwjKB51THhARSRGbRFBOeUBEJFVsEoH6EYiIpBefRBB+V9WQiEiq2CSCcnpYLCKSKjaJIOLuCSIizVaMEkH4QgUCEZEUsUkE5ZQHRERSxS8R6GmxiEiK2CQCPSIQEUkvPomgvGdxhuMQEWlq4pMINB2BiEhasUkE5ZQIRERSxSYR6BGBiEh68UkEXv6MQEUCEZFk8UkE4XdVDYmIpIpNIhARkfRikwjUj0BEJL3YJAISM5SpbkhEJFlsEsGeOYtFRCRZpInAzCaY2Vwzm29mV1WxzWlmNsvMPjKz+6OMJzhf1GcQEWleWkR1YDPLBv4EHAMsAd41syfcfVbSNv2BHwGHuft6M+sSVTx6RCAikl6UJYJDgPnuvsDddwEPAidX2ObrwJ/cfT2Au6+KKpg9VUMqEoiIJIsyEfQEFie9XxIuSzYAGGBmb5jZW2Y2Id2BzOwiM5tqZlNXr169V0GpakhEJFWmHxa3APoD44BJwF/NrGPFjdz9dncvdvfigoKCep3IVTkkIpJWlIlgKVCY9L5XuCzZEuAJd9/t7guBjwkSQ4NTqyERkfSiTATvAv3NrK+ZtQTOAJ6osM2/CUoDmFk+QVXRgiiC0TDUIiLpRZYI3L0E+DbwLDAbeNjdPzKzX5jZSeFmzwJrzWwW8BJwhbuvjSKeMleHMhGRdCJrPgrg7pOByRWW/TTptQOXh1+RKi8RZCsRiIikyPTD4kZTGmaCrNj8xCIitROb22J51VCWSgQiIinikwjKlAhERNKJTSIoDRNBdpYSgYhIstgkgjAPqEQgIlJBjBJBedVQhgMREWliYpcIVDUkIpIqNomg/BmBOpSJiKSKTSJIdChTiUBEJEVsEkFpmZ4RiIikE59EoA5lIiJpxSYRuB4Wi4ikFZtEUFoWfFeJQEQkVWwSQbfcVkwc0o0ObSIdcFVEpNmJzV3x4D55HNwnL9NhiIg0ObEpEYiISHpKBCIiMadEICISc0oEIiIxp0QgIhJzSgQiIjGnRCAiEnNKBCIiMWflY/A0F2a2Gvi0nrvnA2saMJyG0lTjgqYbm+KqG8VVN5/HuPq4e0G6Fc0uEewNM5vq7sWZjqOiphoXNN3YFFfdKK66iVtcqhoSEYk5JQIRkZiLWyK4PdMBVKGpxgVNNzbFVTeKq25iFVesnhGIiEhlcSsRiIhIBUoEIiIxF5tEYGYTzGyumc03s6sa+dyFZvaSmc0ys4/M7LJw+c/MbKmZTQ+/Jibt86Mw1rlmdlyEsS0ysw/D808Nl+WZ2RQzmxd+7xQuNzO7OYxrhpkdFFFM+yddk+lmtsnMvpuJ62Vmd5jZKjObmbSsztfHzL4Wbj/PzL4WUVy/MbM54bn/ZWYdw+VFZrY96brdlrTPweHvf34Y+17N5VpFXHX+vTX0/2sVcT2UFNMiM5seLm/M61XVvaFx/8bc/XP/BWQDnwD9gJbAB8CgRjx/d+Cg8HV74GNgEPAz4Adpth8UxtgK6BvGnh1RbIuA/ArLbgSuCl9fBdwQvp4IPA0YMAp4u5F+dyuAPpm4XsBY4CBgZn2vD5AHLAi/dwpfd4ogrmOBFuHrG5LiKkrersJx3gljtTD24yOIq06/tyj+X9PFVWH9TcBPM3C9qro3NOrfWFxKBIcA8919gbvvAh4ETm6sk7v7cnd/L3y9GZgN9Kxml5OBB919p7svBOYT/AyN5WTg7vD13cCXkpbf44G3gI5m1j3iWI4CPnH36nqTR3a93P1VYF2a89Xl+hwHTHH3de6+HpgCTGjouNz9OXcvCd++BfSq7hhhbB3c/S0P7ib3JP0sDRZXNar6vTX4/2t1cYWf6k8DHqjuGBFdr6ruDY36NxaXRNATWJz0fgnV34gjY2ZFwHDg7XDRt8Mi3h3lxT8aN14HnjOzaWZ2Ubisq7svD1+vALpmIK5yZ5D6D5rp6wV1vz6ZuG7nE3xyLNfXzN43s1fMbEy4rGcYS2PEVZffW2NfrzHASnefl7Ss0a9XhXtDo/6NxSURNAlmtg/wKPBdd98E/BnYFxgGLCconja2w939IOB44FtmNjZ5ZfjJJyNtjM2sJXAS8Ei4qClcrxSZvD5VMbOrgRLgvnDRcqC3uw8HLgfuN7MOjRhSk/u9VTCJ1A8bjX690twbEhrjbywuiWApUJj0vle4rNGYWQ7BL/o+d38MwN1Xunupu5cBf2VPdUajxevuS8Pvq4B/hTGsLK/yCb+vauy4QscD77n7yjDGjF+vUF2vT6PFZ2bnAl8EzgpvIIRVL2vD19MI6t8HhDEkVx9FElc9fm+Neb1aAF8GHkqKt1GvV7p7A438NxaXRPAu0N/M+oafMs8Anmisk4d1kH8HZrv7b5OWJ9evnwKUt2h4AjjDzFqZWV+gP8FDqoaOq52ZtS9/TfCwcWZ4/vJWB18DHk+K65yw5cIoYGNS8TUKKZ/UMn29ktT1+jwLHGtmncJqkWPDZQ3KzCYAVwInufu2pOUFZpYdvu5HcH0WhLFtMrNR4d/oOUk/S0PGVdffW2P+vx4NzHH3RJVPY16vqu4NNPbf2N488W5OXwRP2z8myO5XN/K5Dyco2s0ApodfE4F7gQ/D5U8A3ZP2uTqMdS572TKhmrj6EbTI+AD4qPy6AJ2BF4B5wPNAXrjcgD+FcX0IFEd4zdoBa4HcpGWNfr0IEtFyYDdBvesF9bk+BHX288Ov8yKKaz5BPXH539ht4banhr/f6cB7wIlJxykmuDF/AtxCONpAA8dV599bQ/+/posrXH4XcHGFbRvzelV1b2jUvzENMSEiEnNxqRoSEZEqKBGIiMScEoGISMwpEYiIxJwSgYhIzCkRSOyY2X/D70VmdmYDH/vH6c4l0pSp+ajElpmNIxgV84t12KeF7xnYLd36Le6+TwOEJ9JoVCKQ2DGzLeHL64ExFow5/z0zy7ZgTP93wwHSvhFuP87MXjOzJ4BZ4bJ/hwP1fVQ+WJ+ZXQ+0CY93X/K5wp6gvzGzmRaMZ3960rFfNrN/WjCXwH1hb1PM7HoLxqmfYWb/15jXSOKlRaYDEMmgq0gqEYQ39I3uPsLMWgFvmNlz4bYHAYM9GC4Z4Hx3X2dmbYB3zexRd7/KzL7t7sPSnOvLBIOuDQXyw31eDdcNB74ALAPeAA4zs9kEwzEMdHe3cJIZkSioRCCyx7EE47hMJxgKuDPBODMA7yQlAYDvmNkHBOP+FyZtV5XDgQc8GHxtJfAKMCLp2Es8GJRtOsHEKBuBHcDfzezLwLbKhxRpGEoEInsYcKm7Dwu/+rp7eYlga2Kj4NnC0cBodx8KvA+03ovz7kx6XUowy1gJwSid/yQYTfSZvTi+SLWUCCTONhNMD1juWeCScFhgzGxAOCprRbnAenffZmYDCaYMLLe7fP8KXgNOD59DFBBMnVjlCKkWjE+f6+6Tge8RVCmJRELPCCTOZgClYRXPXcAfCKpl3gsf2K4m/VSEzwAXh/X4cwmqh8rdDswws/fc/ayk5f8CRhOM9OrAle6+Ikwk6bQHHjez1gQllcvr9ROK1IKaj4qIxJyqhkREYk6JQEQk5pQIRERiTolARCTmlAhERGJOiUBEJOaUCEREYu7/AZv+o6gysM4QAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_constraint_viol_perbatch)\n",
    "plt.ylabel('avg viol')\n",
    "plt.xlabel('iterations')\n",
    "plt.title(\"avg violations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(max_constraint_viol_perbatch)\n",
    "plt.ylabel('max viol')\n",
    "plt.xlabel('iterations')\n",
    "plt.title(\"max violations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#adict = {\"max_viol\": max_constraint_viol_perbatch, \"avg_viol\":avg_constraint_viol_perbatch,\n",
    "  #       \"l1_decision\":l1_error_decision_pred, \"l1_weight\":l1_error_weight_pred, \"train_regret\":train_regret, \"val_regret\":val_regret_lst,\n",
    " #        \"l2_decision\":l2_error_decision_pred, \"l2_weight\":l2_error_weight_pred }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump( adict, open( \"MSE_2_proxypipeline_dict.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5842daea53dd272ed90462daeb5f210458e1b3f8f882f697cb32ab8b4c14a531"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
