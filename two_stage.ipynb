{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import typing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import cvxpy as cp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "import sys\n",
    "import io\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "from torch.utils import data as torch_data\n",
    "import pickle\n",
    "import itertools\n",
    "import warnings\n",
    "from numpy import linalg as LA\n",
    "from sklearn import preprocessing\n",
    "from cvxpylayers.torch.cvxpylayer import CvxpyLayer\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "#inci_matrix = torch.tensor([ [-1,-1,-1,0,0,0,0,0],\n",
    "  # [1,0,0,-1,0,-1,0,0],\n",
    "             #  [0,1,0,1,1,0,-1,0],\n",
    "               \n",
    "             #  [0,0,1,0,-1,0,0,-1],\n",
    "            #   [0,0,0,0,0,1,1,1] \n",
    "             #  ],dtype=torch.float32)\n",
    "inci_matrix = pickle.load( open( \"matrix_{}b{}.p\".format(80,130), \"rb\" ) )\n",
    "\n",
    "\n",
    "\n",
    "while len(training_data) != 4000:\n",
    "    \n",
    "    z = torch.tensor([float(random.uniform(0.001, 1)) for i in range(130)])\n",
    "    #z = torch.tensor([e1,e2,e3, e4, e5, e6, e7, e8])\n",
    "    training_data.append(z)\n",
    "training_data = torch.stack(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvx_py(A, pred):\n",
    "   \n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    \n",
    "    eps = 0.5\n",
    "    \n",
    "    batch_s, edges  = pred.shape\n",
    "   \n",
    "    \n",
    "    n,m = A.shape\n",
    "    target = torch.zeros((batch_s, edges))\n",
    "    \n",
    "    #print(target.shape)\n",
    "    c = cp.Parameter(m)\n",
    "    #c = c.detach().numpy()\n",
    "    b = np.zeros(n)\n",
    "    b[0] = -1\n",
    "    b[n-1] = 1\n",
    "    x = cp.Variable(shape=m)\n",
    "    constr = [x>=0, x <= 1,\n",
    "             A*x == b]\n",
    "    \n",
    "  \n",
    "    \n",
    "    problem  = cp.Problem(cp.Minimize(c @ x ),constr)\n",
    "    cvxlayer = CvxpyLayer(problem, parameters=[c], variables=[x])\n",
    "  \n",
    "   \n",
    "    solutions = lambda z: cvxlayer(z)[0] #, args = {'tol':1e-10})[0]\n",
    "    index = 0\n",
    "    for x in pred:\n",
    "        \n",
    "         \n",
    "        #print(x)\n",
    "       # print(x)\n",
    "        \n",
    "            #sol = solutions(x)\n",
    "        target[index] = solutions(x)\n",
    "        \n",
    "        #print(problem.value)\n",
    "        index += 1\n",
    "    \n",
    "    return torch.Tensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_violations(inc_matrix, selected_edges):\n",
    "    #viol = 0\n",
    "    viol_lst = []\n",
    "    n,m = inc_matrix.shape\n",
    "    b = np.zeros(n)\n",
    "    # these are flipped to get 0 for violations, original are the opposite \n",
    "    b[0] = -1\n",
    "    b[n-1] = 1\n",
    "    \n",
    "    batch_size, null = selected_edges.shape\n",
    "    \n",
    "    for i in selected_edges:\n",
    "      #torch.unsqueeze(i,1)\n",
    "      #print(i.shape)\n",
    "      viol = 0\n",
    "      \n",
    "      a = torch.matmul(inci_matrix,i)\n",
    "      #print(a.shape)\n",
    "     # print(a.shape)\n",
    "      #print(b.shape)\n",
    "      c = a - b \n",
    "      for values in c:\n",
    "        viol += torch.abs(values) \n",
    "      \n",
    "      \n",
    "      \n",
    "      for j in i:\n",
    "        if j < 0:\n",
    "          viol += torch.abs(j)\n",
    "        elif j > 1:\n",
    "          viol += torch.abs(j-1)\n",
    "      viol_lst.append(viol)\n",
    "      \n",
    "    #print(viol_lst)\n",
    "      \n",
    "    return  max(viol_lst), sum(viol_lst)/len(viol_lst)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regret_cvxpy(y_true, y_hat,cvx):\n",
    "    A = inci_matrix    \n",
    "    y_true_decision = cvx(A,y_true)\n",
    "    y_hat_decision = cvx(A,y_hat)\n",
    "    \n",
    "    \n",
    "    objective_true = (y_true * y_true_decision).sum(1)\n",
    "    objective_hat =  (y_true * y_hat_decision).sum(1)\n",
    "    \n",
    "   # print(objective_true.shape)\n",
    "   # print(objective_hat.shape)\n",
    "    regret = torch.mean(objective_hat - objective_true)\n",
    "   # print(regret.shape)\n",
    "    return regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_net_data_generation(inputs):\n",
    "    \n",
    "    data = []\n",
    "    target = []\n",
    "\n",
    "    N,M  = inputs.shape\n",
    "    \n",
    "    A = torch.rand((M, M))\n",
    "   \n",
    "    print(\"Condition number: \",LA.cond(A))\n",
    "\n",
    "    A_Inv = torch.linalg.inv(A)\n",
    "    alpha = 0.05 # perturbation amplitude\n",
    "\n",
    "    \n",
    "    for i in inputs:\n",
    "        target.append(i)\n",
    "        x = torch.nn.functional.normalize(torch.matmul(A_Inv,i), dim=0, p=2)\n",
    "        data.append(x)\n",
    "        \n",
    "    \n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(training_data)\n",
    "x_nn, y_nn = pred_net_data_generation(training_data)\n",
    "\n",
    "x_nn = torch.stack(x_nn)\n",
    "y_nn = torch.stack(y_nn)\n",
    "\n",
    "x_nn = preprocessing.normalize(x_nn)\n",
    "y_nn = preprocessing.normalize(y_nn)\n",
    "#print(x_nn[0])\n",
    "#print(x_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_random = 9999\n",
    "np.random.seed(seed_random)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_nn, y_nn, test_size=0.25, train_size=0.75, random_state=seed_random, shuffle=True)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, test_size=0.2, train_size=0.8, random_state=seed_random, shuffle=True)\n",
    "\n",
    "print('shapes of train, validation, test data', x_train.shape, y_train.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'iterations': 1000,'batch_size': 100, 'input_size': 130, 'hidden_units_1': 100, 'hidden_units_2': 200, 'hidden_units_3': 250, 'hidden_units_4': 300, 'hidden_units_5': 250, 'hidden_units_6': 200, 'hidden_units_7': 100, 'do_1': 0.2, 'do_2': 0.1, 'do_3': 0.05, 'output_size': 130, 'lr': 0.001, 'min_lr': 1e-05, 'max_lr': 0.001, 'epochs': 30, 'lr_sched': 'clr', 'lr_sched_mode': 'triangular', 'gamma': 0.95}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "trainset = torch_data.TensorDataset(torch.as_tensor(x_train, dtype=torch.float, device=device), \n",
    "torch.as_tensor(y_train, dtype=torch.float, device=device))\n",
    "train_dl = torch_data.DataLoader(trainset, batch_size=params['batch_size'], drop_last=True)\n",
    "\n",
    "val_dl = torch_data.DataLoader(torch_data.TensorDataset(torch.as_tensor(x_cv, dtype=torch.float, device=device), \n",
    "torch.as_tensor(y_cv, dtype=torch.float, device=device)), batch_size=params['batch_size'], drop_last=True)\n",
    "\n",
    "test_dl = torch_data.DataLoader(torch_data.TensorDataset(torch.as_tensor(x_test, dtype=torch.float, device=device), \n",
    "torch.as_tensor(y_test, dtype=torch.float, device=device)), batch_size=params['batch_size'], drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_weights(net, init_type='normal', init_gain=0.02):\n",
    "\n",
    "    def init_func(m):  # define the initialization function\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, init_gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
    "            elif init_type == 'kaiming_uniform':\n",
    "                nn.init.kaiming_uniform_(m.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "                #init.kaiming_uniform(m.weight.data, a=0, mode='fan_in')\n",
    "                #init.kaiming_uniform(m.bias.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
    "                #init.orthogonal_(m.bias.data, gain=init_gain)\n",
    "                \n",
    "            elif init_type == 'kaiming_normal':\n",
    "                nn.init.kaiming_normal_(m.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "            \n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find(\n",
    "                'BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "            init.normal_(m.weight.data, 1.0, init_gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(9999)\n",
    "def get_model():\n",
    "    \"\"\"\n",
    "    creates a PyTorch model. Change the 'params' dict above to \n",
    "    modify the neural net configuration.\n",
    "    \"\"\"\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(params['input_size'], params['hidden_units_1']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_1']),\n",
    "         torch.nn.Dropout(p=params['do_1']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_1'], params['hidden_units_2']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_2']),\n",
    "         torch.nn.Dropout(p=params['do_2']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_2'], params['hidden_units_3']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_3']),\n",
    "         torch.nn.Dropout(p=params['do_3']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_3'], params['hidden_units_4']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_4']),\n",
    "        torch.nn.Dropout(p=params['do_3']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_4'], params['hidden_units_5']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_5']),\n",
    "        torch.nn.Dropout(p=params['do_3']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_5'], params['hidden_units_6']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_6']),\n",
    "        torch.nn.Dropout(p=params['do_3']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_6'], params['hidden_units_7']),\n",
    "        torch.nn.BatchNorm1d(params['hidden_units_7']),\n",
    "        torch.nn.Dropout(p=params['do_3']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_7'], params['output_size']),\n",
    "       # torch.nn.Sigmoid(),\n",
    "        # torch.nn.Softplus(),\n",
    "    )\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "#def mse_viol(pred, target):\n",
    "    \n",
    "\n",
    "model = get_model()\n",
    "#best_model = copy.deepcopy(model)\n",
    "initialize_model = True\n",
    "if initialize_model:\n",
    "    init_weights(model, 'xavier')\n",
    "\n",
    "print('model loaded into device=', next(model.parameters()).device)\n",
    "\n",
    "# this is just to capture model summary as string\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = buffer = io.StringIO()\n",
    "\n",
    "summary(model, input_size=(params['input_size'], ))\n",
    "\n",
    "sys.stdout = old_stdout\n",
    "model_summary = buffer.getvalue()\n",
    "#print('model-summary\\n', model_summary)\n",
    "# later this 'model-summary' string can be written to tensorboard\n",
    "\n",
    "#lr_reduce_patience = 20\n",
    "#lr_reduce_factor = 0.1\n",
    "\n",
    "loss_fn = nn.MSELoss()  \n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=params['lr'], momentum=0.9, dampening=0, weight_decay=0, nesterov=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stop_patience = 10\n",
    "#min_val_loss = -10\n",
    "#patience_counter = 0\n",
    "#patience = 10\n",
    "\n",
    "best = 10000.0\n",
    "patience = 20\n",
    "fails = 0\n",
    "flag = False\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "regret_lst = []\n",
    "\n",
    "#l1_error = []\n",
    "\n",
    "#avg_violations = []\n",
    "#max_violations = []\n",
    "\n",
    "#l1_loss_fn = nn.L1Loss()\n",
    "\n",
    "train_iterator = itertools.cycle(train_dl)\n",
    "\n",
    "val_iter = itertools.cycle(val_dl)\n",
    "\n",
    "#flow_viol_lst = []\n",
    "#selection_viol_lst = []\n",
    "\n",
    "\n",
    "\n",
    "for iteration in range(0, params['iterations']):\n",
    "  # loop over the dataset multiple times\n",
    "  \n",
    "  print(\"------------------------------------iteration: {}\".format(iteration))\n",
    "    #running_loss = 0.0\n",
    "   \n",
    "    \n",
    "    \n",
    "  model.train()\n",
    "  \n",
    "  #train_iterator = itertools.cycle(train_dl)\n",
    "  data = next(iter(train_iterator))\n",
    "  inputs, targets  = data\n",
    "  \n",
    " \n",
    "  \n",
    "  \n",
    "  prediction = model(inputs)\n",
    "      \n",
    " \n",
    "  loss = loss_fn(prediction,targets) \n",
    "    \n",
    "    \n",
    "  print(\"loss\", loss.item())  \n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "    \n",
    "  train_losses.append(loss.item())\n",
    "  \n",
    "  with torch.no_grad(): \n",
    "    model.eval()\n",
    "    val_data = next(iter(val_iter))\n",
    "    \n",
    "    val_inputs, val_targets = val_data\n",
    "      \n",
    "      #with torch.no_grad():\n",
    "    print(\"eval----------\")\n",
    "    linear_layer_output_val = model(val_inputs)\n",
    "    #max_v_, avg_v_ , a_v, b_v= calc_violations(inci_matrix, linear_layer_output_val.detach())\n",
    "    val_loss = loss_fn(linear_layer_output_val, val_targets)# + 0.9*a_v + 0.1*b_v\n",
    "    val_losses.append(val_loss.item())\n",
    "    \n",
    "    regret = regret_cvxpy(val_targets, linear_layer_output_val, cvx_py) \n",
    "    print(\"regret\",regret.item())\n",
    "    regret_lst.append(regret.item())\n",
    "    print(\"eval done------\")\n",
    "  \n",
    "  print(' train loss: {}, valid loss: {} '.format(round(loss.item(), 3), round(val_loss.item(),3)))\n",
    "  \n",
    "  if iteration%10==0:\n",
    "    if val_loss < (best - 1e-5):\n",
    "      print(\"\\n UPDATE \\n\")\n",
    "      best_model = copy.deepcopy(model)\n",
    "      fails = 0\n",
    "      best = val_loss\n",
    "    else:\n",
    "      fails = fails + 1\n",
    "    if fails > patience:\n",
    "      print(\"Early Stopping. Valid hasn't improved for {}\".format(patience))\n",
    "      flag = True\n",
    "    if flag:\n",
    "      break\n",
    "    loss = 0\n",
    "    val_loss = 0\n",
    "   \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = itertools.cycle(test_dl)\n",
    "test_l2 = nn.MSELoss() \n",
    "#test_l1 = nn.L1Loss() \n",
    "\n",
    "l2_weights = []\n",
    "l2_decision = []\n",
    "test_viol = []\n",
    "optimal_path_acc = []\n",
    "inf_time = []\n",
    "\n",
    "#optimal_path_acc = []\n",
    "\n",
    "i =0 \n",
    "for inputs, targets in test_iter:\n",
    "    \n",
    "    start = time.process_time()\n",
    "    linear_layer_output = torch.nn.functional.normalize(model(inputs))\n",
    "    selected_edges = cvx_py(inci_matrix,linear_layer_output)\n",
    "    inf_time.append(time.process_time() - start)\n",
    "    \n",
    "    error_w = test_l2(linear_layer_output,targets)\n",
    "    l2_weights.append(error_w)\n",
    "    \n",
    "    selected_edges_targets = cvx_py(inci_matrix,targets)\n",
    "    error_d = test_l2(selected_edges,selected_edges_targets)\n",
    "    l2_decision.append(error_d)\n",
    "    \n",
    "    vio = calc_violations(inci_matrix,selected_edges.detach())[1]\n",
    "    test_viol.append(vio)\n",
    "    #selected_edges = model_load(linear_layer_output)\n",
    "    #selected_edges_targets = cvx_py(A,linear_layer_output) \n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break\n",
    "\n",
    "print(\"l2 weights\", sum(l2_weights)/len(l2_weights))\n",
    "print(\"l2 decision\", sum(l2_decision)/len(l2_decision))\n",
    "print(\"inf time\", sum(inf_time)/len(inf_time))\n",
    "print(\"violations\", sum(test_viol)/len(test_viol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses,color='r', label='train loss')\n",
    "plt.plot(val_losses, color='g', label='val loss')\n",
    "\n",
    "plt.xlabel(\"loss\")\n",
    "plt.ylabel(\"iterations\")\n",
    "plt.title(\"loss\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(regret_lst)\n",
    "plt.ylabel('regret')\n",
    "plt.xlabel('iterations')\n",
    "plt.title(\"regret\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
